{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a7a0906",
   "metadata": {},
   "source": [
    "\n",
    "Giả sử chúng ta có một bộ dữ liệu gồm các quan sát độc lập và xác định (iid) là $\\mathcal{D} = \\{ \\mathbf{x}_1, \\mathbf{x}_2. \\dots, \\mathbf{x}_N \\}$. Trong đó mỗi một $\\mathbf{x}_i \\in \\mathbb{R}^{d}$ là một véc tơ quan sát trong không gian $d$ chiều được lấy mẫu từ _phân phối Gaussian đa chiều_. Chúng ta cần ước lượng phân phối của tham số thông qua _ước lượng hợp lý tối đa MLE_.\n",
    "\n",
    "$N$ quan sát được giả định là độc lập. Do đó hàm hợp lý của phân phối của $N$ quan sát sẽ bằng tích của xác suất trên từng quan sát:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\tl(\\mathbf{ \\mu, \\Sigma }|\\mathcal{D}) & = \\log \\prod_{i=1}^m f_{\\mathbf{x}_{i}}(\\mathbf{x}_{i} | \\mu , \\mathbf{\\Sigma} )\n",
    "\t\\\\\n",
    "\t& =  \\log  \\ \\prod_{i=1}^N \\frac{1}{(2 \\pi)^{d/2} |\\mathbf{\\Sigma}|^{1/2}} \\exp \\left( - \\frac{1}{2} (\\mathbf{x}_{i} - \\mu)^{\\intercal} \\mathbf{\\Sigma}^{-1} (\\mathbf{x}_{i} - \\mu) \\right) \n",
    "\t\\\\\n",
    "\t& = \\sum_{i=1}^N \\left( - \\frac{d}{2} \\log (2 \\pi) - \\frac{1}{2} \\log |\\mathbf{\\Sigma}|  - \\frac{1}{2}   \\mathbf{(x}_{i} - \\mu)^{\\intercal} \\mathbf{\\Sigma}^{-1} (\\mathbf{x}_{i} - \\mu)  \\right) \n",
    "  \\\\\n",
    "  & = - \\frac{N}{2} \\log |\\mathbf{\\Sigma}| - \\sum_{i=1}^N  \\frac{1}{2}   \\mathbf{(x}_{i} - \\mu)^{\\intercal} \\mathbf{\\Sigma}^{-1} (\\mathbf{x}_{i} - \\mu) - \\underbrace{\\frac{Nd}{2} \\log (2 \\pi)}_{C} \\\\\n",
    "  & = - \\frac{N}{2} \\log |\\mathbf{\\Sigma}| - \\sum_{i=1}^N  \\frac{1}{2}   \\mathbf{(x}_{i} - \\mu)^{\\intercal} \\mathbf{\\Sigma}^{-1} (\\mathbf{x}_{i} - \\mu) + C\n",
    "\\end{aligned}$$\n",
    "\n",
    "Lấy đạo hàm bậc nhất của _hàm hợp lý_ theo $\\mu$ và $\\mathbf{\\Sigma}$.\n",
    "\n",
    "**Đạo hàm theo** $\\mu$:\n",
    "\n",
    "\n",
    "Để tính toán đạo hàm bậc nhất chúng ta cần áp dụng công thức:\n",
    "\n",
    "$$\\frac{\\partial \\mathbf{w}^{\\intercal}\\mathbf{A}\\mathbf{w}}{\\partial \\mathbf{w}} = 2\\mathbf{A}\\mathbf{w}$$\n",
    "\n",
    "Coi $\\mathbf{\\Sigma}^{-1} = \\mathbf{A}$ và $\\mathbf{x}_i-\\mu = \\mathbf{w}$, khi đó:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\t\\frac{\\partial l(\\mathbf{ \\mu}, \\mathbf{ \\Sigma} | \\mathcal{D} )}{\\partial \\mu}  & = & -\\sum_{i=1}^N  \\mathbf{ \\Sigma^{-1}} ( \\mathbf{x}_{i} - \\mathbf{\\mu} ) \\\\\n",
    "  & = & \\mathbf{ \\Sigma^{-1}}(N\\mu - \\sum_{i=1}^N \\mathbf{x}_i)\n",
    "\\\\\n",
    "  & = & 0\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Nhân cả hai vế của dòng thứ 2 với $\\mathbf{\\Sigma}$ về phía ngoài cùng bên trái ta suy ra nghiệm $\\hat{\\mu}$ chính là:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    " N\\hat{\\mu} - \\sum_{i=1}^N \\mathbf{x}_i & = & 0 \\\\\n",
    " \\leftrightarrow \\hat{\\mu} & = & \\frac{\\sum_{i=1}^{N} \\mathbf{x}_i}{N}\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "**Đạo hàm theo** $\\mathbf{\\Sigma}$:\n",
    "\n",
    "Để tính toán đạo hàm theo $\\Sigma$ chúng ta cần áp dụng một số công thức:\n",
    "\n",
    "1.- Trace của tích ba ma trận không thay đổi nếu hoán vị:\n",
    "\n",
    "$$\\text{trace}{(\\mathbf{ABC})} = \\text{trace}{(\\mathbf{CAB})} = \\text{trace}{(\\mathbf{BCA})}$$\n",
    "\n",
    "2.- Khi $\\mathbf{x}^{\\intercal}\\mathbf{A}\\mathbf{x}$ là một số vô hướng (_scalar_) thì:\n",
    "\n",
    "$$\\mathbf{x}^{\\intercal}\\mathbf{A} \\mathbf{x} = \\text{trace}(\\mathbf{x}^{\\intercal}\\mathbf{A}\\mathbf{x}) = \\text{trace}(\\mathbf{x}^{\\intercal}\\mathbf{x}\\mathbf{A})$$\n",
    "\n",
    "3.- Đạo hàm của: \n",
    "\n",
    "$$\\frac{\\partial ~ \\text{trace}(\\mathbf{AB})}{\\partial \\mathbf{A}} = \\frac{\\partial ~ \\text{trace}(\\mathbf{BA})}{\\partial \\mathbf{A}} = \\mathbf{B}^{\\intercal}$$\n",
    "\n",
    "4.- Đạo hàm của: \n",
    "\n",
    "$$\\frac{\\partial \\log(\\mathbf{A})}{\\partial \\mathbf{A}} = \\mathbf{A}^{-\\intercal}$$\n",
    "\n",
    "5.- Định thức của một ma trận thì bằng nghịch đảo định thức của ma trận nghịch đảo:\n",
    "\n",
    "$$|\\mathbf{A}| = \\frac{1}{|\\mathbf{A}^{-1}|}$$\n",
    "\n",
    "Chứng minh những công thức trên không quá khó. Xin dành cho bạn đọc như một bài tập.\n",
    "\n",
    "Ngoài ra từ công thức thứ 2 và 3 ta suy ra:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\mathbf{A}}  \\mathbf{x}^{\\intercal}\\mathbf{A}\\mathbf{x} =\\frac{\\partial}{\\partial \\mathbf{A}}  \\text{trace} ( \\mathbf{x}^{\\intercal}\\mathbf{x}\\mathbf{A} ) = [ \\mathbf{x}^{\\intercal}\\mathbf{x}]^{\\intercal} =  \\mathbf{x}\\mathbf{x}^{\\intercal}$$\n",
    "\n",
    "đồng thời hàm hợp lý cũng được biến đổi thành:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\tl(\\mathbf{ \\mu, \\mathbf{\\Sigma}} | \\mathcal{D})  & = & C - \\frac{N}{2} \\log |\\mathbf{\\Sigma}|  - \\frac{1}{2}  \\sum_{i=1}^N  (\\mathbf{x}_{i} - \\mu)^{\\intercal} \\mathbf{\\Sigma}^{-1} (\\mathbf{x}_{i} - \\mu)   \n",
    "\t\\\\\n",
    "\t& = & C + \\frac{N}{2} \\log |\\mathbf{\\Sigma}^{-1}|  - \\frac{1}{2}  \\sum_{i=1}^N  \\text{trace}\\left[ (\\mathbf{x}_{i} - \\mu)^{\\intercal} (\\mathbf{x}_{i} - \\mu) \\mathbf{\\Sigma}^{-1}  \\right]\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Bây giờ chúng ta có thể tính toán đạo hàm theo ma trận $\\mathbf{\\Sigma}^{-1}$ như sau:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\t\\frac{\\partial l(\\mathbf{ \\mu, \\Sigma}|\\mathcal{D})}{\\partial \\mathbf{\\Sigma}^{-1}}  & = & \\frac{N}{2}\\mathbf{\\Sigma}^{\\intercal} - \\frac{1}{2}  \\sum_{i=1}^N (\\mathbf{x}_{i} - \\mu) (\\mathbf{x}_{i} - \\mu)^{\\intercal} \\\\\n",
    "& = & \\frac{N}{2}\\mathbf{\\Sigma} - \\frac{1}{2}  \\sum_{i=1}^N (\\mathbf{x}_{i} - \\mu) (\\mathbf{x}_{i} - \\mu)^{\\intercal}\n",
    "  \\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Dòng thứ 2 thu được là vì $\\mathbf{\\Sigma}$ là ma trận đối xứng. Như vậy nghiệm $\\hat{\\mathbf{\\Sigma}}$ chính là:\n",
    "\n",
    "$$\\begin{eqnarray}\\frac{N}{2}\\hat{\\mathbf{\\Sigma}} - \\frac{1}{2}  \\sum_{i=1}^N (\\mathbf{x}_{i} - \\mu) (\\mathbf{x}_{i} - \\mu)^{\\intercal} & = & 0\n",
    "\\\\ \\leftrightarrow \\hat{\\mathbf{\\Sigma}} = \\frac{\\sum_{i=1}^N (\\mathbf{x}_{i} - \\mu) (\\mathbf{x}_{i} - \\mu)^{\\intercal}}{N}\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Như vậy ta thu được ước lượng hợp lý tối đa cho các tham số của _phân phối Gassian đa chiều_:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "\\hat{\\mu} & = & \\frac{\\sum_{i=1}^{N} \\mathbf{x}_i}{N} = \\mathbb{E}(\\mathbf{X}) \\\\\n",
    "\\hat{\\mathbf{\\Sigma}} & = & \\frac{\\sum_{i=1}^N (\\mathbf{x}_{i} - \\mu) (\\mathbf{x}_{i} - \\mu)^{\\intercal}}{N} = \\mathbb{Cov}(\\mathbf{X})\n",
    "\\end{matrix}\n",
    "\\right.\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ac4a6",
   "metadata": {
    "id": "dXcfSfIkyMSm"
   },
   "source": [
    "# 16.2. Gaussian Mixture Model\n",
    "\n",
    "_Gaussian Mixture Model_ (viết tắt _GMM_) là một mô hình phân cụm thuộc lớp bài toán học không giám sát mà phân phối xác suất của mỗi một cụm được giả định là _phân phối Gassian đa chiều_. Sở dĩ mô hình được gọi là _Mixture_ là vì xác suất của mỗi điểm dữ liệu không chỉ phụ thuộc vào một phân phối _Gaussian_ duy nhất mà là kết hợp từ nhiều phân phối _Gaussian_ khác nhau từ mỗi cụm.\n",
    "\n",
    "![](https://imgur.com/6OvUE6Z.png)\n",
    "\n",
    "**Hình 3**: _Phân phối Gaussian đa chiều_ với số cụm $k=3$ đối với bộ dữ liệu một chiều (bên trái) và hai chiều (bên phải).\n",
    "\n",
    "Mục tiêu của mô hình _GMM_ là ước lượng tham số phù hợp nhất cho $k$ cụm thông qua phương pháp ước lượng hợp lý tối đa mà chúng ta sẽ thảo luận kĩ hơn ở bên dưới. Một số giả định của mô hình _GMM_:\n",
    "\n",
    "* Có $k$ cụm cần phân chia mà mỗi cụm tuân theo _phân phối Gaussian đa chiều_ với tập tham số đặc trưng $\\{{(\\mu_i, \\mathbf{\\Sigma}_i)}\\}_{i=1}^{k}$.\n",
    "* $z_{k}$ được giả định là một biến ngẫu nhiên nhận giá trị 1 nếu như quan sát $\\mathbf{x}$ rơi vào cụm thứ $k$, các trường hợp còn lại nhận giá trị 0.\n",
    "* $z_{k}$ được coi như là một _biến ẩn_ (_latent variable_ hoặc _hidden variable_) mà ta chưa biết giá trị của nó. Xác suất xảy ra của $p(z_{k}=1 | \\mathbf{x})$ giúp chúng ta xác định tham số phân phối của _Gaussian Mixture_. Điều này sẽ được thảo luận kĩ hơn bên dưới.\n",
    "\n",
    "Tập hợp các giá trị của $z_{k}$ đối với các cụm sẽ tạo thành một phân phối xác suất sẽ tạo thành một phân phối xác suất $(\\pi_1, \\pi_2, \\dots, \\pi_k)$ trong đó $\\pi_k = p(z_{k}=1 | \\mathbf{x})$.\n",
    "\n",
    "Một xác suất hỗn hợp tại một điểm dữ liệu $\\mathbf{x}$ sẽ được tính theo công thức Bayes như sau:\n",
    "\n",
    "$$\\begin{eqnarray}p(\\mathbf{x}) & = & \\sum_{c=1}^{k}p(z_c)p(\\mathbf{x}|z_c)\\\\\n",
    "& = & \\sum_{c=1}^{k} p(z_c=1) p(\\mathbf{x}|\\mu_c, \\mathbf{\\Sigma}_c) \\\\\n",
    "& = & \\sum_{c=1}^{k} \\pi_c p(\\mathbf{x}|\\mu_c, \\mathbf{\\Sigma}_c) \\\\\n",
    "& = & \\sum_{c=1}^{k} \\pi_c N(\\mathbf{x}|\\mu_c, \\mathbf{\\Sigma}_c) \n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Thành phần xác suất $p(\\mathbf{x}|\\mu_i, \\mathbf{\\Sigma}_i)$ được tính từ phân phối _Guassian đa chiều_ và chúng đồng thời là mục tiêu mà chúng ta cần tham số hoá."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8fe68",
   "metadata": {
    "id": "TqwJg6pB2aj6"
   },
   "source": [
    "## 16.2.1. Ước lượng hợp lý tối đa\n",
    "\n",
    "Bài toán đặt ra đó là giả sử chúng ta có một tập dữ liệu $\\mathcal{X} = \\{\\mathbf{x}_i\\}_{i=1}^{N}$ hãy tìm ra ước lượng hợp lý tối đa của các tham số $\\theta$ sao cho lớp mô hình được giả định là _GMM_ khớp nhất bộ dữ liệu. Như vậy $\\theta^{*}$ chính là nghiệm của bài toán:\n",
    "\n",
    "$$\\theta^{*} = \\arg \\max_{\\theta} p(\\mathbf{X}|\\theta) = \\arg \\max_{\\theta} \\prod_{i=1}^{N} p(\\mathbf{x}_i| \\theta)$$\n",
    "\n",
    "Để giải phương trình trên chúng ta có thể dựa trên hai cách tiếp cận:\n",
    "\n",
    "* Giải trực tiếp phương trình đạo hàm của hàm logarith để theo các hệ số để tìm ra nghiệm tối ưu như đã thực hiện đối với _phân phối Gaussian đa biến_ cho 1 cụm. Tuy nhiên phương pháp này tỏ ra bất khả thi bởi đối với bài toán có nhiều cụm thì hàm mất mát trở nên phức tạp hơn nhiều. Việc giải phương trình đạo hàm dường như là không thể.\n",
    "\n",
    "* Sử dụng thuật toán _EM (Expectation-Maximization)_ để cập nhật dần dần nghiệm của $\\theta$.\n",
    "\n",
    "Thuật toán _EM_ là một trong những phương pháp thường được sử dụng để cập nhật nghiệm theo hàm hợp lý. Đây là một phương pháp đơn giản và hiệu quả, phù hợp với các bài toán phức tạp khi mà lời giải trực tiếp từ đạo hàm không dễ dàng tìm kiếm. Bên dưới chúng ta sẽ tiếp tục tìm hiểu phương pháp này:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707087a",
   "metadata": {
    "id": "8S6lium31EtV"
   },
   "source": [
    "Trong thuật toán _EM_ chúng ta liên tục thực hiện các vòng lặp mà mỗi vòng lặp bao gồm hai bước huấn luyện chính:\n",
    "\n",
    "* E-Step: Ước lượng phân phối của _biến ẩn_ $z$ thể hiện phân phối xác suất của các cụm tương ứng với dữ liệu và bộ tham số phân phối.\n",
    "* M-Step: Tối đa hoá phân phối xác suất đồng thời (_join distribution probability_) của dữ liệu và _biến ẩn_.\n",
    "\n",
    "Cụ thể những bước này sẽ được thể hiện qua hình minh hoạ:\n",
    "\n",
    "![](https://imgur.com/NNCFeR1.png)\n",
    "\n",
    "**Hình 4**: Hình bên trái là bước E-Step. Tại bước này chúng ta tính toán phân phối xác suất tại từng điểm dữ liệu ứng với mỗi cụm theo bộ tham số phân phối trên từng cụm lúc ban đầu. Chẳng hạn tại một điểm trong hình ở phía trên chúng ta tính ra hai xác suất là $P(A)=0.6$ và $P(B)=0.4$ và tại một điểm ở phía dưới tính ra xác suất $P(A)=0.2$ và $P(B)=0.8$. Tiếp theo hình bên phải là bước M-Step thể hiện cách cập nhật lại tham số để phù hợp với phân phối của các cụm dữ liệu. Ở đây tham số trung bình của các cụm được cập nhật lại đồng nghĩa với việc dịch chuyển cụm sao cho giá trị hợp lý của phân phối lý thuyết được tối đa hoá và tiến gần tới phân phối thực ở mỗi cụm.\n",
    "\n",
    "Để cập nhật tham số thì chúng ta xét một hàm _auxilary_ như sau:\n",
    "\n",
    "$$\\begin{eqnarray}Q(\\theta, \\theta_t) & = & \\mathbb{E}_{z}(\\log p(\\mathbf{X}, \\mathbf{Z} | \\theta_t)) \\\\\n",
    "& = & \\sum_z p(z|\\mathbf{X}, \\theta_t) \\log p(\\mathbf{X}, \\mathbf{Z} | \\theta) \\\\\n",
    "& = & \\sum_z p(z|\\mathbf{X}, \\theta_t) \\log \\left[~ p(\\mathbf{Z} | \\mathbf{X}, \\theta) p(\\mathbf{X} | \\theta) \\right] \\\\\n",
    "& = & \\sum_z p(z|\\mathbf{X}, \\theta_t) \\log p(\\mathbf{Z} | \\mathbf{X}, \\theta) + \\underbrace{\\left[ \\sum_z p(z|\\mathbf{X}, \\theta) \\right]}_{1} \\log p(\\mathbf{X} | \\theta) \\\\\n",
    "& = & \\sum_z p(z|\\mathbf{X}, \\theta_t) \\log p(\\mathbf{Z} | \\mathbf{X}, \\theta) + \\log p(\\mathbf{X} | \\theta)\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Như vậy $Q(\\theta, \\theta_t)$ chính là kì vọng của logarith xác suất chung của $\\mathbf{X}$ và $\\mathbf{Z}$ trên từng cụm dữ liệu. Giá trị kì vọng này bằng tổng theo trọng số của xác suất tiên nghiệm $p(z|\\mathbf{X}, \\theta_t)$ trên từng cụm. Xác suất này có thể tính được dựa trên tham số $\\theta_t$ trước đó ($\\theta$ ở đây là đại diện chung cho cả $\\mu$ và $\\mathbf{\\Sigma}$). Tham số mà chúng ta cần cập nhật sẽ nằm ở _log likehood_ của xác suất chung $\\log p(\\mathbf{X}, \\mathbf{Z} | \\theta) $. Để tính xác suất này chúng ta phân tích chúng theo công thức Bayes giữa $p(\\mathbf{Z} | \\mathbf{X}, \\theta)$ và $p(\\mathbf{X} | \\theta)$. Cuối cùng chúng ta rút gọn thành tổng giữa logarith hàm hợp lý $\\log p(\\mathbf{X} | \\theta)$ và logarith xác suất hậu nghiệm $\\log p(\\mathbf{Z} | \\mathbf{X}, \\theta)$.\n",
    "\n",
    "Tại sao tối đa hoá hàm hợp lý chúng ta lại thông qua $Q(\\theta, \\theta_t)$. Đó là bởi khi giá trị $Q(\\theta, \\theta_t)$ gia tăng thì kéo theo sự gia tăng _hàm hợp lý_. Như vậy tồn tại một chuỗi vô hạn $\\{\\theta_j'\\}_{j=0}^{\\infty}$ sao cho $Q(\\theta_j', \\theta_t)$ là một chuỗi tăng và dẫn tới $\\{\\theta_j'\\}_{j=0}^{\\infty}$ hội tụ về nghiệm cực đại $\\theta^{*}$. Khi đó giá trị _hàm hợp lý_ $\\log p(\\mathbf{X} | \\theta')$ cũng là một chuỗi tăng và có nghiệm hội tụ về $\\theta^*$. Tức là quá trình tìm nghiệm của _hàm hợp lý_ có thể tìm được thông qua hàm $Q(\\theta, \\theta_t)$.\n",
    "\n",
    "Tiếp theo ta sẽ chứng minh rằng sự gia tăng của $Q(\\theta, \\theta_t)$ kéo theo sự gia tăng của _hàm hợp lý_. Thật vậy:\n",
    "\n",
    "$$\\begin{eqnarray}Q(\\theta, \\theta_t) - Q(\\theta_t, \\theta_t) & = & \\log p(\\mathbf{X} | \\theta) - \\log p(\\mathbf{X} | \\theta_t) - \\sum_z p(z|\\mathbf{X}, \\theta_t) \\log \\frac{p(\\mathbf{Z} | \\mathbf{X}, \\theta)}{p(\\mathbf{Z} | \\mathbf{X}, \\theta_t)} \\\\\n",
    "& = & \\log p(\\mathbf{X} | \\theta) - \\log p(\\mathbf{X} | \\theta_t) - \\underbrace{\\text{KL}(p(\\mathbf{Z} | \\mathbf{X}, \\theta), p(\\mathbf{Z} | \\mathbf{X}, \\theta_t))}_{\\geq 0} \\\\\n",
    "& \\leq &  \\log p(\\mathbf{X} | \\theta) - \\log p(\\mathbf{X} | \\theta_t)\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Dòng thứ 2 được suy ra là bởi $\\sum_z p(z|\\mathbf{X}, \\theta_t) \\log \\frac{p(\\mathbf{Z} | \\mathbf{X}, \\theta)}{p(\\mathbf{Z} | \\mathbf{X}, \\theta_t)}$ chính là một độ đo Kullback-Leibler Divergence về khoảng cách giữa hai phân phối. Giá trị này luôn lớn hơn hoặc bằng 0. Bạn có thể xem thêm chứng minh tại [Kullback-Leibler Divergence](https://phamdinhkhanh.github.io/2020/07/25/GAN_Wasserstein.html#3-kullback-leibler-divergence).\n",
    "\n",
    "Bất đẳng thức trên cho thấy khi $Q(\\theta, \\theta_t) \\geq Q(\\theta_t, \\theta_t)$ sẽ kéo theo $\\log p(\\mathbf{X} | \\theta) \\geq \\log p(\\mathbf{X} | \\theta_t)$. Như vậy thay vì tối đa hoá hàm mục tiêu là _hàm hợp lý_ thì chúng ta có thể tối đa hoá hàm $Q(\\theta, \\theta_t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c560e",
   "metadata": {
    "id": "eUmjhxUs5URq"
   },
   "source": [
    "## 16.2.2. Khai triển hàm _auxilary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe22b80",
   "metadata": {
    "id": "DDd62DhmuZ2q"
   },
   "source": [
    "Xác suất xảy ra tại một điểm dữ liệu có thể được biểu diễn theo [phân phối Category](https://phamdinhkhanh.github.io/deepai-book/ch_probability/appendix_probability.html#phan-phoi-category) như sau:\n",
    "\n",
    "$$p(\\mathbf{x}_i, \\mathbf{z} | \\theta) = \\prod_{j=1}^{k} [p(\\mathbf{x}_i, z_{j}| \\theta)]^{z_{j}}  = \\prod_{j=1}^{k} [p(\\mathbf{x}_i | z_{j}, \\theta) p(z_{j} | \\theta)]^{z_{j}} = \\prod_{j=1}^{k} [p(\\mathbf{x}_i | z_{j}, \\theta) \\pi_j]^{z_{j}}$$\n",
    "\n",
    "Như vậy giá trị hàm hợp lý của phân phối xác suất đồng thời có thể được viết như sau:\n",
    "\n",
    "$$\\mathcal{L}(\\mathbf{X}, \\mathbf{Z} | \\theta) = p(\\mathbf{X}, \\mathbf{Z} | \\theta) = \\prod_{i=1}^{N}\\prod_{j=1}^{k} \\left[ p(\\mathbf{x}_i, z_{j} | \\theta) \\right]^{z_{j}} = \\prod_{i=1}^{N}\\prod_{j=1}^{k} \\left[ p(\\mathbf{x}_i | z_{j}, \\theta)\\pi_j \\right]^{z_{j}}$$\n",
    "\n",
    "Lấy logarith hai vế ta thu được:\n",
    "\n",
    "$$\\log[p(\\mathbf{X}, \\mathbf{Z})] = \\sum_{i=1}^{N} \\sum_{j=1}^{k} z_{j} \\log p(\\mathbf{x}_i | z_{j}, \\theta) + z_{j} \\log \\pi_j$$\n",
    "\n",
    "\n",
    "Như vậy:\n",
    "\n",
    "\n",
    "$$\\begin{eqnarray}Q(\\theta, \\theta_t) & = & \\mathbb{E}_{z} \\left[ \\log p(\\mathbf{X}, \\mathbf{Z})| \\theta_t \\right] \\\\\n",
    "& = & \\mathbb{E}_{z} \\left[ \\sum_{i=1}^{N} \\sum_{j=1}^{k} z_{j} \\log p(\\mathbf{x}_i | z_{j}, \\theta) + z_{j} \\log \\pi_j | \\theta_t \\right] \\\\\n",
    "& = &  \\sum_{i=1}^{N} \\sum_{j=1}^{k} \\mathbb{E}_{z} [ z_{j}|\\theta_t] \\log p(\\mathbf{x}_i | z_{j}, \\theta) + \\mathbb{E}_{z} [z_{j} | \\theta_t] \\log \\pi_j \\\\\n",
    "& = & \\sum_{i=1}^{N} \\sum_{j=1}^{k} p(z_{j} | \\mathbf{x}_i , \\theta_t) \\left[ \\log p(\\mathbf{x}_i | z_{j}, \\theta) + \\log \\pi_j \\right] \\\\\n",
    "& = & \\sum_{i=1}^{N}\\sum_{j=1}^{k} p( z_{j} | \\mathbf{x}_i , \\theta_t)  \\left[  \\log \\frac{\\exp \\left( - \\frac{1}{2} (\\mathbf{x}_{i} - \\mu_j)^{\\intercal} \\mathbf{\\Sigma}_j^{-1} (\\mathbf{x}_{i} - \\mu_j) \\right)}{(2 \\pi)^{d/2} |\\mathbf{\\Sigma}_j|^{1/2}} + \\log \\pi_j \\right] \\\\\n",
    "& = & \\sum_{i=1}^{N}\\sum_{j=1}^{k} p( z_{j} | \\mathbf{x}_i , \\theta_t) \\left[ - \\frac{1}{2} \\log |\\mathbf{\\Sigma}_j| - \\frac{1}{2}   \\mathbf{(x}_{i} - \\mu_j)^{\\intercal} \\mathbf{\\Sigma}_j^{-1} (\\mathbf{x}_{i} - \\mu_j) + \\log \\pi_j+  C_j  \\right]\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53fb8a",
   "metadata": {
    "id": "C3lEtWh25Zns"
   },
   "source": [
    "## 16.2.3. Các bước trong GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017abf8",
   "metadata": {
    "id": "_xq1dUZTzHjA"
   },
   "source": [
    "**Bước E-Step**:\n",
    "\n",
    "Mục tiêu của bước E-Step là tính xác suất của mỗi điểm dữ liệu dựa vào _phân phối Gaussian đa chiều_ dựa trên tham số $\\theta_t$ của vòng lặp gần nhất. Xác suất này được tính như sau:\n",
    "\n",
    "$$\\begin{eqnarray}\\mathbb{E}_{z}(z_{j} | \\mathbf{x}_i, \\theta_t) & = & 1 \\times p(z_{j} = 1 |  \\mathbf{x}_i, \\theta_t) + 0 \\times p(z_{j} = 0 |  \\mathbf{x}_i,\\theta_t) \\\\\n",
    "& = & p(z_{j}|\\mathbf{x}_i, \\theta_t) \\\\\n",
    "& = & \\frac{p(z_{j} | \\theta_t) p(\\mathbf{x}_i | z_{j}, \\theta_t)}{p(\\mathbf{x}_i | \\theta_t)} \\\\\n",
    "& = & \\frac{\\pi_j N(\\mu_{jt}, \\mathbf{\\Sigma}_{jt}|\\mathbf{x}_i)}{\\sum_{j} \\pi_j N(\\mu_{jt}, \\mathbf{\\Sigma}_{jt}|\\mathbf{x}_i)}\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Xác suất $\\pi_j$ chính là _xác suất tiên nghiệm_ (_posteriori probability_) bằng với tỷ lệ các quan sát thuộc về cụm $j$ ở vòng lặp thứ $t$. Trong khi $N(\\mu_{jt}, \\mathbf{\\Sigma}_{jt}|\\mathbf{x}_i)$ là xác suất của $\\mathbf{x}_i$ rơi vào cụm thứ $j$ được tính theo _phân phối Gaussian đa chiều_. Hai xác suất này có thể tính được và sau cùng ta thu được xác suất rơi vào mỗi cụm tại mỗi một quan sát $\\mathbf{x}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140172f3",
   "metadata": {
    "id": "IdKQJEIn4rws"
   },
   "source": [
    "**Bước M-Step**:\n",
    "\n",
    "Tại bước M-Step chúng ta cần cập nhật lại tham số phân phối theo hàm _auxiliary_ $Q(\\theta, \\theta_t)$. Cực trị đạt được khi đạo hàm bậc nhất bằng 0:\n",
    "\n",
    "$$\\frac{\\partial Q(\\theta, \\theta_t)}{\\partial \\theta} = 0$$\n",
    "\n",
    "\n",
    "Ở đây $\\theta$ là các tham số $\\{\\pi_j, \\mu_j, \\mathbf{\\Sigma}_j \\}_{j=1}^k$. Lần lượt giải phương trình đạo hàm theo $\\mu_j$ và $\\mathbf{\\Sigma}_j$ tương tự như đối với ước lượng MLE đã trình bày ở chương thứ hai:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842169a",
   "metadata": {
    "id": "nc6jjgPUmORu"
   },
   "source": [
    "$$\\begin{eqnarray}\\frac{\\partial Q(\\theta, \\theta_t)}{\\partial \\mu_j} & = &  \\frac{\\partial}{\\partial \\mu_j} \\sum_{i=1}^{N}\\sum_{j=1}^{k} p( z_{j} | \\mathbf{x}_i , \\theta_t) \\left[ - \\frac{1}{2} \\log |\\mathbf{\\Sigma}_j| - \\frac{1}{2}   \\mathbf{(x}_{i} - \\mu_j)^{\\intercal} \\mathbf{\\Sigma}_j^{-1} (\\mathbf{x}_{i} - \\mu_j) + \\log \\pi_j+  C_j  \\right] \\\\\n",
    "& = & \\frac{\\partial}{\\partial \\mu_j} p( z_{j} | \\mathbf{x}_i , \\theta_t) \\left[ \\sum_{i=1}^N  \\mathbf{\\Sigma}_j^{-1} (\\mu_j-\\mathbf{x}_{i})  \\right] \\\\\n",
    "& = & \\frac{\\partial}{\\partial \\mu_j} \\mathbf{\\Sigma}_j^{-1} \\left[ \\sum_{i=1}^N  p( z_{j} | \\mathbf{x}_i , \\theta_t) (\\mu_j-\\mathbf{x}_{i})  \\right] \\\\\n",
    "& = & 0\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Từ đó suy ra:\n",
    "\n",
    "$$\\mu_j^{*} = \\frac{\\sum_{i=1}^{N} p(z_j| \\mathbf{x}_i, \\theta_t) \\mathbf{x}_i}{\\sum_{i=1}^N p(z_j | \\mathbf{x}_i, \\theta_t)}$$\n",
    "\n",
    "Trong đó $p(z_j| \\mathbf{x}_i, \\theta_t)$ chính là xác suất tương ứng để $\\mathbf{x}_i$ thuộc về cụm $j$ được tính từ bước E-Step.\n",
    "\n",
    "Tiếp theo ta cần tính đạo hàm theo $\\mathbf{\\Sigma}_j$.\n",
    "\n",
    "\n",
    "$$\\begin{eqnarray}\\frac{\\partial Q(\\theta, \\theta_t)}{\\partial \\mathbf{\\Sigma}_j^{-1}} & = &  \\frac{\\partial}{\\partial \\mu_j} \\sum_{i=1}^{N}\\sum_{j=1}^{k} p( z_{j} | \\mathbf{x}_i , \\theta_t) \\left[ - \\frac{1}{2} \\log |\\mathbf{\\Sigma}_j| - \\frac{1}{2}   \\mathbf{(x}_{i} - \\mu_j)^{\\intercal} \\mathbf{\\Sigma}_j^{-1} (\\mathbf{x}_{i} - \\mu_j) + \\log \\pi_j+  C_j  \\right] \\\\\n",
    "& = & \\sum_{i=1}^{N}p( z_{j} | \\mathbf{x}_i , \\theta_t) \\left[ \\frac{1}{2}\\mathbf{\\Sigma}_j - \\frac{1}{2}  (\\mathbf{x}_{i} - \\mu_j) (\\mathbf{x}_{i} - \\mu_j)^{\\intercal} \\right] \\\\\n",
    "& = & 0\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Suy ra:\n",
    "\n",
    "$$\\mathbf{\\Sigma}_j^{*} = \\frac{\\sum_{i=1}^{N} p(z_{j} | \\mathbf{x}_i, \\theta_t) [(\\mathbf{x}_i-\\mu_j)(\\mathbf{x}_i-\\mu_j)^{\\intercal}]}{\\sum_{i=1}^{N} p(z_{j} | \\mathbf{x}_i, \\theta_t)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcefd1bb",
   "metadata": {
    "id": "dNmrWwhQmQaA"
   },
   "source": [
    "Như vậy tham số tối ưu ở mỗi cụm sẽ được cập nhật theo công thức:\n",
    "\n",
    "$$\\mu_j^* = \\frac{\\sum_{i=1}^{N} p(z_{j} | \\mathbf{x}_i, \\theta_t) \\mathbf{x}_i}{\\sum_{i=1}^{N} p(z_{j}| \\mathbf{x}_i, \\theta_t)}$$\n",
    "\n",
    "$$\\mathbf{\\Sigma}_j^* = \\frac{\\sum_{i=1}^{N} p(z_{j} | \\mathbf{x}_i, \\theta_t) [(\\mathbf{x}_i-\\mu_j)(\\mathbf{x}_i-\\mu_j)^{\\intercal}]}{\\sum_{i=1}^{N} p(z_{j} | \\mathbf{x}_i, \\theta_t)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8960bb",
   "metadata": {
    "id": "lBU4u5Cc68wY"
   },
   "source": [
    "Để tính $\\pi_j$ chúng ta dựa vào điều kiện ràng buộc $\\sum_{j=1}^k \\pi_j=1$. Khi đó hàm Lagrange tương ứng với $Q(\\theta, \\theta_t)$ là:\n",
    "\n",
    "$$J(\\theta, \\theta_t) = Q(\\theta, \\theta_t) + \\lambda(1 - \\sum_{j=1}^{k} \\pi_j)$$\n",
    "\n",
    "Do đó:\n",
    "\n",
    "$$\\begin{eqnarray}\\frac{\\partial J(\\theta, \\theta_t)}{\\partial \\pi_j} & = & \\frac{\\partial Q(\\theta, \\theta_t)}{\\partial \\pi_j} - \\lambda \\\\\n",
    "& = & \\frac{\\sum_{i=1}^{N} p(z_{j} | \\mathbf{x}_i, \\theta_t)}{\\pi_j} - \\lambda = 0\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Từ đó suy ra: \n",
    "\n",
    "$$\\pi_j = \\frac{\\sum_{i=1}^{N} p(z_{j} | \\mathbf{x}_i, \\theta_t)}{\\lambda} \\tag{1}$$\n",
    "\n",
    "Mặt khác ta có $\\sum_{j=1}^{k} \\pi_j = 1$. Do đó:\n",
    "\n",
    "$$\\sum_{j=1}^k \\pi_j = \\frac{\\sum_{i=1}^{N} \\sum_{j=1}^k p(z_{j} | \\mathbf{x}_i, \\theta_t)}{\\lambda} = \\frac{N}{\\lambda} = 1$$\n",
    "\n",
    "Suy ra $\\lambda = N$ và thế vào công thức $(1)$ ta được:\n",
    "\n",
    "$$\\pi_j^* = \\frac{\\sum_{i=1}^{N} p(z_{j} | \\mathbf{x}_i, \\theta_t)}{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a127fd",
   "metadata": {
    "id": "f7rxwwqH5iUp"
   },
   "source": [
    "Như vậy chúng ta đã tìm ra được tham số tối ưu của thuật toán _GMM_ sau mỗi vòng lặp. Việc giải trực tiếp bài toán tối ưu _hàm hợp lý_ theo ước lượng _MLE_ là bất khả thi trong điều kiện có nhiều cụm dữ liệu. Chính vì thế thuật toán _EM_ được áp dụng để cập nhật dần dần tham số của mô hình. Thuật toán sẽ dần dần hội tụ sau một hữu hạn bước. Về lý thuyết của thuật toán _GMM_ chúng ta sẽ phải trải qua nhiều tính toán đạo hàm tương đối phức tạp. Tuy nhiên để thực hành thuật toán này lại tương đối dễ dàng trong sklearn. Chúng ta cùng sang phần thực hành để nắm rõ chi tiết."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.8.2"
   }
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "source_map": [
   11,
   121,
   150,
   166,
   203,
   207,
   233,
   237,
   251,
   262,
   288,
   296,
   320,
   324,
   330,
   345,
   349,
   353,
   366,
   370,
   386,
   414,
   428,
   432,
   442,
   489,
   493,
   503,
   507,
   546,
   550,
   561,
   587
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
