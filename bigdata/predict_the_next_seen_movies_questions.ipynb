{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoNpnIQOBcfx"
   },
   "source": [
    "# Predict the next seen movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nMdnOrdauzb"
   },
   "source": [
    "> The goal of this project is to validate your skills learned during the previous tutorials with the PySpark distributed computing software. You will build and test several implementations of recommendation systems. Here are the parts of the project:\n",
    "> \n",
    "> * Part A: Load and preprocess the dataset. \n",
    "> * Part B: Build a first set of recommendation algorithms: naive with recurring pairs, a priori, and fp-growth to infer rules from a dataset.\n",
    "> * Part C: Implement the PLSI algorithm (\"Probabilistic Latent Semantic Indexing\"), which is one way to create embeddings from a dataset. These embeddings can be used to fuel a recommendation engine.\n",
    "> * Part D: Predict the next movies seen by a user in function of the last movies that he/she has seen with the previous implemented algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69sUuh3EEEBw"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxRuqODPWgYM"
   },
   "source": [
    "## Install Spark Environment\n",
    "\n",
    "> Since you are running on Google Colab, you will need to install Spark by ourselves, every time we run a new session. You need to install Spark, as well as a Java Runtime Environment.  Then you need to setup a few environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vFR3wKqDrrsZ",
    "ExecuteTime": {
     "end_time": "2024-01-30T15:17:40.555916Z",
     "start_time": "2024-01-30T15:17:37.511788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/quyenlinhta/IASD/iasd/lib/python3.10/site-packages (23.3.2)\r\n",
      "Requirement already satisfied: pyspark in /Users/quyenlinhta/IASD/iasd/lib/python3.10/site-packages (3.5.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/quyenlinhta/IASD/iasd/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "^C\r\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip\n",
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBTHZp82G_Ea"
   },
   "source": [
    "Create and launch a Spark session with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "RKP62k6BW5Xz",
    "outputId": "3717708e-b09c-4b2d-82e6-508091a9f422",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-01-30T15:17:42.872347Z",
     "start_time": "2024-01-30T15:17:40.557132Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/30 16:17:41 WARN Utils: Your hostname, Beta.local resolves to a loopback address: 127.0.0.1; using 10.113.217.79 instead (on interface en0)\n",
      "24/01/30 16:17:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/30 16:17:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().set('spark.ui.port', '4050')\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf) \\\n",
    "    .master('local[*]') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "yA7rmX4p8BBo",
    "outputId": "032fdcab-c4d1-46f1-fa52-81c9c6aeef0c",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-01-30T15:17:43.342847Z",
     "start_time": "2024-01-30T15:17:42.874211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x106c3b850>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.113.217.79:4050\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWQFahH3HfJ9"
   },
   "source": [
    "/!\\ The Spark UI link is not accessible. Use the optional next session if you want to access it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bDPyOrBGzkC"
   },
   "source": [
    "Uncomment and execute the following line, if you want to close and stop the created Spark session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FXvFSpAkGyMm",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-01-30T15:17:43.347292Z",
     "start_time": "2024-01-30T15:17:43.342607Z"
    }
   },
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5yHDm0vXkIQ"
   },
   "source": [
    "## Optional step: Enable Spark UI access through a secure tunnel\n",
    "\n",
    "> This step is useful if you want to look at Spark UI.\n",
    "First, you need to create a free ngrok account : https://dashboard.ngrok.com/login.  \n",
    "Then connect on the website and copy your AuthToken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2bV9Ydi8sLs",
    "outputId": "c05116b9-54c9-489e-e61c-3545e13d01d6",
    "ExecuteTime": {
     "end_time": "2024-01-30T15:17:43.479325Z",
     "start_time": "2024-01-30T15:17:43.346008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darwin Beta.local 23.2.0 Darwin Kernel Version 23.2.0: Wed Nov 15 21:53:18 PST 2023; root:xnu-10002.61.3~2/RELEASE_ARM64_T6000 arm64\r\n"
     ]
    }
   ],
   "source": [
    "!uname -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCerOlcLXmgj",
    "outputId": "1ebd17be-82b4-4b5f-e7fc-36e8d1ada469",
    "ExecuteTime": {
     "end_time": "2024-01-30T15:17:55.528789Z",
     "start_time": "2024-01-30T15:17:43.467226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-30 16:17:43--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 54.237.133.81, 18.205.222.128, ...\r\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 13921656 (13M) [application/octet-stream]\r\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip.3’\r\n",
      "\r\n",
      "ngrok-stable-linux- 100%[===================>]  13.28M  4.49MB/s    in 3.0s    \r\n",
      "\r\n",
      "2024-01-30 16:17:46 (4.49 MB/s) - ‘ngrok-stable-linux-amd64.zip.3’ saved [13921656/13921656]\r\n",
      "\r\n",
      "Archive:  ngrok-stable-linux-amd64.zip\r\n",
      "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHgGqKOeAYVH",
    "outputId": "09fe2b9d-700d-4c9f-d911-3e4fd11c866f",
    "ExecuteTime": {
     "end_time": "2024-01-30T15:17:59.929077Z",
     "start_time": "2024-01-30T15:17:59.776021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: exec format error: ./ngrok\r\n"
     ]
    }
   ],
   "source": [
    "!./ngrok authtoken '2HYfdysedjgB5lcoeE8lqqShgIe_sZUm49MquX5okpssVMYQ' # <-------------- change this line !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1G-XfsyHAT84",
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:00.446571Z",
     "start_time": "2024-01-30T15:18:00.423599Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "zsh:1: exec format error: ./ngrok\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system_raw('./ngrok http 4050 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jWA3ILoOBAw",
    "outputId": "1b9b2d20-9fb8-4679-bf8b-e3648f16b31b",
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:03.095009Z",
     "start_time": "2024-01-30T15:18:03.013373Z"
    }
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 61] Connection refused>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1348\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1347\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1348\u001B[0m     \u001B[43mh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1349\u001B[0m \u001B[43m              \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhas_header\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTransfer-encoding\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1350\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1282\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1281\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1282\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1328\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1327\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1328\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1277\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[0;32m-> 1277\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1037\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[0;32m-> 1037\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1040\u001B[0m \n\u001B[1;32m   1041\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:975\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    974\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[0;32m--> 975\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    976\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:941\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    940\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp.client.connect\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mport)\n\u001B[0;32m--> 941\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    942\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource_address\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    943\u001B[0m \u001B[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:845\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    844\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 845\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    846\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    847\u001B[0m     \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:833\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    832\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[0;32m--> 833\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[0;31mConnectionRefusedError\u001B[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mURLError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01murllib\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m ngrok_tunnels \u001B[38;5;241m=\u001B[39m \u001B[43murllib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhttp://localhost:4040/api/tunnels\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mread()\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf8\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      5\u001B[0m spark_ui_url \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(ngrok_tunnels)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtunnels\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpublic_url\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSpark UI:\u001B[39m\u001B[38;5;124m\"\u001B[39m, spark_ui_url)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:216\u001B[0m, in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    215\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[0;32m--> 216\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopener\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:519\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    516\u001B[0m     req \u001B[38;5;241m=\u001B[39m meth(req)\n\u001B[1;32m    518\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murllib.Request\u001B[39m\u001B[38;5;124m'\u001B[39m, req\u001B[38;5;241m.\u001B[39mfull_url, req\u001B[38;5;241m.\u001B[39mdata, req\u001B[38;5;241m.\u001B[39mheaders, req\u001B[38;5;241m.\u001B[39mget_method())\n\u001B[0;32m--> 519\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[38;5;66;03m# post-process response\u001B[39;00m\n\u001B[1;32m    522\u001B[0m meth_name \u001B[38;5;241m=\u001B[39m protocol\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_response\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:536\u001B[0m, in \u001B[0;36mOpenerDirector._open\u001B[0;34m(self, req, data)\u001B[0m\n\u001B[1;32m    533\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m    535\u001B[0m protocol \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mtype\n\u001B[0;32m--> 536\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_open\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\n\u001B[1;32m    537\u001B[0m \u001B[43m                          \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_open\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n\u001B[1;32m    539\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:496\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers:\n\u001B[1;32m    495\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[0;32m--> 496\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    498\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1377\u001B[0m, in \u001B[0;36mHTTPHandler.http_open\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m   1376\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttp_open\u001B[39m(\u001B[38;5;28mself\u001B[39m, req):\n\u001B[0;32m-> 1377\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhttp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mHTTPConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1351\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1348\u001B[0m         h\u001B[38;5;241m.\u001B[39mrequest(req\u001B[38;5;241m.\u001B[39mget_method(), req\u001B[38;5;241m.\u001B[39mselector, req\u001B[38;5;241m.\u001B[39mdata, headers,\n\u001B[1;32m   1349\u001B[0m                   encode_chunked\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39mhas_header(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransfer-encoding\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n\u001B[0;32m-> 1351\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m URLError(err)\n\u001B[1;32m   1352\u001B[0m     r \u001B[38;5;241m=\u001B[39m h\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m   1353\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n",
      "\u001B[0;31mURLError\u001B[0m: <urlopen error [Errno 61] Connection refused>"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib\n",
    "\n",
    "ngrok_tunnels = urllib.request.urlopen('http://localhost:4040/api/tunnels').read().decode('utf8')\n",
    "spark_ui_url = json.loads(ngrok_tunnels)['tunnels'][0]['public_url']\n",
    "print(\"Spark UI:\", spark_ui_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSX0QbniXqdR"
   },
   "source": [
    "## Other Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vb4tXmFUWMVr",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:07.080850Z",
     "start_time": "2024-01-30T15:18:06.451571Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import urllib.request as req\n",
    "import zipfile\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from fractions import Fraction\n",
    "from decimal import Decimal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', size=18)\n",
    "plt.rc('axes', titlesize=18)\n",
    "plt.rc('axes', labelsize=18)\n",
    "plt.rc('xtick', labelsize=18)\n",
    "plt.rc('ytick', labelsize=18)\n",
    "plt.rc('legend', fontsize=18)\n",
    "plt.rc('lines', markersize=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:07.086225Z",
     "start_time": "2024-01-30T15:18:07.082600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFUvUg2ufEkJ"
   },
   "source": [
    "# Part A - Dataset (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGC6YNJm8wh2"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "r_d9HFUnfPYY",
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:09.726849Z",
     "start_time": "2024-01-30T15:18:09.711131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"url = 'http://files.grouplens.org/datasets/movielens/ml-20m.zip'\\nfilehandle, _ = req.urlretrieve(url)\\nzip_file_object = zipfile.ZipFile(filehandle, 'r')\\nzip_file_object.namelist()\\nzip_file_object.extractall()\""
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"url = 'http://files.grouplens.org/datasets/movielens/ml-20m.zip'\n",
    "filehandle, _ = req.urlretrieve(url)\n",
    "zip_file_object = zipfile.ZipFile(filehandle, 'r')\n",
    "zip_file_object.namelist()\n",
    "zip_file_object.extractall()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3lK0389fXkK",
    "outputId": "6799d146-b413-49bd-bc75-07ec85377e8b",
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:09.981341Z",
     "start_time": "2024-01-30T15:18:09.853725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-20m/links.csv\r\n",
      "ml-20m/sampled_ratings.csv/.part-00003-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv.crc\r\n",
      "ml-20m/sampled_ratings.csv/part-00005-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv\r\n",
      "ml-20m/sampled_ratings.csv/.part-00002-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv.crc\r\n",
      "ml-20m/sampled_ratings.csv/.part-00000-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv.crc\r\n",
      "ml-20m/sampled_ratings.csv/part-00004-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv\r\n",
      "ml-20m/sampled_ratings.csv/.part-00001-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv.crc\r\n",
      "ml-20m/sampled_ratings.csv/part-00007-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv\r\n",
      "ml-20m/sampled_ratings.csv/._SUCCESS.crc\r\n",
      "ml-20m/sampled_ratings.csv/part-00006-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv\r\n",
      "ml-20m/sampled_ratings.csv/part-00001-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv\r\n",
      "ml-20m/sampled_ratings.csv/part-00000-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv\r\n",
      "ml-20m/sampled_ratings.csv/_SUCCESS\r\n",
      "ml-20m/sampled_ratings.csv/.part-00006-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv.crc\r\n",
      "ml-20m/sampled_ratings.csv/.part-00007-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv.crc\r\n",
      "ml-20m/sampled_ratings.csv/part-00003-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv\r\n",
      "ml-20m/sampled_ratings.csv/.part-00005-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv.crc\r\n",
      "ml-20m/sampled_ratings.csv/part-00002-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv\r\n",
      "ml-20m/sampled_ratings.csv/.part-00004-82bd994d-3d41-456b-9762-a7f580b3b806-c000.csv.crc\r\n",
      "ml-20m/ratings.parquet/.part-00001-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet.crc\r\n",
      "ml-20m/ratings.parquet/part-00007-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet\r\n",
      "ml-20m/ratings.parquet/part-00000-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet\r\n",
      "ml-20m/ratings.parquet/.part-00002-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet.crc\r\n",
      "ml-20m/ratings.parquet/._SUCCESS.crc\r\n",
      "ml-20m/ratings.parquet/part-00001-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet\r\n",
      "ml-20m/ratings.parquet/.part-00006-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet.crc\r\n",
      "ml-20m/ratings.parquet/.part-00005-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet.crc\r\n",
      "ml-20m/ratings.parquet/part-00006-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet\r\n",
      "ml-20m/ratings.parquet/part-00003-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet\r\n",
      "ml-20m/ratings.parquet/.part-00000-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet.crc\r\n",
      "ml-20m/ratings.parquet/part-00004-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet\r\n",
      "ml-20m/ratings.parquet/.part-00003-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet.crc\r\n",
      "ml-20m/ratings.parquet/_SUCCESS\r\n",
      "ml-20m/ratings.parquet/part-00005-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet\r\n",
      "ml-20m/ratings.parquet/.part-00007-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet.crc\r\n",
      "ml-20m/ratings.parquet/.part-00004-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet.crc\r\n",
      "ml-20m/ratings.parquet/part-00002-45d7ae19-5960-48bd-982d-055f585da497-c000.snappy.parquet\r\n",
      "ml-20m/movies-sample.csv/._SUCCESS.crc\r\n",
      "ml-20m/movies-sample.csv/part-00000-3237605d-3afd-4ccb-a1a0-2dfbb6bbee51-c000.csv\r\n",
      "ml-20m/movies-sample.csv/_SUCCESS\r\n",
      "ml-20m/movies-sample.csv/.part-00000-3237605d-3afd-4ccb-a1a0-2dfbb6bbee51-c000.csv.crc\r\n",
      "ml-20m/tags.csv\r\n",
      "ml-20m/genome-tags.csv\r\n",
      "ml-20m/ratings.csv\r\n",
      "ml-20m/README.txt\r\n",
      "ml-20m/genome-scores.csv\r\n",
      "ml-20m/movies.csv\r\n"
     ]
    }
   ],
   "source": [
    "!find ml-20m -type f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Uwruo0oIfaop",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:10.088076Z",
     "start_time": "2024-01-30T15:18:10.060645Z"
    }
   },
   "outputs": [],
   "source": [
    "movies_path = \"ml-20m/movies.csv\"\n",
    "ratings_path = \"ml-20m/ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hWQSjOtYWMVx",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:17.710821Z",
     "start_time": "2024-01-30T15:18:10.220914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings_df_csv = spark.read.options(header=True, inferSchema=True).csv(ratings_path)\n",
    "movies_df_csv = spark.read.options(header=True, inferSchema=True).csv(movies_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1M21UsEBv5Up",
    "outputId": "3ed86c02-39e1-4d19-fea9-211c80f6d4c9",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:17.734857Z",
     "start_time": "2024-01-30T15:18:17.711834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y39-SiqZv9hu",
    "outputId": "3fc2191b-389b-4695-dddd-dc1c85282188",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:17.737063Z",
     "start_time": "2024-01-30T15:18:17.726482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtR77Ttq8zT-"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "> In the following sections, we will work with algorithms that may scale more or less well with the size of the dataset. In this section we will develop several functions that will allow you to sample the dataset. Then in the next part of the notebook, it will be up to you to choose which tools you want to apply to your dataset in order to train your models, knowing that we want to have reasonable processing times (in the order of a minute), while having models that 'work' well.\n",
    ">\n",
    "> **Test all the functions that process the dataframe on a toy example, like what is done in first data processing question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1zW1MHjDZnu"
   },
   "source": [
    "### Question A1\n",
    "\n",
    ">Write the *ratings_df_csv* and *movies_df_csv* DataFrame in a compressed parquet format.\n",
    ">\n",
    ">Reload them from parquet, to make next computations faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:49.754662Z",
     "start_time": "2024-01-30T15:18:42.048105Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/30 16:18:42 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings_df_csv.write.parquet(\"ratings.parquet\", compression=\"gzip\")\n",
    "movies_df_csv.write.parquet(\"movies.parquet\", compression=\"gzip\")\n",
    "\n",
    "ratings_df = spark.read.parquet(\"ratings.parquet\")\n",
    "movies_df = spark.read.parquet(\"movies.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stqYh6SJGTCa"
   },
   "source": [
    "### Question A2\n",
    "\n",
    "> Compute an estimation of the whole *ratings_df* dataset size in memory.\n",
    ">\n",
    ">Find the amount of partitions used by *ratings_df*.\n",
    ">\n",
    ">We try to have partitions not too big (in order not to crash our executors), and not to small (dealing with too many small partitions can lead to issues, on driver side for example). For this reason, a rule of thumb to have partitions of 128MB is okay. Given this, what do you think of the dataframe? Is the amount of partitions okay? Or should we repartition it? What would be the function to use if we need to repartition the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:49.826631Z",
     "start_time": "2024-01-30T15:18:49.749394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IESUqOGp_rDf"
   },
   "source": [
    "### Question A3\n",
    "\n",
    ">Create a function named *remove_bad_ratings* that takes a rating dataframe as an argument, and returns a dataframe whose ratings are greater or equals to a rating_threshold, with default value of *3.5*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:49.830085Z",
     "start_time": "2024-01-30T15:18:49.814053Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_bad_ratings(ratings_df, rating_threshold=3.5):\n",
    "    return ratings_df.filter(ratings_df.rating >= rating_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      2|   3.5|1112486027|\n",
      "|     1|     29|   3.5|1112484676|\n",
      "|     1|     32|   3.5|1112484819|\n",
      "|     1|     47|   3.5|1112484727|\n",
      "|     1|     50|   3.5|1112484580|\n",
      "|     1|    112|   3.5|1094785740|\n",
      "|     1|    151|   4.0|1094785734|\n",
      "|     1|    223|   4.0|1112485573|\n",
      "|     1|    253|   4.0|1112484940|\n",
      "|     1|    260|   4.0|1112484826|\n",
      "|     1|    293|   4.0|1112484703|\n",
      "|     1|    296|   4.0|1112484767|\n",
      "|     1|    318|   4.0|1112484798|\n",
      "|     1|    337|   3.5|1094785709|\n",
      "|     1|    367|   3.5|1112485980|\n",
      "|     1|    541|   4.0|1112484603|\n",
      "|     1|    589|   3.5|1112485557|\n",
      "|     1|    593|   3.5|1112484661|\n",
      "|     1|    919|   3.5|1094785621|\n",
      "|     1|    924|   3.5|1094785598|\n",
      "+------+-------+------+----------+\n"
     ]
    }
   ],
   "source": [
    "ratings_removed_bad_ratings = remove_bad_ratings(ratings_df)\n",
    "ratings_removed_bad_ratings.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:50.045943Z",
     "start_time": "2024-01-30T15:18:49.817871Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMKLPBXaI0TA"
   },
   "source": [
    "### Question A4\n",
    "\n",
    ">Create a function named *sample_users* that takes a rating dataframe as an argument, and returns a dataframe with only a *ratio* of users (we want to keep all ratings from users that we keep) ; default value of *ratio* parameter is *0.1*. Function should be deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:50.147997Z",
     "start_time": "2024-01-30T15:18:50.035661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    223|   4.0|1112485573|\n",
      "|     1|    589|   3.5|1112485557|\n",
      "|     1|    653|   3.0|1094785691|\n",
      "|     1|   1291|   3.5|1112485525|\n",
      "|     1|   1374|   4.0|1094785746|\n",
      "|     1|   1848|   3.5|1112486032|\n",
      "|     1|   1994|   3.5|1094786087|\n",
      "|     1|   2140|   4.0|1112485705|\n",
      "|     1|   2288|   4.0|1094786077|\n",
      "|     1|   2716|   3.5|1094786012|\n",
      "|     1|   2762|   4.0|1112485367|\n",
      "|     1|   3265|   3.5|1112484525|\n",
      "|     1|   3476|   3.5|1094786139|\n",
      "|     1|   3479|   4.0|1112485734|\n",
      "|     1|   3889|   4.0|1112486138|\n",
      "|     1|   4571|   4.0|1112485880|\n",
      "|     1|   4915|   3.0|1112486076|\n",
      "|     1|   5679|   3.5|1094786108|\n",
      "|     1|   5898|   3.5|1112486002|\n",
      "|     2|      3|   4.0| 974820889|\n",
      "+------+-------+------+----------+\n"
     ]
    }
   ],
   "source": [
    "def sample_users(ratings_df, ratio=0.1):\n",
    "    return ratings_df.sample(False, ratio, seed=42)\n",
    "\n",
    "\n",
    "ratings_sampled_users = sample_users(ratings_df)\n",
    "ratings_sampled_users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJV6UbAiLGiv"
   },
   "source": [
    "### Question A5\n",
    "\n",
    "> Create a function named *remove_exotic_movies*, taking a rating dataframe as argument, and that removes all movies which have less than *nb_min_ratings* ; *nb_min_ratings* parameter has a default value of *1000*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:53.053444Z",
     "start_time": "2024-01-30T15:18:50.132264Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+------+----------+\n",
      "|movieId|count|userId|rating| timestamp|\n",
      "+-------+-----+------+------+----------+\n",
      "|   3997| 2047|     1|   3.5|1112486192|\n",
      "|   1580|35580|     2|   4.0| 974820748|\n",
      "|   3918| 1246|     2|   3.0| 974820943|\n",
      "|   2366| 6627|     3|   4.0| 944918310|\n",
      "|   1580|35580|     7|   3.0|1011206832|\n",
      "|   3175|13945|     7|   2.0|1011206805|\n",
      "|   4519| 1936|     9|   2.0| 994019800|\n",
      "|   1580|35580|    11|   5.0|1230788734|\n",
      "|   1591| 5255|    11|   5.0|1230782724|\n",
      "|    471|11268|    14|   5.0|1225308771|\n",
      "|   1580|35580|    14|   3.5|1225319912|\n",
      "|   3175|13945|    14|   4.5|1225320332|\n",
      "|  36525| 1169|    14|   4.5|1225311849|\n",
      "|  44022| 2465|    14|   4.0|1225310443|\n",
      "|   1580|35580|    16|   4.0| 990970213|\n",
      "|   1580|35580|    17|   4.0| 979686312|\n",
      "|   1580|35580|    18|   2.5|1236356556|\n",
      "|   2866| 1407|    21|   3.0| 992188523|\n",
      "|   1580|35580|    22|   3.0| 994638608|\n",
      "|   1580|35580|    23|   5.0| 914458526|\n",
      "+-------+-----+------+------+----------+\n"
     ]
    }
   ],
   "source": [
    "def remove_exotic_movies(ratings_df, nb_min_ratings=1000):\n",
    "    return ratings_df.groupBy(\"movieId\").count().filter(F.col(\"count\") >= nb_min_ratings).join(ratings_df, \"movieId\",\n",
    "                                                                                               \"inner\")\n",
    "\n",
    "\n",
    "ratings_removed_exotic_movies = remove_exotic_movies(ratings_df)\n",
    "ratings_removed_exotic_movies.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTKUFM95pAwP"
   },
   "source": [
    "### Question A6\n",
    "\n",
    "> Compute the following stats on the dataset:\n",
    "> - Amount of distinct users\n",
    "> - Amount of distinct movies\n",
    "> - Total amount of ratings\n",
    "> - Let r_u be the amount of ratings made by user u. Study the distribution of r_u over all users (quantiles, histogram...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:55.562341Z",
     "start_time": "2024-01-30T15:18:53.047130Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+-------------+\n",
      "|distinct_users|distinct_movies|total_ratings|\n",
      "+--------------+---------------+-------------+\n",
      "|        138493|          26744|     20000263|\n",
      "+--------------+---------------+-------------+\n",
      "+----------+----------+-----------------+------------------+\n",
      "|min(count)|max(count)|       avg(count)|     stddev(count)|\n",
      "+----------+----------+-----------------+------------------+\n",
      "|        20|      9254|144.4135299257002|230.26725699673392|\n",
      "+----------+----------+-----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "ratings_df.agg(F.countDistinct(\"userId\").alias(\"distinct_users\"),\n",
    "               F.countDistinct(\"movieId\").alias(\"distinct_movies\"),\n",
    "               F.count(\"*\").alias(\"total_ratings\")).show()\n",
    "\n",
    "ratings_df.groupBy(\"userId\").count().agg(F.min(\"count\"), F.max(\"count\"), F.avg(\"count\"), F.stddev(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[<Axes: title={'center': 'count'}>]], dtype=object)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 600x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings_df.groupBy(\"userId\").count().toPandas().hist(\"count\", bins=100, figsize=(6, 6), log=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T15:18:58.303102Z",
     "start_time": "2024-01-30T15:18:56.689193Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFjZb6tFmEPt"
   },
   "source": [
    "### Question A7\n",
    "\n",
    "> Create a function named *remove_old_movies_in_timelines*, that takes a ratings dataframe as parameter, and only keeps the *nb_max_movies* most recent movies seen by each user ; *nb_max_movies* parameter is defaulted at 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T15:19:03.355052Z",
     "start_time": "2024-01-30T15:18:58.299662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|    12|    231|   3.0|859064063|\n",
      "|    12|    110|   4.0|859064062|\n",
      "|    12|    364|   4.0|859064062|\n",
      "|    12|    480|   3.0|859064062|\n",
      "|    12|    527|   4.0|859064062|\n",
      "|    12|    585|   3.0|859064062|\n",
      "|    12|    595|   4.0|859064062|\n",
      "|    12|    356|   4.0|859064001|\n",
      "|    12|    208|   3.0|859064000|\n",
      "|    12|    590|   3.0|859063999|\n",
      "|    12|    589|   4.0|859063998|\n",
      "|    12|     34|   4.0|859063997|\n",
      "|    12|    344|   4.0|859063995|\n",
      "|    12|    380|   4.0|859063994|\n",
      "|    12|    104|   4.0|859063825|\n",
      "|    12|    260|   4.0|859063825|\n",
      "|    12|    376|   3.0|859063825|\n",
      "|    12|    653|   4.0|859063825|\n",
      "|    12|    784|   4.0|859063825|\n",
      "|    12|    788|   4.0|859063825|\n",
      "+------+-------+------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def remove_old_movies_in_timelines(ratings_df, nb_max_movies=100):\n",
    "    window = Window.partitionBy(\"userId\").orderBy(F.desc(\"timestamp\"))\n",
    "    return ratings_df.withColumn(\"rank\", F.rank().over(window)).filter(F.col(\"rank\") <= nb_max_movies).drop(\"rank\")\n",
    "\n",
    "\n",
    "ratings_removed_old_movies_in_timelines = remove_old_movies_in_timelines(ratings_df)\n",
    "ratings_removed_old_movies_in_timelines.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTveqlrl_T8u"
   },
   "source": [
    "# Part B - Association Rules (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fukr5HVii2BG"
   },
   "source": [
    "## Naive: Recurring pairs\n",
    "\n",
    "> This approach is simple and not efficient but gives you a baseline and intuition for the next steps.\n",
    ">\n",
    "> Morally, what we want to do is:\n",
    "> - for each user, regroup all the movies they have liked inside a single row. We will call this the 'user timeline'\n",
    "> - for each user, generate all pairs of movies across their list of movies.\n",
    "> - for each pair of movies, count the amount of distinct users with this pair.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKvQ69TpwF_N"
   },
   "source": [
    "### Question B1\n",
    "\n",
    "> Create a function named *compute_timeline*, that takes a ratings dataframe as parameter, and returns the 'user timeline', a dataframe following this schema:\n",
    "> - userId : integer\n",
    "> - movies : list[integer] (list of movieId seen by user)\n",
    ">\n",
    "> Test it on a toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:18:18.080306Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_timeline(ratings_df):\n",
    "    return ratings_df.groupBy(\"userId\").agg(F.collect_list(\"movieId\").alias(\"movies\"))\n",
    "\n",
    "\n",
    "compute_timeline(ratings_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGO98KnLxKpe"
   },
   "source": [
    "### Question B2\n",
    "\n",
    "> Let's imagine that all of our executors have 4GB of memory. If we consider the 'user timeline' dataset where movie ratings are greater or equal than 3.5, is it okay to store list of movie ids inside rows, as far as memory is concerned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:18:18.081301Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_timeline(remove_bad_ratings(ratings_df)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rSlT9Rd3w23"
   },
   "source": [
    "### Question B3\n",
    "\n",
    "> Create a function named *compute_pairs*, that takes a user timeline dataframe as parameter, and returns a dataframe of movie pairs (generated across all movies of their timeline) following this schema:\n",
    "> - userId : integer\n",
    "> - movieId1 : integer\n",
    "> - movieId2 : integer\n",
    ">\n",
    "> You can rely on an udf to generate list of pair of movies from a list of movies.\n",
    "> \n",
    "> Test it on a toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:18:18.082329Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_pairs(timeline_df):\n",
    "    return timeline_df.withColumn(\"movies\", F.explode(\"movies\")).withColumnRenamed(\"movies\", \"movieId1\").join(\n",
    "        timeline_df.withColumn(\"movies\", F.explode(\"movies\")).withColumnRenamed(\"movies\", \"movieId2\"), \"userId\",\n",
    "        \"inner\").filter(F.col(\"movieId1\") < F.col(\"movieId2\"))\n",
    "\n",
    "\n",
    "compute_pairs(compute_timeline(ratings_df)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PD-P_FNL8yEk"
   },
   "source": [
    "### Question B4\n",
    "\n",
    "> Let's imagine that all of our executors have 4GB of memory. \n",
    "> \n",
    "> If we consider If we consider the 'user timeline where movie ratings are greater or equal than 3.5, what will happen when we generate pairs dataframe for this dataset ?\n",
    "> \n",
    "> You need to consider:\n",
    "> - amount of bytes retained by lists of pairs\n",
    "> - amount of partitions we have in user timeline\n",
    ">\n",
    "> Also, consider what may happen because of skew. We may have all big user timelines inside same partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Amount of bytes retained by lists of pairs\n",
    "print(\n",
    "    f'Amount of bytes retained by lists of pairs: {compute_pairs(compute_timeline(remove_bad_ratings(ratings_df))).rdd.map(lambda x: sys.getsizeof(x[1])).sum() / 1024 ** 3:.2f} GB')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-30T15:18:18.083290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Amount of partitions we have in user timeline\n",
    "print(\n",
    "    f'Amount of partitions we have in user timeline: {compute_timeline(remove_bad_ratings(ratings_df)).rdd.getNumPartitions()}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-30T15:18:18.084435Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YhKxZd6BdWx"
   },
   "source": [
    "\n",
    "### Question B5\n",
    "\n",
    "> Create a function named *compute_pair_frequencies*, that takes a movie pair dataframe as parameter, and returns a dataframe of movie pairs and their user count, following this schema:\n",
    "> - movieId1 : integer\n",
    "> - movieId2 : integer\n",
    "> - count : integer\n",
    "> \n",
    "> Dataframe should be **ordered**, with most frequent pairs first.\n",
    ">\n",
    "> Test it on a toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:18:18.085791Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_pair_frequencies(pairs_df):\n",
    "    return pairs_df.groupBy(\"movieId1\", \"movieId2\").count().orderBy(F.desc(\"count\"))\n",
    "\n",
    "\n",
    "compute_pair_frequencies(compute_pairs(compute_timeline(ratings_df))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d81d3Thf6DPD"
   },
   "source": [
    "### Question B6\n",
    "\n",
    "> Quickly test the whole algorithm on *ratings_df* or a subset of it.\n",
    "> \n",
    "> How many shuffles for the whole algorithm ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CiZfGfshztLZ",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:18:18.086833Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f'Amount of shuffles: {compute_pair_frequencies(compute_pairs(compute_timeline(remove_bad_ratings(ratings_df)))).rdd.getNumPartitions()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuqp0Y6ky8ed"
   },
   "source": [
    "## A priori\n",
    "\n",
    "> You can find a good description of Apriori algorithm here:  \n",
    "> https://en.wikipedia.org/wiki/Apriori_algorithm\n",
    ">\n",
    "> Some other resources:  \n",
    "> [Apriori — Association Rule Mining In-depth Explanation and Python Implementation](https://towardsdatascience.com/apriori-association-rule-mining-explanation-and-python-implementation-290b42afdfc6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0E8hbjPFLgd"
   },
   "source": [
    "### Question B7\n",
    "\n",
    "> Implement your own version of A priori to compute most frequent pairs and quickly test it on *ratings_df* or a subset of it.\n",
    "> \n",
    "> You may want to rely on *F.explode* as an alternative to udf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.219512Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYjT4dDVFSGv"
   },
   "source": [
    "### Question B8\n",
    "\n",
    "> Implement your own version of A priori to compute most frequent triplets.\n",
    "> \n",
    "> A this stage of the 'A priori' section, you are probably doing the same thing multiple times. \n",
    "> \n",
    "> Maybe it's time to factorize your code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.220813Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRUB_yQA7I-m"
   },
   "source": [
    "## 3. FP-Growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can find a good description of FP-Growth algorithm with Spark here:  \n",
    "> https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html\n",
    ">\n",
    "> Some other resources:  \n",
    "[FP Growth — Frequent Pattern Generation in Data Mining with Python Implementation](https://towardsdatascience.com/fp-growth-frequent-pattern-generation-in-data-mining-with-python-implementation-244e561ab1c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a5CJmMyFW9Q"
   },
   "source": [
    "### Question B9\n",
    "\n",
    "> Use the Spark version of FP-Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.221980Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj1HcZkRGRRs"
   },
   "source": [
    "# Part C - Probabilistic Latent Semantic Model (5 points)\n",
    "\n",
    "> Aim of this section is to implement a Probabilistic Latent Semantic Model.\n",
    "> \n",
    "> We will use an expectation maximization algorithm to learn its parameters.\n",
    ">\n",
    "> In the first set of questions you will implement some utility functions to deal with matrix manipulations.\n",
    ">\n",
    "> In the second set of questions, you will implement the algorithm itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "papRtCuWJxho"
   },
   "source": [
    "## Matrix manipulation functions\n",
    "\n",
    "> We will implement matrix operations that will be usefull to run the PLSI algorithm afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtRkYH9NC-RO"
   },
   "source": [
    "### Question CMatrix1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzVkNoL4KQ0L"
   },
   "source": [
    "#### `matrix_sum_rows` \n",
    "\n",
    "> Takes a matrix (a column containing arrays of fixed length) and returns the sum of each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "P1VyUs79KUeg",
    "ExecuteTime": {
     "end_time": "2024-01-30T15:19:10.900819Z",
     "start_time": "2024-01-30T15:19:09.326032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input array\n",
      "[[ 1.  2.  3.  4.]\n",
      " [40. 30. 20. 10.]]\n",
      "Expected output\n",
      "[ 10. 100.]\n",
      "Obtained output\n",
      "+------------------------+-------+\n",
      "|matrix                  |row_sum|\n",
      "+------------------------+-------+\n",
      "|[1.0, 2.0, 3.0, 4.0]    |10.0   |\n",
      "|[40.0, 30.0, 20.0, 10.0]|100.0  |\n",
      "+------------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "# Hint: https://stackoverflow.com/a/57448698/2015762\n",
    "from prettytable import PrettyTable\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "\n",
    "def matrix_sum_rows(col_name, length_of_array):\n",
    "    cols = [F.col(col_name)[i] for i in range(length_of_array)]\n",
    "    return F.udf(lambda *xs: float(sum(xs)), FloatType())(*cols)\n",
    "\n",
    "\n",
    "input_array = np.array([[1, 2, 3, 4], [40, 30, 20, 10]], dtype=float)\n",
    "expected_output = input_array.sum(axis=1)\n",
    "print('Input array')\n",
    "print(input_array)\n",
    "print('Expected output')\n",
    "print(expected_output)\n",
    "print('Obtained output')\n",
    "(\n",
    "    spark.sparkContext.parallelize(input_array.tolist()).map(lambda x: Row(matrix=x)).toDF()\n",
    "    .withColumn('row_sum', matrix_sum_rows('matrix', 4))\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRczikuRIiwH"
   },
   "source": [
    "### Question CMatrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFJwS3HAKYDj",
    "tags": []
   },
   "source": [
    "#### `matrix_sum_columns`\n",
    "\n",
    "> Takes a matrix (a column containing arrays of fixed length) and returns the sum of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "df36LGTSKclE",
    "ExecuteTime": {
     "end_time": "2024-01-30T15:32:16.852358Z",
     "start_time": "2024-01-30T15:32:16.570687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input array\n",
      "[[ 1.  2.  3.  4.]\n",
      " [40. 30. 20. 10.]]\n",
      "Expected output\n",
      "[41. 32. 23. 14.]\n",
      "Obtained output\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'alias'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 18\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(expected_output)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mObtained output\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     16\u001B[0m (\n\u001B[1;32m     17\u001B[0m     spark\u001B[38;5;241m.\u001B[39msparkContext\u001B[38;5;241m.\u001B[39mparallelize(input_array\u001B[38;5;241m.\u001B[39mtolist())\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: Row(matrix\u001B[38;5;241m=\u001B[39mx))\u001B[38;5;241m.\u001B[39mtoDF()\n\u001B[0;32m---> 18\u001B[0m     \u001B[38;5;241m.\u001B[39mselect(\u001B[43mmatrix_sum_columns\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmatrix\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malias\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcol_sum\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     19\u001B[0m )\u001B[38;5;241m.\u001B[39mshow(truncate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'alias'"
     ]
    }
   ],
   "source": [
    "# Hint: https://stackoverflow.com/a/54382990/2015762\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "\n",
    "\n",
    "def matrix_sum_columns(col_name, length_of_array):\n",
    "    pass\n",
    "\n",
    "\n",
    "input_array = np.array([[1, 2, 3, 4], [40, 30, 20, 10]], dtype=float)\n",
    "expected_output = input_array.sum(axis=0)\n",
    "print('Input array')\n",
    "print(input_array)\n",
    "print('Expected output')\n",
    "print(expected_output)\n",
    "print('Obtained output')\n",
    "(\n",
    "    spark.sparkContext.parallelize(input_array.tolist()).map(lambda x: Row(matrix=x)).toDF()\n",
    "    .select(matrix_sum_columns('matrix', 4).alias('col_sum'))\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47EAeV3_IqpH"
   },
   "source": [
    "### Question CMatrix3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCWm2vK4KhES"
   },
   "source": [
    "#### `matrix_normalize_rows`\n",
    "\n",
    "> Takes a matrix (a column containing arrays of fixed length) and returns the same matrix where the rows have been divded by their sum, such that each row sums to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsNhEtSuKZBI",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.225218Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_normalize_rows(col_name, length_of_array):\n",
    "\n",
    "\n",
    "input_array = np.array([[1, 2, 3, 4], [40, 30, 20, 10]], dtype=float)\n",
    "expected_output = input_array / input_array.sum(axis=1).reshape(-1, 1)\n",
    "print('Input array')\n",
    "print(input_array)\n",
    "print('Expected output')\n",
    "print(expected_output)\n",
    "print('Obtained output')\n",
    "(\n",
    "    spark.sparkContext.parallelize(input_array.tolist()).map(lambda x: Row(numbers=x)).toDF()\n",
    "    .withColumn('normalized_elements', matrix_normalize_rows('numbers', 4))\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdOIy3UaIu9P"
   },
   "source": [
    "### Question CMatrix4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPWSuJVkKkoS"
   },
   "source": [
    "#### `matrix_elementwise_product`\n",
    "\n",
    "> Takes two matrices and return their elementwise product (aka. Hadamard product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EHBDsfzKovu",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.226322Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_elementwise_product(col_name_1, col_name_2, length_of_array):\n",
    "\n",
    "\n",
    "input_array_1 = np.array([[1, 2, 3, 4], [40, 30, 20, 10]], dtype=float)\n",
    "input_array_2 = np.array([[1, 2, 1, 2], [10, 20, 10, 20]], dtype=float)\n",
    "expected_output = input_array_1 * input_array_2\n",
    "print('Input array')\n",
    "print(input_array_1)\n",
    "print(input_array_2)\n",
    "print('Expected output')\n",
    "print(expected_output)\n",
    "print('Obtained output')\n",
    "(\n",
    "    spark.sparkContext.parallelize(zip(input_array.tolist(), input_array_2.tolist())).map(\n",
    "        lambda x: Row(numbers_1=x[0], numbers_2=x[1])).toDF()\n",
    "    .withColumn('elementwise_products', matrix_elementwise_product('numbers_1', 'numbers_2', 4))\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G7umlGqIx0F"
   },
   "source": [
    "### Question CMatrix5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLayzlbbKvS2"
   },
   "source": [
    "#### `matrix_elementwise_divide`\n",
    "\n",
    "> Takes two matrices and divide elementwise the first one by the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZ2Mhzj9KwT6",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.227546Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_elementwise_divide(col_name_1, col_name_2, length_of_array):\n",
    "\n",
    "\n",
    "input_array_1 = np.array([[1, 2, 3, 4], [40, 30, 20, 10]], dtype=float)\n",
    "input_array_2 = np.array([[1, 2, 1, 2], [10, 20, 10, 20]], dtype=float)\n",
    "expected_output = input_array_1 / input_array_2\n",
    "print('Input array')\n",
    "print(input_array_1)\n",
    "print(input_array_2)\n",
    "print('Expected output')\n",
    "print(expected_output)\n",
    "print('Obtained output')\n",
    "(\n",
    "    spark.sparkContext.parallelize(zip(input_array.tolist(), input_array_2.tolist())).map(\n",
    "        lambda x: Row(numbers_1=x[0], numbers_2=x[1])).toDF()\n",
    "    .withColumn('elementwise_divided', matrix_elementwise_divide('numbers_1', 'numbers_2', 4))\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwbYk4FxJ4oF"
   },
   "source": [
    "## PLSI\n",
    "\n",
    "> With\n",
    "> * N the number of users u\n",
    "> * M the number of movies s\n",
    "> * L the number of latent classes z\n",
    "> * T number of (user, movie) interactions (each interaction (s_t, u_t) means user u_t liked movie s_t)\n",
    ">\n",
    ">We suppose that the probability that a user will like a movie can be written in the form of a mixture model given by the equation:\n",
    "$$\n",
    "p(s|u) = \\sum_{z=1}^L p(s|z) p(z|u)\n",
    "$$\n",
    "And we want to optimize the likelihood of the observed user interactions\n",
    "$$\n",
    "L = - \\frac{1}{T} \\sum_{1}^{T} \\log p(s_t|u_t) = - \\frac{1}{T} \\sum_{1}^{T} \\sum_{z=1}^L p(s_t|z) p(z|u_t)\n",
    "$$\n",
    "That can be done using an EM algorithm working as follow:\n",
    ">\n",
    ">**E step**\n",
    ">\n",
    ">For each interaction (u_t, s_t), compute for all z = 1, ..., L:\n",
    "$$\n",
    "p(z|(u_t, s_t)) = \\frac{p(s_t|z) p(z|u_t)}{\\sum_z p(s_t|z) p(z|u_t)}\n",
    "$$\n",
    ">\n",
    ">**M step**\n",
    ">\n",
    ">Find each movie probability given a latent class\n",
    "$$\n",
    "p(s|z) = \\frac{N(z, s)}{N(z)} \n",
    "\\quad \\text{where} \\quad N(z, s) = \\sum_s \\sum_u p(z|(u, s)) \n",
    "\\quad \\text{and} \\quad N(z) = \\sum_s N(z, s)\n",
    "$$\n",
    "Find each latent class probability given each user.\n",
    "$$\n",
    "p(z|u) = \\frac{\\sum_s p(z|(u, s))}{\\sum_z \\sum_s p(z|(u, s))}\n",
    "$$\n",
    ">\n",
    ">We will have the following dataframes\n",
    ">\n",
    ">* `count_z_s`: M rows, with columns  `movieId`, `N(z,s)`.\n",
    ">* `count_z`: 1 row, with column `N(z)`.\n",
    ">* `p_s_knowing_z`: M rows, with columns  `movieId`, `p(s|z)`. For a given z, the sum of p(s|z) equals 1.\n",
    ">* `p_z_knowing_u`: N rows, with columns `userId`, `p(z|u)`. For a given u, the sum of p(z|u) equals 1.\n",
    ">* `p_z_knowing_u_and_s`: N x M rows, with columns `userId`, `movieId`, `p(z|u,s)`.\n",
    ">\n",
    "> \n",
    "> Implement the PLSI algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question CPLSI1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDGcbe41LwPV",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.228558Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_count_z(count_z_s, n_latent_classes):\n",
    "    \"\"\"Compute N(z) = sum_s N(z,s)\n",
    "    \"\"\"\n",
    "    # ...\n",
    "    pass\n",
    "\n",
    "\n",
    "count_z_s = ss.sparkContext.parallelize([\n",
    "    st.Row(**{\"movieId\": 1, \"N(z,s)\": [1., 3., 4.]}),\n",
    "    st.Row(**{\"movieId\": 2, \"N(z,s)\": [4., 5., 0.]}),\n",
    "]).toDF()\n",
    "get_count_z(count_z_s, 3).show()\n",
    "# Expected [5., 8., 4.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question CPLSI1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyftz13QLyez",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.229472Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_count_z_s(p_z_knowing_u_and_s, n_latent_classes):\n",
    "    \"\"\"Compute N(z,s) = sum_u p(z|u,s)\n",
    "    \"\"\"\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question CPLSI1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-hhH_jgLzaN",
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.230501Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_p_s_knowing_z(count_z_s, count_z, n_latent_classes):\n",
    "    \"\"\"Compute p(s|z) = N(z,s) / N(z)\n",
    "    \n",
    "    Hint: crossJoin may help\n",
    "    \"\"\"\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question CPLSI1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8qlxgcWL2Pc",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.231393Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_p_z_knowing_u(p_z_knowing_u_and_s, n_latent_classes):\n",
    "    \"\"\"Compute p(z|u) = sum_s p(z|u,s) / sum_z sum_s p(z|u,s)\n",
    "    \"\"\"\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question CPLSI1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvjuAPagL49D",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.232303Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_p_z_knowing_u_and_s(observed_pairs, count_z_s, count_z, p_z_knowing_u, n_latent_classes):\n",
    "    \"\"\"For all pairs of observed (u, s)\n",
    "    \n",
    "    Compute p(z|u,s) = [N(z, s) / N(z) * p(z|u)] / sum_z [N(z, s) / N(z) * p(z|u)]\n",
    "                     = [p(s|z) * p(z|u)] / sum_z [p(s|z) * p(z|u)]\n",
    "    \"\"\"\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question CPLSI1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Lb6J5x_L7sj",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.233214Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_likelihood(observed_pairs, count_z_s, count_z, p_z_knowing_u, n_latent_classes):\n",
    "    \"\"\"Compute the log likelihood of the observed pairs\n",
    "    \n",
    "    L = - 1 / T * sum_t log[ p(s|u) ]\n",
    "      = - 1 / T * sum_t log[ sum_z p(s|z) * p(z|u) ]\n",
    "    \"\"\"\n",
    "    # ...\n",
    "\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question CPLSI1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-x-AT8iL-TD",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.234128Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_statistics(observed_pairs, n_latent_classes):\n",
    "    \"\"\"Initialize either p(s|z) and p(z|u) or p(z|(u, s)) to be able to fuel the first iteration of the EM algorithm.\n",
    "    What would happen if you initialize these to a constant value ?\n",
    "    \"\"\"\n",
    "    # ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question CPLSI1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQiwyBZVMAu-",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.235063Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_plsi(observed_pairs, n_iterations, n_latent_classes, checkpoint_every=1):\n",
    "    start_init_time = time.time()\n",
    "    spark.sparkContext.setJobDescription(\"Initialization\")\n",
    "\n",
    "    # ... = initialize_statistics(observed_pairs, n_latent_classes)\n",
    "    llh = log_likelihood(observed_pairs,  # ... #, n_latent_class\n",
    "                         mlflow.log_metric(key=\"llh\", value=llh, step=0)\n",
    "    print(f'LLH: {llh:.10f}')\n",
    "\n",
    "    end_init_time = time.time()\n",
    "    print(f'Initialization: {end_init_time - start_init_time:.1f}s')\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        start_e_step = time.time()\n",
    "    spark.sparkContext.setJobDescription(f\"Iteration {i + 1}: E-step\")\n",
    "    # E step\n",
    "    # ...\n",
    "\n",
    "    end_e_step = time.time()\n",
    "    print(f'Iteration {i + 1}: E-step: {end_e_step - start_e_step:.1f}s')\n",
    "\n",
    "    spark.sparkContext.setJobDescription(f\"Iteration {i + 1}: M-step\")\n",
    "    # M step\n",
    "    # ...\n",
    "\n",
    "    llh = log_likelihood(observed_pairs, count_z_s, count_z, p_z_knowing_u, n_latent_classes)\n",
    "    mlflow.log_metric(key=\"llh\", value=llh, step=i + 1)\n",
    "\n",
    "    end_m_step = time.time()\n",
    "    print(f'Iteration {i + 1}: M-step: {end_m_step - end_e_step:.1f}s')\n",
    "    print(f'LLH: {llh:.10f}')\n",
    "\n",
    "    return get_p_s_knowing_z(count_z_s, count_z, n_latent_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "er6q4Xm5Jj7W",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.236065Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dV0zwPSlJkqk",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.237276Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpBo-j0dMGIs",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.238269Z"
    }
   },
   "outputs": [],
   "source": [
    "n_iterations = 20\n",
    "n_latent_classes = 5\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"n_iterations\", n_iterations)\n",
    "    mlflow.log_param(\"n_latent_classes\", n_latent_classes)\n",
    "    run_plsi(ratings_df.sample(0.1), n_iterations=n_iterations, n_latent_classes=n_latent_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UK3XqiypKREd"
   },
   "source": [
    "### Question CPLSI2.1\n",
    "\n",
    "> How does the EM algorithm is supposed to scale with the number of EM steps ? Do you observe such a scaling ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.239300Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UK3XqiypKREd"
   },
   "source": [
    "### Question CPLSI2.2\n",
    "> If each steap takes longer than the previous one: Try using .cache() wisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.240386Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UK3XqiypKREd"
   },
   "source": [
    "### Question CPLSI2.3\n",
    "\n",
    "> Try to unpersist your dataframes when they become unneeded (look at the Storage tab in the Spark UI) (Optional + 2pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.241417Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UK3XqiypKREd"
   },
   "source": [
    "### Question CPLSI2.4\n",
    "\n",
    "> If after few steps (typically 5), your algorithm starts being much slower and spend more and more time scheduling jobs (look in the Spark UI), try using [.localCheckpoint()](https://spark.apache.org/docs/2.1.0/api/python/pyspark.html#pyspark.RDD.localCheckpoint). How does it differ from caching ? What are the benefits and the drawbacks ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.242645Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbstFMhYnpSk"
   },
   "source": [
    "# Part D - Test them all (5 points)\n",
    "\n",
    "> In this section, we create training and test datasets, and test all the different prediction algorithms described above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "engmZXePsEfv"
   },
   "source": [
    "## Training and Testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIxB2g3QsKGC"
   },
   "source": [
    "### Question D1\n",
    "\n",
    "> Create the training dataset named *training_df*. It is made of raw ratings dataframe, where:\n",
    "> - *hash(userId) % 2 == 0*\n",
    "> - and *rating >= 3.5*\n",
    "> \n",
    "> You should rely on functions written in Part A.\n",
    "> \n",
    "> Persist it on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.243819Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK43OefMszyg"
   },
   "source": [
    "### Question D2\n",
    "\n",
    "> Create a function named *create_test_df*, that creates a test dataset from a ratings dataframe ; it only retain the following records:\n",
    "> - hash(userId) % 2 == 1\n",
    "> - rating >= 3.5\n",
    "> \n",
    "> Also, the function returns a dataframe structured like this:\n",
    "> - userid : the user id\n",
    "> - movies : list[integer] (all the movies in the user timeline minus the *K* most recent ones)\n",
    "> - label : list[integer] (all the *K* most recent movies in user timeline)\n",
    ">\n",
    "> *K* is parameter whose default value is 5.\n",
    "> \n",
    "> Test the test dataset creation on a toy example.\n",
    "> \n",
    "> Create the real test dataset from the whole movieLense dataset. Name it *test_df*. Persist it on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.244829Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_test_df(ratings_df, K=5):\n",
    "    return ratings_df.filter(F.col(\"userId\") % 2 == 1).groupBy(\"userId\").agg(\n",
    "        F.collect_list(\"movieId\").alias(\"movies\")).withColumn(\"label\", F.slice(F.col(\"movies\"), -K, K)).withColumn(\n",
    "        \"movies\", F.slice(F.col(\"movies\"), 1, F.size(F.col(\"movies\")) - K))\n",
    "\n",
    "\n",
    "test_df = create_test_df(ratings_df)\n",
    "test_df.show()\n",
    "test_df.write.parquet(\"test.parquet\", compression=\"gzip\")\n",
    "test_df = spark.read.parquet(\"test.parquet\")\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CIzNEs5zgVW"
   },
   "source": [
    "### Question D3\n",
    "\n",
    "> Use/adapt each of the algorithms defined in previous sections (naïve, a-priori, FP-growth, PLSI) to predict the 5 next movies that will be seen by the user based on previously seen movies.\n",
    "> \n",
    "> Each algorithm can be 'trained' on *training_df* or a subset of it ; choose and justify.\n",
    "> \n",
    "> For each algorithm, make a quick qualitative analysis, to see how relevant recommended movies are. You should rely on *movies_df* for this question.\n",
    ">\n",
    "> Then, compare the algorithms with the *test_df*, with metrics like *recall* and *precision at k* (define some methods that compute recall and precision at k from test dataframe and predictions dataframe parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAyI7OsuWMWe",
    "ExecuteTime": {
     "start_time": "2024-01-30T15:17:56.245892Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
