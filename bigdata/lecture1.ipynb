{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Big Data\n",
    "\n",
    "Date: September 26, 2023"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c92dcb3bd850cc05"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:31.690109Z",
     "start_time": "2023-11-06T09:40:31.664814Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', size=18)\n",
    "plt.rc('axes', titlesize=18)\n",
    "plt.rc('axes', labelsize=18)\n",
    "plt.rc('xtick', labelsize=18)\n",
    "plt.rc('ytick', labelsize=18)\n",
    "plt.rc('legend', fontsize=18)\n",
    "plt.rc('lines', markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "3V of big data:\n",
    "- Volume: It is the amount of data that is generated from different sources like social media, machines, internet, etc. It is the size of data that determines the value and potential of the data under consideration and whether it can actually be considered as Big Data or not.\n",
    "- Velocity: For Big Data, velocity is the rate at which data is generated and the speed at which the data moves from one point to another. The flow of data is massive and continuous.\n",
    "- Variety: It refers to the many types of data that are available. It can be in the form of structured, unstructured, and semi-structured form. Structured data is organized and is typically found in databases, while unstructured data is chaotic and raw that cannot be organized or easily interpreted. Semi-structured data is a combination of both structured and unstructured data.\n",
    "\n",
    "Example of structure, unstructured and semi-structured data:\n",
    "- Structured data (Schema first): Relational database\n",
    "- Unstructured data (Non-schema): Text, images, video, audio\n",
    "- Semi-structured data (Data first): XML, JSON, HTML\n",
    "\n",
    "BATCH vs STREAMING\n",
    "\n",
    "Batch processing is a method of running high-volume data that is collected over a period of time. Batch processing is used for tasks that require processing large volumes of data where a group of transactions is collected over a period of time. Data is collected, entered, processed and then the batch results are produced (Hadoop, Spark, Hive, Pig, etc.).\n",
    "\n",
    "Streaming data is data that is generated continuously by thousands of data sources, which typically send in the data records simultaneously, and in small sizes (order of Kilobytes). Streaming data includes a wide variety of data such as log files generated by customers using mobile or web applications, ecommerce purchases, in-game player activity, information from social networks, financial trading floors, or geospatial services, and telemetry from connected devices or instrumentation in data centers.\n",
    "\n",
    "Robustness: The system should be able to recover from failure. Moreover, it should be able to process data that is out of order or arrive late."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a609417cbc9e3b75"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "L = [2, 3, 1, 2, 1, 3, 4, 5, 6, 7]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:31.690825Z",
     "start_time": "2023-11-06T09:40:31.668326Z"
    }
   },
   "id": "a81f7bccbf2eaea1"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "M = reduce(lambda x, y: x + y, list(map(lambda x: 1 if x % 2 == 0 else 0, L)))\n",
    "M1 = reduce(lambda x, y: x + y, list(map(lambda x: 1 if x % 2 != 0 else 0, L)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:31.719712Z",
     "start_time": "2023-11-06T09:40:31.671613Z"
    }
   },
   "id": "99c43f2b845130aa"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:31.721077Z",
     "start_time": "2023-11-06T09:40:31.679321Z"
    }
   },
   "id": "2ebf22be348eaf7b"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:31.757309Z",
     "start_time": "2023-11-06T09:40:31.682107Z"
    }
   },
   "id": "b565d7497601e51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "P_{n, s} = \\mathbf{A}_{n, m} \\cdot \\mathbf{B}_{m, s}\n",
    "= \\begin{bmatrix}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1m} \\\\\n",
    "    a_{21} & a_{22} & \\cdots & a_{2m} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    a_{n1} & a_{n2} & \\cdots & a_{nm}\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix}\n",
    "    b_{11} & b_{12} & \\cdots & b_{1s} \\\\\n",
    "    b_{21} & b_{22} & \\cdots & b_{2s} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    b_{m1} & b_{m2} & \\cdots & b_{ms}\n",
    "  \\end{bmatrix}\n",
    "  \n",
    "= P_{i, j} = \\sum_{k=1}^m a_{ik} b_{kj}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "945a297512ad452"
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$ \n",
    "\\mathbf{A} (i, k, a) \\rightarrow \\mathbf{A} (row, column, value) \\\\\n",
    "\\mathbf{B} (k, j, b) \\rightarrow \\mathbf{B} (row, column, value) \\\\\n",
    "\\mathbf{P} (i, j, p) \\rightarrow \\mathbf{P} (row, column, value) \\\\\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f057f1e4794e5bc8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In SQL, we can use the following query to calculate the matrix multiplication:\n",
    "```sql\n",
    "SELECT A.row, B.column, SUM(A.value * B.value) AS value\n",
    "FROM A, B\n",
    "WHERE A.column = B.row\n",
    "GROUP BY A.row, B.column\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e62c0404f0a420f9"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "A = [[1, 2, 3], [4, 5, 6]]\n",
    "B = [[1, 2], [3, 4], [5, 6]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:31.757733Z",
     "start_time": "2023-11-06T09:40:31.684847Z"
    }
   },
   "id": "3f0dcad6359fc3cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "MapReduce is a programming model and an associated implementation for processing and generating big data sets with a parallel, distributed algorithm on a cluster. A MapReduce program is composed of a map procedure (or method), which performs filtering and sorting (such as sorting students by first name into queues, one queue for each name), and a reduce method, which performs a summary operation (such as counting the number of students in each queue, yielding name frequencies)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd6455ea370c671e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MapReduce\n",
    "\n",
    "- Data model: key-value pairs $(k, v)$\n",
    "- Execution model: $map(k, udf) \\rightarrow m(k, v) \\rightarrow [(), (), ...]$, $reduce(k, [v_1, v_2, ...]) \\rightarrow [(), (), ...]$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57edd13264a7d656"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SPARK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f58b39663f64b2cc"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# ! pip install pyspark"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:31.758200Z",
     "start_time": "2023-11-06T09:40:31.689247Z"
    }
   },
   "id": "e976755ccc5d5ba7"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at /var/folders/sm/lw2bbffs15g5l3r4ldd25hc00000gn/T/ipykernel_17020/2854745563.py:2 ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[69], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkContext\n\u001B[0;32m----> 2\u001B[0m sc \u001B[38;5;241m=\u001B[39m \u001B[43mSparkContext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/IASD/iasd/lib/python3.10/site-packages/pyspark/context.py:201\u001B[0m, in \u001B[0;36mSparkContext.__init__\u001B[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gateway \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m gateway\u001B[38;5;241m.\u001B[39mgateway_parameters\u001B[38;5;241m.\u001B[39mauth_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    197\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    198\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is not allowed as it is a security risk.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    199\u001B[0m     )\n\u001B[0;32m--> 201\u001B[0m \u001B[43mSparkContext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ensure_initialized\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgateway\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgateway\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_init(\n\u001B[1;32m    204\u001B[0m         master,\n\u001B[1;32m    205\u001B[0m         appName,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    215\u001B[0m         memory_profiler_cls,\n\u001B[1;32m    216\u001B[0m     )\n",
      "File \u001B[0;32m~/IASD/iasd/lib/python3.10/site-packages/pyspark/context.py:449\u001B[0m, in \u001B[0;36mSparkContext._ensure_initialized\u001B[0;34m(cls, instance, gateway, conf)\u001B[0m\n\u001B[1;32m    446\u001B[0m     callsite \u001B[38;5;241m=\u001B[39m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context\u001B[38;5;241m.\u001B[39m_callsite\n\u001B[1;32m    448\u001B[0m     \u001B[38;5;66;03m# Raise error if there is already a running Spark context\u001B[39;00m\n\u001B[0;32m--> 449\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    450\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot run multiple SparkContexts at once; \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    451\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexisting SparkContext(app=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, master=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    452\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m created by \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m at \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    453\u001B[0m         \u001B[38;5;241m%\u001B[39m (\n\u001B[1;32m    454\u001B[0m             currentAppName,\n\u001B[1;32m    455\u001B[0m             currentMaster,\n\u001B[1;32m    456\u001B[0m             callsite\u001B[38;5;241m.\u001B[39mfunction,\n\u001B[1;32m    457\u001B[0m             callsite\u001B[38;5;241m.\u001B[39mfile,\n\u001B[1;32m    458\u001B[0m             callsite\u001B[38;5;241m.\u001B[39mlinenum,\n\u001B[1;32m    459\u001B[0m         )\n\u001B[1;32m    460\u001B[0m     )\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    462\u001B[0m     SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context \u001B[38;5;241m=\u001B[39m instance\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at /var/folders/sm/lw2bbffs15g5l3r4ldd25hc00000gn/T/ipykernel_17020/2854745563.py:2 "
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:43.779976Z",
     "start_time": "2023-11-06T09:40:43.753498Z"
    }
   },
   "id": "c58ffa6b1424934a"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "<SparkContext master=local[*] appName=pyspark-shell>",
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.113.217.28:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        "
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:45.541086Z",
     "start_time": "2023-11-06T09:40:45.534252Z"
    }
   },
   "id": "609520a3468ca23b"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "list_of_number = [2, 4, 3, 2, 5, 5, 3, 5, 2, 6, 8, 3, 9, 9, 2, 3, 6, 4, 7, 9, 8]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:46.962520Z",
     "start_time": "2023-11-06T09:40:46.952968Z"
    }
   },
   "id": "b8e0c3a9eda0cfff"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 3, 2, 5, 5, 3, 5, 2, 6, 8, 3, 9, 9, 2, 3, 6, 4, 7, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "print(list_of_number)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:48.202910Z",
     "start_time": "2023-11-06T09:40:48.194598Z"
    }
   },
   "id": "116d4df3bf34ce5b"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(list_of_number)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:48.512896Z",
     "start_time": "2023-11-06T09:40:48.503488Z"
    }
   },
   "id": "c78603c50611be1a"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "ParallelCollectionRDD[63] at readRDDFromFile at PythonRDD.scala:289"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:48.814853Z",
     "start_time": "2023-11-06T09:40:48.803821Z"
    }
   },
   "id": "4a2a58175d237094"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD:  [2, 4, 3, 2, 5, 5, 3, 5, 2, 6, 8, 3, 9, 9, 2, 3, 6, 4, 7, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "# collect() is an action\n",
    "print(\"RDD: \", rdd.collect())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:49.144331Z",
     "start_time": "2023-11-06T09:40:49.101911Z"
    }
   },
   "id": "5dcfb753c465eabc"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of partitions: \", rdd.getNumPartitions())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:49.473626Z",
     "start_time": "2023-11-06T09:40:49.434535Z"
    }
   },
   "id": "98e5e8605df5594"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions structure:  [[2, 4], [3, 2], [5, 5, 3, 5], [2, 6], [8, 3], [9, 9, 2, 3], [6, 4], [7, 9, 8]]\n"
     ]
    }
   ],
   "source": [
    "# glom() is an transformation\n",
    "print(\"Partitions structure: \", rdd.glom().collect())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:49.943281Z",
     "start_time": "2023-11-06T09:40:49.730374Z"
    }
   },
   "id": "91479869759527f5"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plus one:  [3, 5, 4, 3, 6, 6, 4, 6, 3, 7, 9, 4, 10, 10, 3, 4, 7, 5, 8, 10, 9]\n",
      "Structure:  [[3, 5], [4, 3], [6, 6, 4, 6], [3, 7], [9, 4], [10, 10, 3, 4], [7, 5], [8, 10, 9]]\n"
     ]
    }
   ],
   "source": [
    "# map() is an transformation\n",
    "plus_one = rdd.map(lambda x: x + 1).collect()\n",
    "print(\"Plus one: \", plus_one)\n",
    "print(\"Structure: \", rdd.map(lambda x: x + 1).glom().collect())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:50.284507Z",
     "start_time": "2023-11-06T09:40:49.993659Z"
    }
   },
   "id": "f5e30ced2738689a"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even:  [2, 4, 2, 2, 6, 8, 2, 6, 4, 8]\n",
      "Structure:  [[2, 4], [2], [], [2, 6], [8], [2], [6, 4], [8]]\n"
     ]
    }
   ],
   "source": [
    "# filter() is an transformation\n",
    "even = rdd.filter(lambda x: x % 2 == 0).collect()\n",
    "print(\"Even: \", even)\n",
    "print(\"Structure: \", rdd.filter(lambda x: x % 2 == 0).glom().collect())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:50.656732Z",
     "start_time": "2023-11-06T09:40:50.329333Z"
    }
   },
   "id": "445fcc8845452671"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map:  [[3, 5], [4, 3], [6, 6, 4, 6], [3, 7], [9, 4], [10, 10, 3, 4], [7, 5], [8, 10, 9]]\n",
      "Map and reduce:  126\n"
     ]
    }
   ],
   "source": [
    "# map() and reduce() is an action which is not required shuffle operation\n",
    "print(\"Map: \", rdd.map(lambda x: x + 1).glom().collect())\n",
    "print(\"Map and reduce: \", rdd.map(lambda x: x + 1).reduce(lambda x, y: x + y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:50.913861Z",
     "start_time": "2023-11-06T09:40:50.637050Z"
    }
   },
   "id": "e97d3edd175bc50e"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "assert rdd.map(lambda x: x + 1).reduce(lambda x, y: x + y) == sum(plus_one)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:51.043033Z",
     "start_time": "2023-11-06T09:40:50.909486Z"
    }
   },
   "id": "7728928fdddc7a76"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of even numbers:  44\n",
      "Sum of odd numbers:  61\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sum of even numbers and odd numbers\n",
    "print(\"Sum of even numbers: \", rdd.filter(lambda x: x % 2 == 0).reduce(lambda x, y: x + y))\n",
    "print(\"Sum of odd numbers: \", rdd.filter(lambda x: x % 2 != 0).reduce(lambda x, y: x + y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:51.521230Z",
     "start_time": "2023-11-06T09:40:51.244144Z"
    }
   },
   "id": "d9b3bdb6c3806f04"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of even numbers:  44\n",
      "Sum of odd numbers:  61\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of even numbers: \", rdd.map(lambda x: x if x % 2 == 0 else 0).reduce(lambda x, y: x + y))\n",
    "print(\"Sum of odd numbers: \", rdd.map(lambda x: x if x % 2 != 0 else 0).reduce(lambda x, y: x + y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:40:51.858954Z",
     "start_time": "2023-11-06T09:40:51.600181Z"
    }
   },
   "id": "7801a5aabcf397f5"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 44)], [(1, 61)], [], [], [], [], [], []]\n",
      "Sum of even numbers:  44\n",
      "Sum of odd numbers:  61\n"
     ]
    }
   ],
   "source": [
    "# reduceByKey() is an transformation\n",
    "print(rdd.map(lambda x: (x % 2, x)).reduceByKey(lambda x, y: x + y).glom().collect())\n",
    "print(\"Sum of even numbers: \", rdd.map(lambda x: (x % 2, x)).reduceByKey(lambda x, y: x + y).collect()[0][1])\n",
    "print(\"Sum of odd numbers: \", rdd.map(lambda x: (x % 2, x)).reduceByKey(lambda x, y: x + y).collect()[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:44:32.694952Z",
     "start_time": "2023-11-06T09:44:31.830826Z"
    }
   },
   "id": "f651368ce22afc35"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat map:  [0, 1, 0, 1, 2, 3, 0, 1, 2, 0, 1, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 0, 1, 2, 3, 4, 0, 1, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 0, 1, 2, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Union:  [2, 4, 3, 2, 5, 5, 3, 5, 2, 6, 8, 3, 9, 9, 2, 3, 6, 4, 7, 9, 8, 2, 4, 3, 2, 5, 5, 3, 5, 2, 6, 8, 3, 9, 9, 2, 3, 6, 4, 7, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "# flatMap(), union() are transformations\n",
    "print(\"Flat map: \", rdd.flatMap(lambda x: list(range(x))).collect())\n",
    "print(\"Union: \", rdd.union(rdd).collect())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:47:18.595275Z",
     "start_time": "2023-11-06T09:47:18.414301Z"
    }
   },
   "id": "ecf1450c61d64e"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take:  [2, 4, 3, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "# take is an action\n",
    "print(\"Take: \", rdd.take(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:48:16.608317Z",
     "start_time": "2023-11-06T09:48:16.445342Z"
    }
   },
   "id": "79ee60607493ba13"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "# Word count exercise\n",
    "text = [\"aa bb nn aa cc\", \"aa bb cc dd ee\", \"aa bb cc dd ff\", \"aa bb cc dd gg\", \"zz cc xx vv bb\", \"aa bb cc dd hh\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:50:32.841784Z",
     "start_time": "2023-11-06T09:50:32.837781Z"
    }
   },
   "id": "31df59c0ea784d29"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa bb nn aa cc', 'aa bb cc dd ee', 'aa bb cc dd ff', 'aa bb cc dd gg', 'zz cc xx vv bb', 'aa bb cc dd hh']\n",
      "[[], ['aa bb nn aa cc'], ['aa bb cc dd ee'], ['aa bb cc dd ff'], [], ['aa bb cc dd gg'], ['zz cc xx vv bb'], ['aa bb cc dd hh']]\n"
     ]
    }
   ],
   "source": [
    "r = sc.parallelize(text)\n",
    "print(r.collect())\n",
    "print(r.glom().collect())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:56:16.997500Z",
     "start_time": "2023-11-06T09:56:16.862863Z"
    }
   },
   "id": "a60c42d2f8da0baf"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def word_count(r):\n",
    "    count = r.flatMap(lambda x: x.split()).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).collect()\n",
    "    return count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:56:19.640777Z",
     "start_time": "2023-11-06T09:56:19.636827Z"
    }
   },
   "id": "957933414314e088"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "[('ff', 1),\n ('nn', 1),\n ('zz', 1),\n ('hh', 1),\n ('ee', 1),\n ('aa', 6),\n ('gg', 1),\n ('dd', 4),\n ('vv', 1),\n ('cc', 6),\n ('xx', 1),\n ('bb', 6)]"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count(r)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T09:56:20.132364Z",
     "start_time": "2023-11-06T09:56:19.884892Z"
    }
   },
   "id": "52ffb01631a3dbf6"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "def max_count(r):\n",
    "    count = r.flatMap(lambda x: x.split()).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)\n",
    "    max_count = count.map(lambda x: x[1]).reduce(lambda x, y: x if x > y else y)\n",
    "    return count.flatMap(lambda x: [x] if x[1] == max_count else []).collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T10:18:46.885495Z",
     "start_time": "2023-11-06T10:18:46.879230Z"
    }
   },
   "id": "c4c5054838fd854e"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "[('aa', 6), ('cc', 6), ('bb', 6)]"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_count(r)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T10:18:47.685040Z",
     "start_time": "2023-11-06T10:18:47.180191Z"
    }
   },
   "id": "ed18f7e13766e9cb"
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "# Calculate intersection of two RDDs\n",
    "r1 = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "r2 = sc.parallelize([2, 4, 6, 8, 10, 12, 14, 16, 18])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T10:40:58.674845Z",
     "start_time": "2023-11-06T10:40:58.665473Z"
    }
   },
   "id": "383959da9dbf04db"
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "def intersection(r1, r2):\n",
    "    result1 = r1.map(lambda x: (x, 1)) # [(1, 1), (2, 1), (3, 1), ...]\n",
    "    result2 = r2.map(lambda x: (x, 1)) # [(1, 1), (2, 1), (3, 1), ...]\n",
    "    result = result1.union(result2).reduceByKey(lambda x, y: x + y).flatMap(lambda x: [x[0]] if x[1] == 2 else []).collect() # [(1, 2), (2, 2), (3, 2), ...]\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T10:40:58.955047Z",
     "start_time": "2023-11-06T10:40:58.945802Z"
    }
   },
   "id": "aaf1fac5884046cf"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 4, 6, 8]"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection(r1, r2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T10:40:59.953313Z",
     "start_time": "2023-11-06T10:40:59.233658Z"
    }
   },
   "id": "5ea6930e2a66af30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b5107dc32c41cd90"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
