{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoNpnIQOBcfx"
      },
      "source": [
        "# Predict the next seen movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nMdnOrdauzb"
      },
      "source": [
        "> The goal of this project is to validate your skills learned during the previous tutorials with the PySpark distributed computing software. You will build and test several implementations of recommendation systems. Here are the parts of the project:\n",
        ">\n",
        "> * Part A: Load and preprocess the dataset.\n",
        "> * Part B: Build a first set of recommendation algorithms: naive with recurring pairs, a priori, and fp-growth to infer rules from a dataset.\n",
        "> * Part C: Implement the PLSI algorithm (\"Probabilistic Latent Semantic Indexing\"), which is one way to create embeddings from a dataset. These embeddings can be used to fuel a recommendation engine.\n",
        "> * Part D: Predict the next movies seen by a user in function of the last movies that he/she has seen with the previous implemented algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69sUuh3EEEBw"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxRuqODPWgYM"
      },
      "source": [
        "## Install Spark Environment\n",
        "\n",
        "> Since you are running on Google Colab, you will need to install Spark by ourselves, every time we run a new session. You need to install Spark, as well as a Java Runtime Environment.  Then you need to setup a few environment variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjh2g1iwrxAQ"
      },
      "source": [
        "Execute:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IInRgu9Hrnse"
      },
      "source": [
        "or directly with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vFR3wKqDrrsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4dde02-5ba0-48a2-a7e0-3bf8cb8e3471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=c230da6d9d62258b9d1c7973ae94e815f22d5d2eec384ff4565a269c38dd4865\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBTHZp82G_Ea"
      },
      "source": [
        "Create and launch a Spark session with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RKP62k6BW5Xz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "conf = SparkConf().set('spark.ui.port', '4050')\n",
        "\n",
        "spark = SparkSession.builder.config(conf=conf)\\\n",
        "  .master('local[*]')\\\n",
        "  .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "yA7rmX4p8BBo",
        "outputId": "2e1d047a-acf0-47d5-ff5f-dc6fd9326db9",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7adff8215de0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6e135daa8c0a:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWQFahH3HfJ9"
      },
      "source": [
        "/!\\ The Spark UI link is not accessible. Use the optional next session if you want to access it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bDPyOrBGzkC"
      },
      "source": [
        "Uncomment and execute the following line, if you want to close and stop the created Spark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FXvFSpAkGyMm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5yHDm0vXkIQ"
      },
      "source": [
        "## Optional step: Enable Spark UI access through a secure tunnel\n",
        "\n",
        "> This step is useful if you want to look at Spark UI.\n",
        "First, you need to create a free ngrok account : https://dashboard.ngrok.com/login.  \n",
        "Then connect on the website and copy your AuthToken."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S2bV9Ydi8sLs"
      },
      "outputs": [],
      "source": [
        "# !uname -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eCerOlcLXmgj"
      },
      "outputs": [],
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NHgGqKOeAYVH"
      },
      "outputs": [],
      "source": [
        "# !./ngrok authtoken '2HYfdysedjgB5lcoeE8lqqShgIe_sZUm49MquX5okpssVMYQ' # <-------------- change this line !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1G-XfsyHAT84"
      },
      "outputs": [],
      "source": [
        "# get_ipython().system_raw('./ngrok http 4050 &')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3jWA3ILoOBAw"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import urllib\n",
        "\n",
        "# ngrok_tunnels = urllib.request.urlopen('http://localhost:4040/api/tunnels').read().decode('utf8')\n",
        "# spark_ui_url = json.loads(ngrok_tunnels)['tunnels'][0]['public_url']\n",
        "# print(\"Spark UI:\", spark_ui_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSX0QbniXqdR"
      },
      "source": [
        "## Other Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vb4tXmFUWMVr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import urllib.request as req\n",
        "import zipfile\n",
        "import glob\n",
        "from datetime import datetime\n",
        "from fractions import Fraction\n",
        "from decimal import Decimal\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from pyspark import StorageLevel\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, StructType, StructField, StringType, IntegerType, BooleanType, Tuple, FloatType\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "#Additional imports\n",
        "import gc\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFUvUg2ufEkJ"
      },
      "source": [
        "# Part A - Dataset (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGC6YNJm8wh2"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r_d9HFUnfPYY"
      },
      "outputs": [],
      "source": [
        "url = 'http://files.grouplens.org/datasets/movielens/ml-20m.zip'\n",
        "filehandle, _ = req.urlretrieve(url)\n",
        "zip_file_object = zipfile.ZipFile(filehandle, 'r')\n",
        "zip_file_object.namelist()\n",
        "zip_file_object.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3lK0389fXkK",
        "outputId": "38311117-c022-4718-f004-c7b401ca1abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ml-20m/tags.csv\n",
            "ml-20m/README.txt\n",
            "ml-20m/genome-scores.csv\n",
            "ml-20m/ratings.csv\n",
            "ml-20m/movies.csv\n",
            "ml-20m/links.csv\n",
            "ml-20m/genome-tags.csv\n"
          ]
        }
      ],
      "source": [
        "!find ml-20m -type f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Uwruo0oIfaop",
        "tags": []
      },
      "outputs": [],
      "source": [
        "movies_path = \"ml-20m/movies.csv\"\n",
        "ratings_path = \"ml-20m/ratings.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hWQSjOtYWMVx",
        "tags": []
      },
      "outputs": [],
      "source": [
        "ratings_df_csv = spark.read.options(header=True, inferSchema=True).csv(ratings_path)\n",
        "movies_df_csv = spark.read.options(header=True, inferSchema=True).csv(movies_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M21UsEBv5Up",
        "outputId": "2163d85c-dc48-44b8-ea91-90565a5a3dd2",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "ratings_df_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtR77Ttq8zT-"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "> In the following sections, we will work with algorithms that may scale more or less well with the size of the dataset. In this section we will develop several functions that will allow you to sample the dataset. Then in the next part of the notebook, it will be up to you to choose which tools you want to apply to your dataset in order to train your models, knowing that we want to have reasonable processing times (in the order of a minute), while having models that 'work' well.\n",
        ">\n",
        "> **Test all the functions that process the dataframe on a toy example, like what is done in first data processing question.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1zW1MHjDZnu"
      },
      "source": [
        "### Question A1\n",
        "\n",
        ">Write the *ratings_df_csv* and *movies_df_csv* DataFrame in a compressed parquet format.\n",
        ">\n",
        ">Reload them from parquet, to make next computations faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HoJg58KMaufR"
      },
      "outputs": [],
      "source": [
        "ratings_parquet_path = 'ml-20m/ratings.parquet'\n",
        "ratings_df_csv.write.mode(\"overwrite\").parquet(ratings_parquet_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_parquet_path = 'ml-20m/movies.parquet'\n",
        "movies_df_csv.write.mode(\"overwrite\").parquet(movies_parquet_path)"
      ],
      "metadata": {
        "id": "5u9KTML2dg18"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df_parquet = spark.read.parquet(ratings_parquet_path)"
      ],
      "metadata": {
        "id": "vLfUaxhZeLXT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df_parquet = spark.read.parquet(movies_parquet_path)"
      ],
      "metadata": {
        "id": "oXE90qe7e88L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df_parquet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-yHkis9fCPV",
        "outputId": "823fd5f8-05be-4a6a-de9c-230201dbef31"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[movieId: int, title: string, genres: string]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stqYh6SJGTCa"
      },
      "source": [
        "### Question A2\n",
        "\n",
        "> Compute an estimation of the whole *ratings_df* dataset size in memory.\n",
        ">\n",
        ">Find the amount of partitions used by *ratings_df*.\n",
        ">\n",
        ">We try to have partitions not too big (in order not to crash our executors), and not to small (dealing with too many small partitions can lead to issues, on driver side for example). For this reason, a rule of thumb to have partitions of 128MB is okay. Given this, what do you think of the dataframe? Is the amount of partitions okay? Or should we repartition it? What would be the function to use if we need to repartition the dataframe?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmGGQGH1aufS",
        "outputId": "0cc7a66b-4093-4c7a-9bc9-d909f98f6184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000263"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "ratings_df_parquet.printSchema()\n",
        "ratings_df_parquet.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**\n",
        "* 'userId' is an integer column, each integer is stored in 32 bits (=4 Bytes)\n",
        "* The same goes for 'movieId' and 'timestamp'. 'rating' is a double stored in 64 bits (=8 Bytes)\n",
        "* So each rows contains (3*4)+8 = 20 Bytes of data, for a total of 20 000 263 * 20 Bytes <br>  \n",
        "That is a total of 400 005 260 Bytes (~ 400 MB)"
      ],
      "metadata": {
        "id": "EzZmrQCyzbp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df_csv.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcRpYiGk1JdT",
        "outputId": "2d4a01fc-df7d-4cf0-b9cc-d8bb03238226"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df_parquet.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rodbrhu3KKG",
        "outputId": "89c30803-1289-49db-a956-22bfa9650a6f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The dataframe is split into 2 partitions in parquet format and 4 in csv format\n",
        "* This does not respect the rule of thumb of having roughly 128 MB per partition\n",
        "* To respect to the rule of thumb, we should split the dataset into 3 partitions using df.repartition(3)"
      ],
      "metadata": {
        "id": "jXbJ3Pcb1ump"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df_parquet = ratings_df_parquet.repartition(3)"
      ],
      "metadata": {
        "id": "JZi4izWU1q8H"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df_parquet.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiqQthlY31-J",
        "outputId": "03c3cc88-0890-4eeb-865e-cae9f1c1254e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IESUqOGp_rDf"
      },
      "source": [
        "### Question A3\n",
        "\n",
        ">Create a function named *remove_bad_ratings* that takes a rating dataframe as an argument, and returns a dataframe whose ratings are greater or equals to a rating_threshold, with default value of *3.5*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qZFx9pvvaufS"
      },
      "outputs": [],
      "source": [
        "def remove_bad_ratings(rating_df,\n",
        "                       threshold=3.5):\n",
        "  return rating_df.filter(rating_df.rating>=threshold)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_ratings_df = remove_bad_ratings(ratings_df_parquet)"
      ],
      "metadata": {
        "id": "8bpOk-I0hXT0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "good_ratings_df.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEerXq-lhdrV",
        "outputId": "1ae682e0-b5cb-4cb2-cbf7-5840cdb1f2e1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(userId=42913, movieId=930, rating=4.0, timestamp=985661582),\n",
              " Row(userId=1131, movieId=1210, rating=4.0, timestamp=862594943),\n",
              " Row(userId=55563, movieId=337, rating=4.0, timestamp=1346832403),\n",
              " Row(userId=32274, movieId=3148, rating=4.5, timestamp=1143254050),\n",
              " Row(userId=19697, movieId=1089, rating=5.0, timestamp=1120575477)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMKLPBXaI0TA"
      },
      "source": [
        "### Question A4\n",
        "\n",
        ">Create a function named *sample_users* that takes a rating dataframe as an argument, and returns a dataframe with only a *ratio* of users (we want to keep all ratings from users that we keep) ; default value of *ratio* parameter is *0.1*. Function should be deterministic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kIvB6mKQaufY"
      },
      "outputs": [],
      "source": [
        "def sample_users(rating_df, ratio=0.1):\n",
        "  return rating_df.filter(F.hash('userId') % int(1/ratio) == 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_small_df = sample_users(ratings_df_parquet, ratio = 0.10)"
      ],
      "metadata": {
        "id": "VczBuOZqyXJN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing if the small df has more or less 10% the original dataframe size i.e. 2M rows. <br>"
      ],
      "metadata": {
        "id": "LFMuPkv-4f6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_small_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEG3Mb7wiZhU",
        "outputId": "015c3acf-1dd5-40c5-8f7d-cd9ac83d263b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1973662"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_small_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPHl-jzGBw5c",
        "outputId": "978cc733-ef32-4e32-d6c9-05bae2929642"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "| 51793|   2528|   5.0| 992150670|\n",
            "| 60271|   2089|   4.0|1129599380|\n",
            "| 47045|      1|   5.0| 982395391|\n",
            "| 13376|   2268|   4.0| 973220222|\n",
            "| 62599|   3255|   3.0|1108532462|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJV6UbAiLGiv"
      },
      "source": [
        "### Question A5\n",
        "\n",
        "> Create a function named *remove_exotic_movies*, taking a rating dataframe as argument, and that removes all movies which have less than *nb_min_ratings* ; *nb_min_ratings* parameter has a default value of *1000*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gouPDZQiaufZ"
      },
      "outputs": [],
      "source": [
        "def remove_exotic_movies(rating_df,\n",
        "                         nb_min_ratings=1000,\n",
        "                         drop_count=False):\n",
        "    #We don't want to modify in the input df so we will do the transformations in an other variable\n",
        "    nb_ratings_per_movie = rating_df.groupBy('movieId').agg(F.count('rating').alias('count'))\n",
        "    result = rating_df.join(nb_ratings_per_movie, on='movieId', how='left')\n",
        "    result = result.filter(f\"count >= {nb_min_ratings}\")\n",
        "    #Wether we want to keep the column counting the amount of ratings\n",
        "    if drop_count :\n",
        "      result = result.drop(\"count\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_exotic_movies(ratings_small_df, drop_count=False).head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqTIdDGskh_X",
        "outputId": "edcf44a0-c070-40a4-fae0-679ff516a662"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(movieId=1580, userId=54456, rating=5.0, timestamp=974792198, count=3510),\n",
              " Row(movieId=1580, userId=20351, rating=4.0, timestamp=1115685444, count=3510),\n",
              " Row(movieId=1580, userId=50611, rating=5.0, timestamp=958264661, count=3510),\n",
              " Row(movieId=1580, userId=52935, rating=3.0, timestamp=1131579026, count=3510),\n",
              " Row(movieId=1580, userId=70394, rating=2.0, timestamp=1057994061, count=3510)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTKUFM95pAwP"
      },
      "source": [
        "### Question A6\n",
        "\n",
        "> Compute the following stats on the dataset:\n",
        "> - Amount of distinct users\n",
        "> - Amount of distinct movies\n",
        "> - Total amount of ratings\n",
        "> - Let r_u be the amount of ratings made by user u. Study the distribution of r_u over all users (quantiles, histogram...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "SiVk2vOlaufZ"
      },
      "outputs": [],
      "source": [
        "def df_stats(rating_df) :\n",
        "  nb_distinct_users = rating_df.select('userId').distinct().count()\n",
        "  print(f\"Amount of distinct users : {nb_distinct_users}\")\n",
        "  nb_distinct_movies = rating_df.select('movieId').distinct().count()\n",
        "  print(f\"Amount of distinct movies : {nb_distinct_movies}\")\n",
        "  nb_ratings = rating_df.count()\n",
        "  print(f\"Total amount of ratings : {nb_ratings}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats(ratings_df_parquet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV1InH3OpUGr",
        "outputId": "1c9dc23c-a327-4eea-bcdb-04ef4e788217"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of distinct users : 138493\n",
            "Amount of distinct movies : 26744\n",
            "Total amount of ratings : 20000263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def r_u_stats(rating_df, show_hist=False):\n",
        "    ratings_per_user = rating_df.groupBy('userId').agg(F.count('rating').alias('r_u'))\n",
        "    ratings_per_user.select('r_u').summary(\"count\", \"mean\", \"min\", \"25%\", \"50%\", \"75%\", \"max\").show()\n",
        "    if show_hist :\n",
        "        ratings_per_user_values = [row.r_u for row in ratings_per_user.select('r_u').collect()]\n",
        "        plt.hist(ratings_per_user_values, bins=50, log=True);"
      ],
      "metadata": {
        "id": "GrmyCWddRbNy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_u_stats(ratings_small_df, True)"
      ],
      "metadata": {
        "id": "oFWr4cgApvsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "3802f1f8-1354-48c7-bd18-b973c9db66b9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|               r_u|\n",
            "+-------+------------------+\n",
            "|  count|             13870|\n",
            "|   mean|142.29718817591925|\n",
            "|    min|                20|\n",
            "|    25%|                34|\n",
            "|    50%|                66|\n",
            "|    75%|               152|\n",
            "|    max|              5356|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJbcMpnj-UJi",
        "outputId": "06d9ad90-dbb8-43c7-d439-55b3b0600d3f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14807"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFjZb6tFmEPt"
      },
      "source": [
        "### Question A7\n",
        "\n",
        "> Create a function named *remove_old_movies_in_timelines*, that takes a ratings dataframe as parameter, and only keeps the *nb_max_movies* most recent movies seen by each user ; *nb_max_movies* parameter is defaulted at 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vbZ5EiZ2aufa"
      },
      "outputs": [],
      "source": [
        "def remove_old_movies_in_timelines(rating_df,\n",
        "                                   nb_max_movies=100):\n",
        "  # Define a window specification partitioned by 'userId' and ordered by 'timestamp' in descending order\n",
        "  window_spec = Window.partitionBy(\"userId\").orderBy(F.col(\"timestamp\").desc())\n",
        "  # Add a new column 'most_recent' representing the rank of each row within its partition\n",
        "  df_with_rank = rating_df.withColumn(\"most_recent\", F.row_number().over(window_spec))\n",
        "  # Filter out rows where 'rank' is less than or equal to 100\n",
        "  result_df = df_with_rank.filter(F.col(\"most_recent\") <= nb_max_movies)\n",
        "  return result_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_old_movies_in_timelines(ratings_small_df.filter(\"userId == 60271\")).tail(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vMOgjNA3ZwZ",
        "outputId": "c19d2ad5-9403-4916-dd8e-bf0797d1cfdc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(userId=60271, movieId=8873, rating=4.0, timestamp=1131858185, most_recent=81),\n",
              " Row(userId=60271, movieId=1449, rating=4.0, timestamp=1131858085, most_recent=82),\n",
              " Row(userId=60271, movieId=30812, rating=2.0, timestamp=1131857834, most_recent=83),\n",
              " Row(userId=60271, movieId=2302, rating=3.0, timestamp=1131483756, most_recent=84),\n",
              " Row(userId=60271, movieId=303, rating=1.5, timestamp=1131483714, most_recent=85),\n",
              " Row(userId=60271, movieId=1127, rating=3.5, timestamp=1131483690, most_recent=86),\n",
              " Row(userId=60271, movieId=5669, rating=5.0, timestamp=1130128857, most_recent=87),\n",
              " Row(userId=60271, movieId=4979, rating=3.5, timestamp=1130128770, most_recent=88),\n",
              " Row(userId=60271, movieId=2395, rating=4.0, timestamp=1130128763, most_recent=89),\n",
              " Row(userId=60271, movieId=30810, rating=4.5, timestamp=1130128745, most_recent=90),\n",
              " Row(userId=60271, movieId=4878, rating=4.0, timestamp=1130128382, most_recent=91),\n",
              " Row(userId=60271, movieId=765, rating=2.5, timestamp=1130128050, most_recent=92),\n",
              " Row(userId=60271, movieId=2019, rating=5.0, timestamp=1130127986, most_recent=93),\n",
              " Row(userId=60271, movieId=4327, rating=4.5, timestamp=1130127974, most_recent=94),\n",
              " Row(userId=60271, movieId=420, rating=1.5, timestamp=1130127618, most_recent=95),\n",
              " Row(userId=60271, movieId=553, rating=3.5, timestamp=1130127589, most_recent=96),\n",
              " Row(userId=60271, movieId=597, rating=2.0, timestamp=1130127448, most_recent=97),\n",
              " Row(userId=60271, movieId=344, rating=3.0, timestamp=1130127410, most_recent=98),\n",
              " Row(userId=60271, movieId=377, rating=2.5, timestamp=1130127404, most_recent=99),\n",
              " Row(userId=60271, movieId=1380, rating=2.5, timestamp=1130127213, most_recent=100)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTveqlrl_T8u"
      },
      "source": [
        "# Part B - Association Rules (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fukr5HVii2BG"
      },
      "source": [
        "## Naive: Recurring pairs\n",
        "\n",
        "> This approach is simple and not efficient but gives you a baseline and intuition for the next steps.\n",
        ">\n",
        "> Morally, what we want to do is:\n",
        "> - for each user, regroup all the movies they have liked inside a single row. We will call this the 'user timeline'\n",
        "> - for each user, generate all pairs of movies across their list of movies.\n",
        "> - for each pair of movies, count the amount of distinct users with this pair.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before starting part B, we will create a very small subset of ratings_df to test our functions"
      ],
      "metadata": {
        "id": "h6ozvGmvdooX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_small_df = sample_users(ratings_df_parquet, ratio = 0.01) #20M rows -> 200k rows\n",
        "ratings_small_df = remove_bad_ratings(ratings_small_df, threshold = 3.5)\n",
        "ratings_small_df = remove_exotic_movies(ratings_small_df, nb_min_ratings=100, drop_count=True)"
      ],
      "metadata": {
        "id": "oSFNb2t9dn74"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_small_df.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6JVJf1Xeaz_",
        "outputId": "d44f5abb-971e-4ca8-bb2b-c074fb1c6d92"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[movieId: int, userId: int, rating: double, timestamp: int]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_small_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEwR7OnKeh5p",
        "outputId": "320c025c-d12a-4f6f-9e51-deba160ea1aa"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(movieId=1580, userId=116159, rating=5.0, timestamp=901306654),\n",
              " Row(movieId=1580, userId=137912, rating=4.5, timestamp=1112382039),\n",
              " Row(movieId=1580, userId=82224, rating=3.5, timestamp=1111473046),\n",
              " Row(movieId=1580, userId=74757, rating=3.5, timestamp=1064772181),\n",
              " Row(movieId=1580, userId=122834, rating=4.0, timestamp=878135856)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_small_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyoLd5lJfv8j",
        "outputId": "cfd41b24-2ced-4851-8161-8c32c45f6550"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44513"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKvQ69TpwF_N"
      },
      "source": [
        "### Question B1\n",
        "\n",
        "> Create a function named *compute_timeline*, that takes a ratings dataframe as parameter, and returns the 'user timeline', a dataframe following this schema:\n",
        "> - userId : integer\n",
        "> - movies : list[integer] (list of movieId seen by user)\n",
        ">\n",
        "> Test it on a toy example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "wNX2p7NUaufa"
      },
      "outputs": [],
      "source": [
        "def compute_timeline(rating_df):\n",
        "  user_timeline = rating_df.groupby('userId').agg(F.collect_list(\"movieId\").alias('movies'))\n",
        "  return user_timeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_timeline(ratings_small_df).tail(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuPCwx9Y7na_",
        "outputId": "13ad99ee-c3bc-46ec-d426-e14f4f1c23a7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(userId=138390, movies=[1265, 2396, 2797, 497, 300, 1307, 1148, 2502, 1961, 1207, 912, 1247, 1394, 920, 1968, 919, 2571, 1225, 904, 903, 1641, 594, 2324, 39, 21, 1393, 457, 953, 1617, 1196, 541, 260, 1954, 357, 2599])]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_small_df.filter(\"userId == 138390\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af5fUFpkqpJw",
        "outputId": "3d1767f4-1420-4589-b513-b5eb70726381"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------+---------+\n",
            "|movieId|userId|rating|timestamp|\n",
            "+-------+------+------+---------+\n",
            "|   1265|138390|   4.0|945188228|\n",
            "|   2396|138390|   5.0|945188161|\n",
            "|   2797|138390|   5.0|945189468|\n",
            "|    497|138390|   5.0|945189057|\n",
            "|    300|138390|   4.0|945188751|\n",
            "|   1307|138390|   5.0|945188823|\n",
            "|   1148|138390|   4.0|945190519|\n",
            "|   2502|138390|   4.0|945189407|\n",
            "|   1961|138390|   4.0|945189487|\n",
            "|   1207|138390|   5.0|945188047|\n",
            "|    912|138390|   4.0|945190457|\n",
            "|   1247|138390|   4.0|945187161|\n",
            "|   1394|138390|   4.0|945188287|\n",
            "|    920|138390|   5.0|945190761|\n",
            "|   1968|138390|   4.0|945189507|\n",
            "|    919|138390|   5.0|945187819|\n",
            "|   2571|138390|   4.0|945188228|\n",
            "|   1225|138390|   4.0|945190669|\n",
            "|    904|138390|   5.0|945187844|\n",
            "|    903|138390|   5.0|945187939|\n",
            "+-------+------+------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGO98KnLxKpe"
      },
      "source": [
        "### Question B2\n",
        "\n",
        "> Let's imagine that all of our executors have 4GB of memory. If we consider the 'user timeline' dataset where movie ratings are greater or equal than 3.5, is it okay to store list of movie ids inside rows, as far as memory is concerned?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_ratings_df = remove_bad_ratings(ratings_df_parquet, threshold=3.5)"
      ],
      "metadata": {
        "id": "GGAUMwT2_yWw"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats(good_ratings_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "205lMUiqAAqw",
        "outputId": "86367bd2-23c9-4fb7-af60-55cdd6a7ad5b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of distinct users : 138362\n",
            "Amount of distinct movies : 22884\n",
            "Total amount of ratings : 12195566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_ratings_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVsXcl8AAJ4B",
        "outputId": "273a62fe-0458-4dd6-a7d6-c58ba348f28e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we only keep the good ratings (>=3.5) we are left with 12.2M rows, 138k users <br>\n",
        "If we consider the 'user timeline' for these 138k users we would have : <br>\n",
        "- 12.2M / 138k = 88 rated movies per user on average\n",
        "- So user_timeline would have a list of 88 integers (on average) for 138k users, so each rows holds (88+1) * 4 Bytes of memory (+1 for the userId) <br>\n",
        "\n",
        "For a total of roughly 50 MB <br>\n",
        "So it is okay to store list of movies ids in this setup"
      ],
      "metadata": {
        "id": "F3fFHBlyAHmA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rSlT9Rd3w23"
      },
      "source": [
        "### Question B3\n",
        "\n",
        "> Create a function named *compute_pairs*, that takes a user timeline dataframe as parameter, and returns a dataframe of movie pairs (generated across all movies of their timeline) following this schema:\n",
        "> - userId : integer\n",
        "> - movieId1 : integer\n",
        "> - movieId2 : integer\n",
        ">\n",
        "> You can rely on an udf to generate list of pair of movies from a list of movies.\n",
        ">\n",
        "> Test it on a toy example."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We define this as a F.udf because we want to be able to use it on a dataframe column\n",
        "@F.udf(ArrayType(ArrayType(IntegerType())))\n",
        "def generate_pairs(movie_list):\n",
        "  pairs = []\n",
        "  for i in range(len(movie_list)):\n",
        "    for j in range(i+1,len(movie_list),1):\n",
        "      pairs.append((movie_list[i],movie_list[j]))\n",
        "  return pairs\n",
        "\n",
        "# Register the UDF\n",
        "spark.udf.register(\"generate_pairs\", generate_pairs)"
      ],
      "metadata": {
        "id": "9Pc2ouQLAaOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81404e7c-58bd-4af5-a723-b05f7eb54519"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.udf.UserDefinedFunction at 0x7adfd18c34c0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pairs(user_timeline_df):\n",
        "  user_pairs = user_timeline_df.withColumn('movies_pairs', F.explode(generate_pairs(\"movies\")))\n",
        "  return user_pairs.select(\n",
        "      \"userId\",\n",
        "      F.col('movies_pairs')[0].alias(\"movieId1\"),\n",
        "      F.col('movies_pairs')[1].alias(\"movieId2\")\n",
        "  )"
      ],
      "metadata": {
        "id": "dTLQcGg4tuqF"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_pairs(compute_timeline(ratings_small_df)).head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejGfZB2lyKqf",
        "outputId": "b01dae77-a3b2-4f7a-c441-49012e70e6ca"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(userId=148, movieId1=1270, movieId2=597),\n",
              " Row(userId=148, movieId1=1270, movieId2=497),\n",
              " Row(userId=148, movieId1=1270, movieId2=587),\n",
              " Row(userId=148, movieId1=1270, movieId2=1307),\n",
              " Row(userId=148, movieId1=1270, movieId2=908)]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD-P_FNL8yEk"
      },
      "source": [
        "### Question B4\n",
        "\n",
        "> Let's imagine that all of our executors have 4GB of memory.\n",
        ">\n",
        "> If we consider If we consider the 'user timeline where movie ratings are greater or equal than 3.5, what will happen when we generate pairs dataframe for this dataset ?\n",
        ">\n",
        "> You need to consider:\n",
        "> - amount of bytes retained by lists of pairs\n",
        "> - amount of partitions we have in user timeline\n",
        ">\n",
        "> Also, consider what may happen because of skew. We may have all big user timelines inside same partition."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previously, we said user_timeline hold roughly 50 MB of memory space <br>\n",
        "For a list of size n, the list of all possible pairs of movies will be of size n choose 2 (en français **2 parmi n**) <br>\n",
        "So each user would have 88 choose 2 pairs of movies (88 being the avg of movies rated by an user). <br>\n",
        "88 choose 2 = 3800, each users has roughly 3800 pairs of movies (very rough estimate because the number of possible pairs grows very fast when n grows) for a total of roughly 3800 x 2 x 64 = 60 KB/user <br>\n",
        "We have 138k users in the user_timeline df, so the total storage is roughly 8 GB"
      ],
      "metadata": {
        "id": "rDMxvEmzGc5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_timeline = compute_timeline(good_ratings_df)"
      ],
      "metadata": {
        "id": "dH4Nt_1NUIIc"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_timeline.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1H7NPTOUeWF",
        "outputId": "5dbc9d9d-c839-4ecf-ba13-228d6d71cae8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 partitions is not enough, one executor could easily be overloaded with more than 4GB of data to deal with because of the skewing effect. <br>\n",
        "We need at least 4 partitions to be safer"
      ],
      "metadata": {
        "id": "nfUftvdaU0N1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YhKxZd6BdWx"
      },
      "source": [
        "### Question B5\n",
        "\n",
        "> Create a function named *compute_pair_frequencies*, that takes a movie pair dataframe as parameter, and returns a dataframe of movie pairs and their user count, following this schema:\n",
        "> - movieId1 : integer\n",
        "> - movieId2 : integer\n",
        "> - count : integer\n",
        ">\n",
        "> Dataframe should be **ordered**, with most frequent pairs first.\n",
        ">\n",
        "> Test it on a toy example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "7NRGsEk_aufc"
      },
      "outputs": [],
      "source": [
        "def compute_pair_frequencies(movie_pairs_df):\n",
        "    frequency_pairs = movie_pairs_df.groupBy(['movieId1','movieId2']).agg(F.count('userId').alias('count'))\n",
        "    return frequency_pairs.sort('count', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_data = [\n",
        "    (1, 311),\n",
        "    (1, 510),\n",
        "    (1, 689),\n",
        "    (1, 951),\n",
        "    (1, 933),\n",
        "    (2, 311),\n",
        "    (2, 510),\n",
        "    (3, 689),\n",
        "    (3, 951),\n",
        "    (4, 933),\n",
        "]\n",
        "\n",
        "schema = [\"userId\", \"movieId\"]\n",
        "toy_df = spark.createDataFrame(toy_data, schema=schema)\n",
        "\n",
        "test = compute_pair_frequencies(compute_pairs(compute_timeline(toy_df)))"
      ],
      "metadata": {
        "id": "XXxQMa-iMUUy"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hsNtnmJOkVK",
        "outputId": "451a597f-8d82-4d29-8561-8b2f31fb52ac"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+-----+\n",
            "|movieId1|movieId2|count|\n",
            "+--------+--------+-----+\n",
            "|     689|     951|    2|\n",
            "|     311|     510|    2|\n",
            "|     510|     951|    1|\n",
            "|     311|     689|    1|\n",
            "|     311|     951|    1|\n",
            "|     510|     689|    1|\n",
            "|     951|     933|    1|\n",
            "|     311|     933|    1|\n",
            "|     689|     933|    1|\n",
            "|     510|     933|    1|\n",
            "+--------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d81d3Thf6DPD"
      },
      "source": [
        "### Question B6\n",
        "\n",
        "> Quickly test the whole algorithm on *ratings_df* or a subset of it.\n",
        ">\n",
        "> How many shuffles for the whole algorithm ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "CiZfGfshztLZ"
      },
      "outputs": [],
      "source": [
        "test = compute_pair_frequencies(\n",
        "    compute_pairs(\n",
        "        compute_timeline(ratings_small_df)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtUFMZQhQbmP",
        "outputId": "9839cfa0-cda0-4548-8f4b-475daee2dd08"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(movieId1=296, movieId2=593, count=378),\n",
              " Row(movieId1=593, movieId2=318, count=375),\n",
              " Row(movieId1=296, movieId2=318, count=370),\n",
              " Row(movieId1=318, movieId2=356, count=335),\n",
              " Row(movieId1=318, movieId2=527, count=327),\n",
              " Row(movieId1=593, movieId2=356, count=316),\n",
              " Row(movieId1=1196, movieId2=260, count=308),\n",
              " Row(movieId1=318, movieId2=50, count=305),\n",
              " Row(movieId1=296, movieId2=50, count=304),\n",
              " Row(movieId1=296, movieId2=356, count=294)]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuqp0Y6ky8ed"
      },
      "source": [
        "## A priori\n",
        "\n",
        "> You can find a good description of Apriori algorithm here:  \n",
        "> https://en.wikipedia.org/wiki/Apriori_algorithm\n",
        ">\n",
        "> Some other resources:  \n",
        "> [Apriori — Association Rule Mining In-depth Explanation and Python Implementation](https://towardsdatascience.com/apriori-association-rule-mining-explanation-and-python-implementation-290b42afdfc6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0E8hbjPFLgd"
      },
      "source": [
        "### Question B7\n",
        "\n",
        "> Implement your own version of A priori to compute most frequent pairs and quickly test it on *ratings_df* or a subset of it.\n",
        ">\n",
        "> You may want to rely on *F.explode* as an alternative to udf."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Apriori_B7(ratings_df, support_threshold=10):\n",
        "\n",
        "  #[---K=1---]\n",
        "  candidates_k1 = ratings_df\\\n",
        "                  .groupBy('movieId')\\\n",
        "                  .agg(F.count('userId').alias('support'))\\\n",
        "                  .filter(f'support >= {support_threshold}')\n",
        "  #[---K=2---]\n",
        "  K=2\n",
        "  #UDF to generate subsets of length K\n",
        "  @F.udf(ArrayType(ArrayType(IntegerType())))\n",
        "  def get_combinations(movie_list):\n",
        "    return [subset for subset in combinations(movie_list, r=K)]\n",
        "\n",
        "  # Transforms the previous candidates into a set like this : {276,165,956,...}\n",
        "  candidates_k1 = set(candidates_k1.select('movieId').rdd.map(lambda x:x.movieId).collect())\n",
        "  # and broadcast it to the partitions\n",
        "  broadcast_set = spark.sparkContext.broadcast(candidates_k1)\n",
        "  print(\"candidates_k1 :\", broadcast_set.value)\n",
        "  # UDF to prune i.e. check if the generated candidates belong to the previous candidates set\n",
        "  @udf(BooleanType())\n",
        "  def prune(movie):\n",
        "      if movie not in broadcast_set.value:\n",
        "          return False\n",
        "      return True\n",
        "  # Note : We use Python sets here to efficiently search if an item belongs to a set (membership test in O(1) time instead of doing a linear search with .isin())\n",
        "\n",
        "  candidates_k2 = compute_timeline(ratings_df.filter(prune(F.col('movieId'))))\\\n",
        "                  .withColumn(\"movie_pairs\", F.explode(get_combinations(\"movies\")))\\\n",
        "                  .groupBy('movie_pairs')\\\n",
        "                  .agg(F.count('userId')\\\n",
        "                  .alias('support'))\\\n",
        "                  .filter(F.col('support')>=support_threshold)\\\n",
        "                  .sort('support', ascending=False)\n",
        "  return candidates_k2"
      ],
      "metadata": {
        "id": "pbWz_uHKYK5o"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Apriori_B7(ratings_small_df,250).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4vK-7MPY4dY",
        "outputId": "1ce8ffdd-564e-47bc-98ec-5e8f837b7dca"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "candidates_k1 : {1, 4993, 4226, 260, 2571, 780, 2959, 527, 150, 541, 32, 296, 1193, 2858, 1196, 1197, 1198, 47, 50, 1210, 318, 5952, 457, 2762, 588, 589, 590, 593, 858, 480, 608, 356, 364, 2028, 110, 1136, 1270, 3578}\n",
            "+------------+-------+\n",
            "| movie_pairs|support|\n",
            "+------------+-------+\n",
            "|  [296, 593]|    378|\n",
            "|  [593, 318]|    375|\n",
            "|  [296, 318]|    370|\n",
            "|  [318, 356]|    335|\n",
            "|  [318, 527]|    327|\n",
            "|  [593, 356]|    316|\n",
            "| [1196, 260]|    308|\n",
            "|   [318, 50]|    305|\n",
            "|   [296, 50]|    304|\n",
            "|  [296, 356]|    294|\n",
            "| [2571, 318]|    287|\n",
            "|  [593, 527]|    286|\n",
            "| [1210, 260]|    286|\n",
            "|  [356, 110]|    277|\n",
            "|   [593, 50]|    273|\n",
            "|  [318, 110]|    272|\n",
            "|  [527, 356]|    271|\n",
            "|[1210, 1196]|    270|\n",
            "|  [296, 527]|    269|\n",
            "|   [296, 47]|    263|\n",
            "+------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYjT4dDVFSGv"
      },
      "source": [
        "### Question B8\n",
        "\n",
        "> Implement your own version of A priori to compute most frequent triplets.\n",
        ">\n",
        "> A this stage of the 'A priori' section, you are probably doing the same thing multiple times.\n",
        ">\n",
        "> Maybe it's time to factorize your code..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Factorized version\n",
        "\n",
        "def generate_candidates(ratings_df, previous_candidates_set, K, support_threshold):\n",
        "    '''\n",
        "    Takes the previous candidates set, generates all K-itemsets off of this set\n",
        "    then filter out the itemsets whose support is below the threshold\n",
        "    '''\n",
        "    @F.udf(ArrayType(ArrayType(IntegerType())))\n",
        "    def get_combinations(movie_list):\n",
        "      return [subset for subset in combinations(movie_list, r=K)]\n",
        "\n",
        "    result = compute_timeline(\n",
        "        ratings_df.filter(\n",
        "            F.col('movieId').isin(previous_candidates_set)\n",
        "        )\n",
        "    )\\\n",
        "    .withColumn(f\"{K}-itemsets\", F.explode(get_combinations(F.col(\"movies\"))))\\\n",
        "    .groupBy(f\"{K}-itemsets\")\\\n",
        "    .agg(F.count('userId').alias('support'))\\\n",
        "    .filter(F.col('support')>=support_threshold)\n",
        "\n",
        "    return result\n",
        "\n",
        "def Apriori_B8(ratings_df, support_threshold=10, max_K=3):\n",
        "  #[---K=1---]\n",
        "  K=1\n",
        "  candidates_k1 = ratings_df\\\n",
        "                  .groupBy('movieId')\\\n",
        "                  .agg(F.count('userId').alias('support'))\\\n",
        "                  .filter(f'support >= {support_threshold}')\n",
        "  candidates = set(candidates_k1.select('movieId').rdd.map(lambda x:x.movieId).collect())\n",
        "\n",
        "  #[--- K=2 -> max_K-1 ---]\n",
        "\n",
        "  for K in range(2, max_K, 1):\n",
        "      broadcast_set = spark.sparkContext.broadcast(candidates)\n",
        "      print(f\"candidates_k{K-1} (length={len(broadcast_set.value)}) :\", broadcast_set.value)\n",
        "      candidates = set(\n",
        "          generate_candidates(\n",
        "              ratings_df=ratings_df,\n",
        "              previous_candidates_set=broadcast_set.value,\n",
        "              K=K,\n",
        "              support_threshold=support_threshold\n",
        "          )\n",
        "          .withColumn('candidates', F.explode(f\"{K}-itemsets\"))\\\n",
        "          .select('candidates').rdd.map(lambda x:x.candidates)\\\n",
        "          .collect()\n",
        "      )\n",
        "\n",
        "  #[---K=max_K---]\n",
        "\n",
        "  broadcast_set = spark.sparkContext.broadcast(candidates)\n",
        "  print(f\"candidates_k{max_K-1} (length={len(broadcast_set.value)}) :\", broadcast_set.value)\n",
        "\n",
        "  candidates = generate_candidates(\n",
        "                  ratings_df=ratings_df,\n",
        "                  previous_candidates_set=broadcast_set.value,\n",
        "                  K=max_K,\n",
        "                  support_threshold=support_threshold\n",
        "              )\\\n",
        "              .sort('support', ascending=False)\n",
        "\n",
        "  return candidates"
      ],
      "metadata": {
        "id": "zCiY76pVqBur"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Apriori_B8(ratings_small_df,150,3).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJm3-C2BTndK",
        "outputId": "cb69e6cf-e834-442a-8062-9a42b9260c50"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "candidates_k1 (length=128) : {1, 33794, 2571, 1036, 527, 17, 21, 539, 541, 32, 34, 36, 3114, 1580, 47, 1073, 50, 1079, 1089, 2115, 1097, 1610, 587, 588, 3147, 590, 589, 592, 593, 1617, 595, 597, 608, 110, 111, 1136, 4226, 648, 1682, 150, 2716, 165, 1704, 1193, 1196, 1197, 1198, 1200, 1206, 1208, 1721, 1210, 1213, 1214, 58559, 7361, 1219, 1732, 1221, 1222, 1225, 2762, 3793, 4306, 1240, 6874, 733, 1246, 223, 1247, 5349, 6377, 1258, 1259, 750, 1265, 2291, 1270, 1784, 260, 778, 1291, 780, 2324, 4886, 2329, 1307, 293, 296, 5418, 2858, 318, 5952, 5445, 858, 2396, 349, 4963, 356, 357, 2918, 1387, 364, 4973, 377, 380, 4993, 4995, 1923, 904, 6539, 2959, 912, 919, 924, 3996, 1961, 1968, 2997, 2502, 457, 480, 2028, 7153, 500, 1527, 3578, 508}\n",
            "candidates_k2 (length=58) : {1, 4993, 4226, 260, 1291, 1036, 2571, 780, 2959, 527, 150, 2329, 541, 32, 296, 1193, 2858, 1704, 1196, 1197, 1198, 47, 1961, 50, 2997, 1210, 1213, 318, 1214, 5952, 1089, 1221, 457, 2762, 588, 589, 590, 593, 4306, 595, 1240, 858, 608, 480, 356, 364, 2028, 110, 111, 1136, 1265, 7153, 500, 1270, 1527, 377, 3578, 380}\n",
            "+------------------+-------+\n",
            "|3-itemsets        |support|\n",
            "+------------------+-------+\n",
            "|[296, 593, 318]   |268    |\n",
            "|[1210, 1196, 260] |242    |\n",
            "|[593, 318, 356]   |234    |\n",
            "|[296, 318, 50]    |230    |\n",
            "|[296, 318, 356]   |224    |\n",
            "|[593, 318, 527]   |222    |\n",
            "|[1198, 1196, 260] |222    |\n",
            "|[296, 593, 50]    |219    |\n",
            "|[2571, 1196, 260] |219    |\n",
            "|[296, 593, 356]   |216    |\n",
            "|[593, 318, 50]    |213    |\n",
            "|[296, 593, 47]    |210    |\n",
            "|[296, 47, 318]    |209    |\n",
            "|[296, 318, 527]   |207    |\n",
            "|[318, 527, 356]   |206    |\n",
            "|[593, 47, 318]    |206    |\n",
            "|[318, 356, 110]   |204    |\n",
            "|[296, 593, 527]   |200    |\n",
            "|[1198, 1210, 1196]|198    |\n",
            "|[296, 2571, 318]  |197    |\n",
            "+------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRUB_yQA7I-m"
      },
      "source": [
        "## 3. FP-Growth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71Xd8iUHaufe"
      },
      "source": [
        "> You can find a good description of FP-Growth algorithm with Spark here:  \n",
        "> https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html\n",
        ">\n",
        "> Some other resources:  \n",
        "[FP Growth — Frequent Pattern Generation in Data Mining with Python Implementation](https://towardsdatascience.com/fp-growth-frequent-pattern-generation-in-data-mining-with-python-implementation-244e561ab1c3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a5CJmMyFW9Q"
      },
      "source": [
        "### Question B9\n",
        "\n",
        "> Use the Spark version of FP-Growth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_timeline = compute_timeline(ratings_small_df)"
      ],
      "metadata": {
        "id": "rxnyQ2zalz3W"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "3N75ii5Hauff"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.fpm import FPGrowth\n",
        "\n",
        "fpGrowth = FPGrowth(itemsCol='movies', minSupport=0.1, minConfidence=0.5)\n",
        "model = fpGrowth.fit(user_timeline)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display frequent itemsets.\n",
        "@F.udf\n",
        "def get_len(item_list):\n",
        "    return len(item_list)\n",
        "model.freqItemsets.filter(get_len(F.col('items'))>=2).sort('freq', ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxHsADUHmKff",
        "outputId": "9449c211-3f71-4334-9ad4-e4509aa4b300"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----+\n",
            "|          items|freq|\n",
            "+---------------+----+\n",
            "|     [296, 593]| 378|\n",
            "|     [593, 318]| 375|\n",
            "|     [296, 318]| 370|\n",
            "|     [356, 318]| 335|\n",
            "|     [527, 318]| 327|\n",
            "|     [356, 593]| 316|\n",
            "|    [1196, 260]| 308|\n",
            "|      [50, 318]| 305|\n",
            "|      [50, 296]| 304|\n",
            "|     [356, 296]| 294|\n",
            "|    [2571, 318]| 287|\n",
            "|    [1210, 260]| 286|\n",
            "|     [527, 593]| 286|\n",
            "|     [110, 356]| 277|\n",
            "|      [50, 593]| 273|\n",
            "|     [110, 318]| 272|\n",
            "|     [527, 356]| 271|\n",
            "|   [1210, 1196]| 270|\n",
            "|     [527, 296]| 269|\n",
            "|[296, 593, 318]| 268|\n",
            "+---------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display generated association rules.\n",
        "model.associationRules.sort('confidence', ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofS_BvDUmP2w",
        "outputId": "c4bc0f91-322c-44f9-f712-305521314857"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+------------------+------------------+-------------------+\n",
            "|          antecedent|consequent|        confidence|              lift|            support|\n",
            "+--------------------+----------+------------------+------------------+-------------------+\n",
            "|[1291, 1210, 1198...|    [1196]|0.9857142857142858|3.5369747899159667|0.10283159463487332|\n",
            "|[1210, 1198, 260,...|    [1196]|0.9782608695652174| 3.510230179028133|0.10059612518628912|\n",
            "|   [1291, 1210, 260]|    [1196]|0.9731543624161074| 3.491906829846033|0.10804769001490314|\n",
            "|        [1240, 1210]|    [1196]| 0.972027972027972|  3.48786507610037|0.10357675111773472|\n",
            "|  [7153, 5952, 2571]|    [4993]|0.9705882352941176| 4.460717163577759|0.12295081967213115|\n",
            "|  [1291, 1210, 1198]|    [1196]|0.9673202614379085| 3.470972702806613|0.11028315946348734|\n",
            "|   [1210, 1198, 260]|    [1196]|0.9629629629629629|3.4553376906318083|0.13561847988077497|\n",
            "|         [1221, 296]|     [858]|0.9615384615384616|3.6451542807475015|0.11177347242921014|\n",
            "|         [1221, 318]|     [858]|0.9612903225806452|3.6442135957718245|0.11102831594634874|\n",
            "|        [7153, 5952]|    [4993]|0.9607843137254902| 4.415659414450712|0.14605067064083457|\n",
            "|   [1210, 260, 2571]|    [1196]|0.9572192513368984|  3.43472790185593|0.13338301043219075|\n",
            "|         [1221, 593]|     [858]|0.9551282051282052| 3.620853252209185|0.11102831594634874|\n",
            "|        [5952, 1196]|    [4993]|0.9539473684210527| 4.384237563085796|0.10804769001490314|\n",
            "|  [1210, 1198, 2571]|    [1196]|0.9536423841059603|3.4218932606155046|0.10730253353204174|\n",
            "|[1291, 1210, 1196...|    [1198]|0.9517241379310345| 3.470689655172414|0.10283159463487332|\n",
            "|   [1270, 1210, 260]|    [1196]|0.9503105590062112|3.4099378881987583|0.11400894187779434|\n",
            "|   [1210, 1198, 318]|    [1196]|0.9466666666666667|3.3968627450980393|0.10581222056631892|\n",
            "|         [7153, 356]|    [4993]|0.9452054794520548| 4.344060799399512|0.10283159463487332|\n",
            "|   [1291, 1196, 260]|    [1198]|0.9451219512195121| 3.446613202545069|0.11549925484351714|\n",
            "|        [7153, 1196]|    [4993]|0.9440559440559441| 4.338777660695468|0.10059612518628912|\n",
            "+--------------------+----------+------------------+------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform examines the input items against all the association rules and summarize the\n",
        "# consequents as prediction\n",
        "model.transform(user_timeline).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gj6uMSBmVZi",
        "outputId": "68cadefd-e4f5-4528-8b17-c078a015de8c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+\n",
            "|userId|movies                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |prediction                                                                                                            |\n",
            "+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+\n",
            "|148   |[1270, 597, 497, 587, 1307, 908, 1210, 539, 1197, 912, 440, 4995, 339, 17, 39, 736, 356, 3751, 4306, 4886, 1097]                                                                                                                                                                                                                                                                                                                                                                                          |[1198, 1196, 260, 296, 2571, 1, 593, 318, 50, 110, 2762, 1136, 527, 4993, 2959, 5952]                                 |\n",
            "|229   |[593, 329, 2628, 47, 2329, 3147, 6, 474, 16, 292, 2571, 780, 1527, 316, 318, 231, 733, 161, 1356, 1625, 589, 527, 293, 2858, 1213, 457, 1617, 110, 150, 2353, 2028, 2762, 1584, 1580]                                                                                                                                                                                                                                                                                                                     |[296, 356, 480, 4993, 1198, 2959, 1196, 260, 50, 1210, 858, 1270, 4226, 32, 608]                                      |\n",
            "|307   |[858, 1210, 1, 780, 1527, 17, 733, 1356, 62, 1393, 141, 260]                                                                                                                                                                                                                                                                                                                                                                                                                                              |[296, 2571, 1198, 593, 356, 1196, 318, 1270, 1291, 589, 480, 1221]                                                    |\n",
            "|326   |[329, 1356, 260]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |[1210, 1198, 1196, 296, 2571, 593, 356, 318]                                                                          |\n",
            "|463   |[296, 593, 34, 223, 111, 47, 339, 590, 318, 17, 161, 39, 509, 364, 288, 25, 62, 21, 595, 457, 608, 141, 11, 110, 150, 454, 337, 551, 36]                                                                                                                                                                                                                                                                                                                                                                  |[356, 527, 480, 50, 32, 2571, 589, 260, 2858, 588, 1, 2959]                                                           |\n",
            "|471   |[858, 1721, 1270, 1265, 588, 2797, 597, 593, 1198, 1259, 1201, 2683, 2355, 587, 1210, 1961, 1291, 539, 2628, 1207, 47, 912, 2329, 1304, 6, 500, 4995, 920, 919, 1517, 1028, 8360, 2268, 2571, 4034, 1225, 1220, 1073, 590, 318, 1219, 3408, 594, 6874, 2918, 1358, 1234, 2194, 50, 5989, 527, 1704, 364, 356, 62, 480, 1610, 1784, 6377, 1221, 1393, 595, 8636, 457, 608, 4306, 953, 592, 4963, 1196, 5349, 508, 110, 260, 2028, 349, 454, 2762, 2115, 1193, 3578, 1090, 1101, 1278, 1258, 1097, 1387, 36]|[296, 2858, 4993, 2959, 5952, 589, 1, 150, 1197, 4226, 1240, 32, 1136, 1036]                                          |\n",
            "|496   |[858, 1270, 588, 2396, 34, 1198, 1259, 2355, 587, 1307, 908, 2804, 1291, 2791, 367, 1197, 1288, 1266, 1304, 1, 440, 235, 2571, 1222, 1220, 1136, 1240, 590, 1641, 2716, 2174, 1036, 39, 2918, 3052, 1234, 1200, 589, 1214, 356, 1923, 480, 2291, 1221, 21, 1079, 457, 1196, 260, 2028, 1080, 2000, 551, 1278, 1387, 1580]                                                                                                                                                                                 |[1210, 50, 2858, 4993, 527, 296, 593, 318, 2959, 110, 5952, 3578, 47, 2762, 364, 595, 150]                            |\n",
            "|537   |[1270, 588, 1653, 223, 7361, 4993, 3793, 919, 4226, 235, 2571, 6333, 1527, 318, 6874, 2959, 7438, 750, 364, 4878, 6377, 8636, 5952, 5349, 7153, 2762, 4886, 6016, 551]                                                                                                                                                                                                                                                                                                                                    |[50, 2858, 296, 593, 356, 47, 1196, 260, 4306, 480, 1, 457, 595, 1198, 1210, 110, 1197, 527, 858, 2028, 3578]         |\n",
            "|766   |[588, 296, 497, 253, 329, 539, 367, 47, 1, 500, 377, 780, 316, 318, 380, 527, 364, 356, 62, 480, 595, 32, 11, 110, 150, 357, 36]                                                                                                                                                                                                                                                                                                                                                                          |[593, 457, 50, 2571, 589, 260, 608, 2858, 2959]                                                                       |\n",
            "|823   |[593, 539, 500, 377, 780, 590, 318, 17, 733, 736, 509, 356, 62, 480, 141, 11, 150]                                                                                                                                                                                                                                                                                                                                                                                                                        |[296, 527, 110, 457, 50, 2571, 47, 589, 260]                                                                          |\n",
            "|833   |[329, 474, 377, 339, 292, 165, 316, 318, 161, 380, 648, 527, 364, 356, 480, 457, 150, 349, 454]                                                                                                                                                                                                                                                                                                                                                                                                           |[296, 110, 593, 50, 2571, 47, 589, 588, 1, 595]                                                                       |\n",
            "|960   |[597, 34, 587, 253, 329, 539, 367, 47, 440, 500, 377, 292, 780, 590, 316, 318, 161, 39, 589, 527, 288, 356, 21, 595, 457, 11, 150, 454, 357]                                                                                                                                                                                                                                                                                                                                                              |[296, 480, 110, 593, 50, 2571, 1196, 260, 32, 364, 588]                                                               |\n",
            "|1037  |[2692, 1288, 1247, 919, 2571, 1220, 318, 2324, 2918, 50, 2028, 1080, 2700, 2599, 2706]                                                                                                                                                                                                                                                                                                                                                                                                                    |[296, 527, 110, 593, 356, 260, 1198, 457, 47, 2858, 4993, 2959, 2762, 1196, 1210, 858, 1270, 4226]                    |\n",
            "|1088  |[1073, 733, 736, 648, 1200, 1214]                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |[296, 2571, 1198, 593, 1196, 260, 318]                                                                                |\n",
            "|1096  |[858, 593, 1198, 1201, 1207, 4993, 923, 919, 1028, 2571, 1250, 318, 1234, 750, 527, 1221, 1203, 608, 1196, 541, 7153, 1193]                                                                                                                                                                                                                                                                                                                                                                               |[296, 260, 50, 2858, 356, 5952, 2959, 2762, 1210, 1291, 1270, 47, 2028, 4226, 3578, 4306, 110, 1197, 589, 1036, 1, 32]|\n",
            "|1238  |[1198, 1259, 1210, 1291, 924, 919, 1252, 904, 1732, 1073, 903, 380, 1625, 1617, 1196, 260]                                                                                                                                                                                                                                                                                                                                                                                                                |[2571, 356, 318, 1270, 296, 1, 593, 480, 858, 527, 4993, 589, 1197, 1240, 2762, 2028, 50, 1136, 110, 457, 1036]       |\n",
            "|1342  |[58559, 2502, 79132, 4226, 2571, 318, 1213, 260, 3949]                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[1210, 1196, 2858, 4993, 296, 593, 356, 1198, 2959, 2762, 50, 527, 858, 1270, 47, 2028, 589, 7361]                    |\n",
            "|1545  |[588, 597, 593, 34, 300, 587, 329, 367, 47, 440, 500, 377, 292, 165, 316, 318, 231, 586, 161, 39, 589, 364, 356, 480, 592, 11, 110, 150, 349, 454, 357]                                                                                                                                                                                                                                                                                                                                                   |[296, 527, 457, 1, 595, 50, 2571, 1196, 260, 32]                                                                      |\n",
            "|1580  |[908, 1197, 1196, 260]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[1210, 1291, 1198, 1270, 296, 2571, 593, 356, 318, 1136, 1, 4993, 858, 589, 2028]                                     |\n",
            "|1591  |[1580, 1721, 1127, 1198, 1210, 924, 1304, 1682, 1641, 231, 356, 480, 32, 1196, 150, 1101, 1584]                                                                                                                                                                                                                                                                                                                                                                                                           |[296, 527, 110, 593, 457, 318, 2571, 1, 260, 1270, 1291, 50, 47, 858, 4993, 589, 1197, 1240, 2762, 2028, 1036]        |\n",
            "+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj1HcZkRGRRs"
      },
      "source": [
        "# Part C - Probabilistic Latent Semantic Model (5 points)\n",
        "\n",
        "> Aim of this section is to implement a Probabilistic Latent Semantic Model.\n",
        ">\n",
        "> We will use an expectation maximization algorithm to learn its parameters.\n",
        ">\n",
        "> In the first set of questions you will implement some utility functions to deal with matrix manipulations.\n",
        ">\n",
        "> In the second set of questions, you will implement the algorithm itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "papRtCuWJxho"
      },
      "source": [
        "## Matrix manipulation functions\n",
        "\n",
        "> We will implement matrix operations that will be usefull to run the PLSI algorithm afterwards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtRkYH9NC-RO"
      },
      "source": [
        "### Question CMatrix1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzVkNoL4KQ0L"
      },
      "source": [
        "#### `matrix_sum_rows`\n",
        "\n",
        "> Takes a matrix (a column containing arrays of fixed length) and returns the sum of each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "P1VyUs79KUeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6040bf5-46a2-47b6-dc0d-161ccf335f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input array\n",
            "[[ 1.  2.  3.  4.]\n",
            " [40. 30. 20. 10.]]\n",
            "Expected output\n",
            "[ 10. 100.]\n",
            "Obtained output\n",
            "+------------------------+-------+\n",
            "|matrix                  |row_sum|\n",
            "+------------------------+-------+\n",
            "|[1.0, 2.0, 3.0, 4.0]    |10.0   |\n",
            "|[40.0, 30.0, 20.0, 10.0]|100.0  |\n",
            "+------------------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Hint: https://stackoverflow.com/a/57448698/2015762\n",
        "def matrix_sum_rows(col_name, length_of_array):\n",
        "    return sum([F.col(col_name).getItem(i) for i in range(length_of_array)])\n",
        "\n",
        "input_array = np.array([[1, 2, 3, 4], [40, 30, 20, 10]], dtype=float)\n",
        "expected_output = input_array.sum(axis=1)\n",
        "print('Input array')\n",
        "print(input_array)\n",
        "print('Expected output')\n",
        "print(expected_output)\n",
        "print('Obtained output')\n",
        "(\n",
        "    spark.sparkContext.parallelize(input_array.tolist()).map(lambda x: Row(matrix=x)).toDF()\n",
        "    .withColumn('row_sum', matrix_sum_rows('matrix', 4))\n",
        ").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRczikuRIiwH"
      },
      "source": [
        "### Question CMatrix2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFJwS3HAKYDj",
        "tags": []
      },
      "source": [
        "#### `matrix_sum_columns`\n",
        "\n",
        "> Takes a matrix (a column containing arrays of fixed length) and returns the sum of each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "df36LGTSKclE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a569b5b-56ab-42a7-b702-ffadef06cea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input array\n",
            "[[ 1.  2.  3.  4.]\n",
            " [40. 30. 20. 10.]]\n",
            "Expected output\n",
            "[41. 32. 23. 14.]\n",
            "Obtained output\n",
            "+------------------------+\n",
            "|col_sum                 |\n",
            "+------------------------+\n",
            "|[41.0, 32.0, 23.0, 14.0]|\n",
            "+------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Hint: https://stackoverflow.com/a/54382990/2015762\n",
        "def matrix_sum_columns(col_name, length_of_array):\n",
        "    return F.array([F.sum(F.col(col_name)[col_index]) for col_index in range(length_of_array)])\n",
        "\n",
        "\n",
        "input_array = np.array([[1, 2, 3, 4], [40, 30, 20, 10]], dtype=float)\n",
        "expected_output = input_array.sum(axis=0)\n",
        "print('Input array')\n",
        "print(input_array)\n",
        "print('Expected output')\n",
        "print(expected_output)\n",
        "print('Obtained output')\n",
        "(\n",
        "    spark.sparkContext.parallelize(input_array.tolist()).map(lambda x: Row(matrix=x)).toDF()\n",
        "    .select(matrix_sum_columns('matrix', 4).alias('col_sum'))\n",
        ").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47EAeV3_IqpH"
      },
      "source": [
        "### Question CMatrix3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCWm2vK4KhES"
      },
      "source": [
        "#### `matrix_normalize_rows`\n",
        "\n",
        "> Takes a matrix (a column containing arrays of fixed length) and returns the same matrix where the rows have been divded by their sum, such that each row sums to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "XsNhEtSuKZBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65122b9-d2a4-451a-8b8c-2158f9c3102b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input array\n",
            "[[ 1.  2.  3.  4.]\n",
            " [40. 30. 20. 10.]]\n",
            "Expected output\n",
            "[[0.1 0.2 0.3 0.4]\n",
            " [0.4 0.3 0.2 0.1]]\n",
            "Obtained output\n",
            "+--------------------+\n",
            "|normalized_elements |\n",
            "+--------------------+\n",
            "|[0.1, 0.2, 0.3, 0.4]|\n",
            "|[0.4, 0.3, 0.2, 0.1]|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def matrix_normalize_rows(col_name, length_of_array):\n",
        "    rows_sum = sum([F.col(col_name).getItem(i) for i in range(length_of_array)])\n",
        "    return F.array([F.col(col_name).getItem(i)/rows_sum for i in range(length_of_array)])\n",
        "\n",
        "\n",
        "input_array = np.array([[1, 2, 3, 4], [40, 30, 20, 10]], dtype=float)\n",
        "expected_output = input_array / input_array.sum(axis=1).reshape(-1, 1)\n",
        "print('Input array')\n",
        "print(input_array)\n",
        "print('Expected output')\n",
        "print(expected_output)\n",
        "print('Obtained output')\n",
        "(\n",
        "    spark.sparkContext.parallelize(input_array.tolist()).map(lambda x: Row(numbers=x)).toDF()\n",
        "    .select(matrix_normalize_rows('numbers', 4).alias('normalized_elements'))\n",
        ").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdOIy3UaIu9P"
      },
      "source": [
        "### Question CMatrix4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPWSuJVkKkoS"
      },
      "source": [
        "#### `matrix_elementwise_product`\n",
        "\n",
        "> Takes two matrices and return their elementwise product (aka. Hadamard product)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "4EHBDsfzKovu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d8e18a-9c38-440a-d848-a187a8e09e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input array\n",
            "[[ 1.  2.  3.  4.]\n",
            " [40. 30. 20. 10.]]\n",
            "[[ 1.  2.  1.  2.]\n",
            " [10. 20. 10. 20.]]\n",
            "Expected output\n",
            "[[  1.   4.   3.   8.]\n",
            " [400. 600. 200. 200.]]\n",
            "Obtained output\n",
            "+----------------------------+\n",
            "|elementwise_products        |\n",
            "+----------------------------+\n",
            "|[1.0, 4.0, 3.0, 8.0]        |\n",
            "|[400.0, 600.0, 200.0, 200.0]|\n",
            "+----------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def matrix_elementwise_product(col_name_1, col_name_2, length_of_array):\n",
        "    return F.array([F.col(col_name_1).getItem(i)*F.col(col_name_2).getItem(i) for i in range(length_of_array)])\n",
        "\n",
        "input_array_1 = np.array([[1, 2, 3, 4], [40, 30, 20, 10]], dtype=float)\n",
        "input_array_2 = np.array([[1, 2, 1, 2], [10, 20, 10, 20]], dtype=float)\n",
        "expected_output = input_array_1 * input_array_2\n",
        "print('Input array')\n",
        "print(input_array_1)\n",
        "print(input_array_2)\n",
        "print('Expected output')\n",
        "print(expected_output)\n",
        "print('Obtained output')\n",
        "(\n",
        "    spark.sparkContext.parallelize(zip(input_array.tolist(), input_array_2.tolist())).map(lambda x: Row(numbers_1=x[0], numbers_2=x[1])).toDF()\n",
        "    .select(matrix_elementwise_product('numbers_1', 'numbers_2', 4).alias('elementwise_products'))\n",
        ").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G7umlGqIx0F"
      },
      "source": [
        "### Question CMatrix5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLayzlbbKvS2"
      },
      "source": [
        "#### `matrix_elementwise_divide`\n",
        "\n",
        "> Takes two matrices and divide elementwise the first one by the second one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "rZ2Mhzj9KwT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b26973-0136-4846-9877-9c890fc60722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input array\n",
            "[[ 1.  2.  3.  4.]\n",
            " [40. 30. 20. 10.]]\n",
            "[[ 1.  2.  1.  2.]\n",
            " [10. 20. 10. 20.]]\n",
            "Expected output\n",
            "[[1.  1.  3.  2. ]\n",
            " [4.  1.5 2.  0.5]]\n",
            "Obtained output\n",
            "+--------------------+\n",
            "|elementwise_divided |\n",
            "+--------------------+\n",
            "|[1.0, 1.0, 3.0, 2.0]|\n",
            "|[4.0, 1.5, 2.0, 0.5]|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def matrix_elementwise_divide(col_name_1, col_name_2, length_of_array):\n",
        "    return F.array([F.col(col_name_1).getItem(i)/F.col(col_name_2).getItem(i) for i in range(length_of_array)])\n",
        "\n",
        "input_array_1 = np.array([[1, 2, 3, 4], [40, 30, 20, 10]], dtype=float)\n",
        "input_array_2 = np.array([[1, 2, 1, 2], [10, 20, 10, 20]], dtype=float)\n",
        "expected_output = input_array_1 / input_array_2\n",
        "print('Input array')\n",
        "print(input_array_1)\n",
        "print(input_array_2)\n",
        "print('Expected output')\n",
        "print(expected_output)\n",
        "print('Obtained output')\n",
        "(\n",
        "    spark.sparkContext.parallelize(zip(input_array.tolist(), input_array_2.tolist())).map(lambda x: Row(numbers_1=x[0], numbers_2=x[1])).toDF()\n",
        "    .select(matrix_elementwise_divide('numbers_1', 'numbers_2', 4).alias('elementwise_divided'))\n",
        ").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwbYk4FxJ4oF"
      },
      "source": [
        "## PLSI\n",
        "\n",
        "> With\n",
        "> * N the number of users u\n",
        "> * M the number of movies s\n",
        "> * L the number of latent classes z\n",
        "> * T number of (user, movie) interactions (each interaction (s_t, u_t) means user u_t liked movie s_t)\n",
        ">\n",
        ">We suppose that the probability that a user will like a movie can be written in the form of a mixture model given by the equation:\n",
        "$$\n",
        "p(s|u) = \\sum_{z=1}^L p(s|z) p(z|u)\n",
        "$$\n",
        "And we want to optimize the log-likelihood of the observed user interactions\n",
        "$$\n",
        "\\mathcal{L} = - \\dfrac{1}{T} \\sum_{1}^{T} \\log p(s_t|u_t)\n",
        "$$\n",
        "That can be done using an EM algorithm working as follow:\n",
        ">\n",
        "> Init for $i=0$, and for all $u$, $s$ and $z$, $p_{0}(s|z)$ and $p_{0}(z|u)$.\n",
        ">\n",
        "> Then, for each step $i$:\n",
        ">\n",
        ">**E step**\n",
        ">\n",
        ">For each interaction (u, s), compute for all z = 1, ..., L:\n",
        "$$\n",
        "p_{i+1}(z|(u, s)) = \\frac{p_{i}(s|z) p_{i}(z|u)}{\\sum_{z'} p_{i}(s|z') p_{i}(z'|u)}\n",
        "$$\n",
        ">\n",
        ">**M step**\n",
        ">\n",
        ">Find each movie probability given a latent class:\n",
        "$$\n",
        "p_{i+1}(s|z) = \\frac{\\sum_u p_{i+1}(z|(u, s))}{\\sum_s \\sum_u p_{i+1}(z|(u, s))}\n",
        "$$\n",
        "$$\n",
        "\\text{that is to say} \\quad  p_{i+1}(s|z) = \\frac{N_{i+1}(z, s)}{N_{i+1}(z)}\n",
        "\\quad \\text{where} \\quad N_{i+1}(z, s) = \\sum_u p_{i+1}(z|(u, s))\n",
        "\\quad \\text{and} \\quad N_{i+1}(z) = \\sum_s N_{i+1}(z, s)\n",
        "$$\n",
        "Find each latent class probability given each user:\n",
        "$$\n",
        "p_{i+1}(z|u) = \\frac{\\sum_s p_{i+1}(z|(u, s))}{\\sum_z \\sum_s p_{i+1}(z|(u, s))}\n",
        "$$\n",
        ">\n",
        ">We will have the following dataframes\n",
        ">\n",
        ">* `count_z_s`: M rows, with columns  `movieId`, `N(z,s)`.\n",
        ">* `count_z`: 1 row, with column `N(z)`.\n",
        ">* `p_s_knowing_z`: M rows, with columns  `movieId`, `p(s|z)`. For a given z, the sum of p(s|z) equals 1.\n",
        ">* `p_z_knowing_u`: N rows, with columns `userId`, `p(z|u)`. For a given u, the sum of p(z|u) equals 1.\n",
        ">* `p_z_knowing_u_and_s`: N x M rows, with columns `userId`, `movieId`, `p(z|u,s)`.\n",
        ">\n",
        ">\n",
        "> Implement the PLSI algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "NnRkekT_aufi"
      },
      "source": [
        "### Question CPLSI1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "wDGcbe41LwPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6adc3f-cad6-4d5e-d64a-fcf723b04d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|           N(z)|\n",
            "+---------------+\n",
            "|[5.0, 8.0, 4.0]|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_count_z(count_z_s, n_latent_classes):\n",
        "    \"\"\"Compute N(z) = sum_s N(z,s)\n",
        "    \"\"\"\n",
        "    #Using matrix_sum_columns\n",
        "    return count_z_s.select(matrix_sum_columns('N(z,s)', n_latent_classes).alias('N(z)'))\n",
        "\n",
        "count_z_s = spark.sparkContext.parallelize([\n",
        "    Row(**{\"movieId\":1, \"N(z,s)\": [1., 3., 4.]}),\n",
        "    Row(**{\"movieId\":2, \"N(z,s)\": [4., 5., 0.]}),\n",
        "]).toDF()\n",
        "count_z = get_count_z(count_z_s, 3)\n",
        "count_z.show()\n",
        "# Expected [5., 8., 4.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "HG464Kgvaufj"
      },
      "source": [
        "### Question CPLSI1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "uyftz13QLyez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b69bdcf-d91b-4eca-f962-8ecbd8c1780a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------------------------------+\n",
            "|movieId|N(z,s)                                         |\n",
            "+-------+-----------------------------------------------+\n",
            "|1      |[1.2200000000000002, 0.22, 1.1500000000000001] |\n",
            "|2      |[0.43000000000000005, 1.44, 1.4700000000000002]|\n",
            "+-------+-----------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_count_z_s(p_z_knowing_u_and_s, n_latent_classes):\n",
        "    \"\"\"Compute N(z,s) = sum_u p(z|u,s)\n",
        "    \"\"\"\n",
        "    return p_z_knowing_u_and_s\\\n",
        "           .groupBy('movieId')\\\n",
        "           .agg(matrix_sum_columns(\"p(z|u,s)\", n_latent_classes).alias('N(z,s)'))\n",
        "\n",
        "#Example\n",
        "p_z_knowing_u_and_s = spark.sparkContext.parallelize([\n",
        "    Row(**{\"userId\":1, \"movieId\":1, \"p(z|u,s)\":[0.67, 0.10, 0.93]}),\n",
        "    Row(**{\"userId\":1, \"movieId\":2, \"p(z|u,s)\":[0.33, 0.63, 0.67]}),\n",
        "    Row(**{\"userId\":2, \"movieId\":1, \"p(z|u,s)\":[0.55, 0.12, 0.22]}),\n",
        "    Row(**{\"userId\":2, \"movieId\":2, \"p(z|u,s)\":[0.10, 0.81, 0.80]}),\n",
        "]).toDF()\n",
        "get_count_z_s(p_z_knowing_u_and_s, 3).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qP2ubspaufj"
      },
      "source": [
        "### Question CPLSI1.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Y-hhH_jgLzaN",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8da993d-2664-4eb3-a477-63992aee3290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+\n",
            "|movieId|           p(s|z)|\n",
            "+-------+-----------------+\n",
            "|      1|[0.2, 0.375, 1.0]|\n",
            "|      2|[0.8, 0.625, 0.0]|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_p_s_knowing_z(count_z_s, count_z, n_latent_classes):\n",
        "    \"\"\"Compute p(s|z) = N(z,s) / N(z)\n",
        "    Hint: crossJoin may help\n",
        "    \"\"\"\n",
        "    # Expected output : M rows (movieIds), columns movieId and p(s|z). For a given z, the sum of p(s|z) equals 1.\n",
        "    crossjoin = count_z_s.crossJoin(count_z)\n",
        "    return crossjoin.withColumn('p(s|z)',matrix_elementwise_divide('N(z,s)','N(z)',n_latent_classes))\\\n",
        "           .select(['movieId','p(s|z)'])\n",
        "\n",
        "get_p_s_knowing_z(count_z_s, count_z, 3).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leO3uQ-Kaufk"
      },
      "source": [
        "### Question CPLSI1.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "k8qlxgcWL2Pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070ca48c-1be2-4760-ece9-f5c3bb38bb53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------------------------------------------------+\n",
            "|userId|p(z|u)                                                       |\n",
            "+------+-------------------------------------------------------------+\n",
            "|1     |[0.3003003003003003, 0.21921921921921922, 0.4804804804804805]|\n",
            "|2     |[0.25, 0.3576923076923077, 0.3923076923076923]               |\n",
            "+------+-------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_p_z_knowing_u(p_z_knowing_u_and_s, n_latent_classes):\n",
        "    \"\"\"Compute p(z|u) = sum_s p(z|u,s) / sum_z sum_s p(z|u,s)\n",
        "    \"\"\"\n",
        "    # Input p(z|u,s) : N x M rows, with columns userId, movieId, p(z|u,s).\n",
        "    # Expected output : N rows (userIds), with columns userId, p(z|u). For a given u, the sum of p(z|u) equals 1.\n",
        "    return p_z_knowing_u_and_s\\\n",
        "           .groupBy('userId')\\\n",
        "           .agg(matrix_sum_columns('p(z|u,s)', n_latent_classes).alias('numerateur'))\\\n",
        "           .select(['userId',matrix_normalize_rows('numerateur', n_latent_classes).alias('p(z|u)')])\n",
        "\n",
        "#Example\n",
        "p_z_knowing_u_and_s = spark.sparkContext.parallelize([\n",
        "    Row(**{\"userId\":1, \"movieId\":1, \"p(z|u,s)\":[0.67, 0.10, 0.93]}),\n",
        "    Row(**{\"userId\":1, \"movieId\":2, \"p(z|u,s)\":[0.33, 0.63, 0.67]}),\n",
        "    Row(**{\"userId\":2, \"movieId\":1, \"p(z|u,s)\":[0.55, 0.12, 0.22]}),\n",
        "    Row(**{\"userId\":2, \"movieId\":2, \"p(z|u,s)\":[0.10, 0.81, 0.80]}),\n",
        "]).toDF()\n",
        "\n",
        "get_p_z_knowing_u(p_z_knowing_u_and_s,3).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb3NnhQkaufk"
      },
      "source": [
        "### Question CPLSI1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "pvjuAPagL49D"
      },
      "outputs": [],
      "source": [
        "def get_p_z_knowing_u_and_s(observed_pairs, count_z_s, count_z, p_z_knowing_u, n_latent_classes):\n",
        "    \"\"\"For all pairs of observed (u, s)\n",
        "\n",
        "    Compute p(z|u,s) = [N(z, s) / N(z) * p(z|u)] / sum_z [N(z, s) / N(z) * p(z|u)]\n",
        "                     = [p(s|z) * p(z|u)] / sum_z [p(s|z) * p(z|u)]\n",
        "    \"\"\"\n",
        "    # Using previous functions\n",
        "    # We\n",
        "    p_s_knowing_z = get_p_s_knowing_z(count_z_s, count_z, n_latent_classes)\n",
        "    p_z_knowing_u_and_s = p_s_knowing_z.crossJoin(p_z_knowing_u)\\\n",
        "                          .withColumn('[p(s|z) * p(z|u)]', matrix_elementwise_product('p(s|z)','p(z|u)', n_latent_classes))\\\n",
        "                          .withColumn('p(z|u,s)', matrix_normalize_rows('[p(s|z) * p(z|u)]', n_latent_classes))\\\n",
        "                          .select(['userId','movieId','p(z|u,s)'])\n",
        "\n",
        "    return observed_pairs.join(p_z_knowing_u_and_s, on=['userId','movieId'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example\n",
        "toy_data = spark.sparkContext.parallelize([\n",
        "    Row(**{\"userId\":1, \"movieId\":1, \"p(z|u,s)\":[0.67, 0.10, 0.93]}),\n",
        "    Row(**{\"userId\":1, \"movieId\":2, \"p(z|u,s)\":[0.33, 0.63, 0.67]}),\n",
        "    Row(**{\"userId\":2, \"movieId\":1, \"p(z|u,s)\":[0.55, 0.12, 0.22]}),\n",
        "    Row(**{\"userId\":2, \"movieId\":2, \"p(z|u,s)\":[0.10, 0.81, 0.80]}),\n",
        "]).toDF()\n",
        "\n",
        "L = 3\n",
        "get_p_z_knowing_u_and_s(\n",
        "    observed_pairs=toy_data.select(['userId','movieId']),\n",
        "    count_z_s=get_count_z_s(toy_data,L),\n",
        "    count_z=get_count_z(get_count_z_s(toy_data,L),L),\n",
        "    p_z_knowing_u=get_p_z_knowing_u(toy_data,L),\n",
        "    n_latent_classes=L\n",
        ").show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpoeMipiX8pD",
        "outputId": "ae2112a0-84fd-4294-df59-ecef9d2046a5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+---------------------------------------------------------------+\n",
            "|userId|movieId|p(z|u,s)                                                       |\n",
            "+------+-------+---------------------------------------------------------------+\n",
            "|1     |1      |[0.48061559967557416, 0.06288679032097097, 0.45649761000345496]|\n",
            "|1     |2      |[0.14546247514977023, 0.353462810167797, 0.5010747146824326]   |\n",
            "|2     |2      |[0.10939715040010185, 0.5210093223615689, 0.3695935272383292]  |\n",
            "|2     |1      |[0.4570371152902944, 0.11720867815589, 0.4257542065538155]     |\n",
            "+------+-------+---------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z19MUSvIaufk"
      },
      "source": [
        "### Question CPLSI1.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "4Lb6J5x_L7sj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09b2699-bd01-492c-efa9-62e6db8f1981"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7038967914900829"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "def log_likelihood(observed_pairs, count_z_s, count_z, p_z_knowing_u, n_latent_classes):\n",
        "\n",
        "    \"\"\"Compute the log likelihood of the observed pairs\n",
        "\n",
        "    L = - 1 / T * sum_t log[ p(s|u) ]\n",
        "      = - 1 / T * sum_t log[ sum_z p(s|z) * p(z|u) ]\n",
        "    \"\"\"\n",
        "    T = observed_pairs.count()\n",
        "    p_s_knowing_z = get_p_s_knowing_z(count_z_s, count_z, n_latent_classes)\n",
        "\n",
        "    # First compute p(s|z) * p(z|u)\n",
        "    # then log[ sum_z p(s|z) * p(z|u) ]\n",
        "    # then sum_t log[ sum_z p(s|z) * p(z|u) ]\n",
        "    # finally retrieve the value, multiply by - 1 / T\n",
        "    result = p_s_knowing_z.crossJoin(p_z_knowing_u)\\\n",
        "             .withColumn('p(s|z) * p(z|u)', matrix_elementwise_product('p(s|z)','p(z|u)', n_latent_classes))\\\n",
        "             .withColumn('log[ sum_z p(s|z) * p(z|u)]', F.log(matrix_sum_rows('p(s|z) * p(z|u)', n_latent_classes)))\\\n",
        "             .select((F.sum('log[ sum_z p(s|z) * p(z|u)]')).alias('log_likelihood'))\\\n",
        "             .rdd.map(lambda x:x.log_likelihood)\\\n",
        "             .collect()[0]/(-T)\n",
        "    return result\n",
        "\n",
        "#Example\n",
        "toy_data = spark.sparkContext.parallelize([\n",
        "    Row(**{\"userId\":1, \"movieId\":1, \"p(z|u,s)\":[0.67, 0.10, 0.93]}),\n",
        "    Row(**{\"userId\":1, \"movieId\":2, \"p(z|u,s)\":[0.33, 0.63, 0.67]}),\n",
        "    Row(**{\"userId\":2, \"movieId\":1, \"p(z|u,s)\":[0.55, 0.12, 0.22]}),\n",
        "    Row(**{\"userId\":2, \"movieId\":2, \"p(z|u,s)\":[0.10, 0.81, 0.80]}),\n",
        "]).toDF()\n",
        "\n",
        "L = 3\n",
        "log_likelihood(\n",
        "    observed_pairs=toy_data.select(['userId','movieId']),\n",
        "    count_z_s=get_count_z_s(toy_data,L),\n",
        "    count_z=get_count_z(get_count_z_s(toy_data,L),L),\n",
        "    p_z_knowing_u=get_p_z_knowing_u(toy_data,L),\n",
        "    n_latent_classes=L\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VToiqJUCaufl"
      },
      "source": [
        "### Question CPLSI1.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "W-x-AT8iL-TD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "547bca11-1446-4dae-e9a5-e3763e39fa77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+----------------------------------------------------+\n",
            "|movieId|userId|p(z|u,s)                                            |\n",
            "+-------+------+----------------------------------------------------+\n",
            "|1      |1     |[0.23018087, 9.0680015E-4, 0.0071779853, 0.76173437]|\n",
            "|2      |1     |[0.23048683, 0.279084, 0.24728674, 0.24314244]      |\n",
            "|1      |2     |[0.010815675, 0.027935416, 0.25617668, 0.7050722]   |\n",
            "|2      |2     |[0.04617858, 0.23373222, 0.5808177, 0.13927153]     |\n",
            "+-------+------+----------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import udf, explode, arrays_zip, lit\n",
        "\n",
        "def initialize_statistics(observed_pairs, n_latent_classes):\n",
        "    \"\"\"Initialize either p(s|z) and p(z|u) or p(z|(u, s)) to be able to fuel the first iteration of the EM algorithm.\n",
        "    What would happen if you initialize these to a constant value ?\n",
        "    \"\"\"\n",
        "    def generate_random_probs(n):\n",
        "        probs = np.random.rand(n)*np.random.randint(0, 100, size=n) #Doing this makes the probabilities less centered around 25%\n",
        "        normalized_probs = probs / np.sum(probs)\n",
        "        return normalized_probs.tolist()\n",
        "    generate_random_probs_udf = udf(generate_random_probs, ArrayType(FloatType()))\n",
        "\n",
        "    return observed_pairs.withColumn(\"p(z|u,s)\", generate_random_probs_udf(lit(n_latent_classes)))\n",
        "\n",
        "initialize_statistics(toy_data.select(['movieId','userId']),4).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the maximization objective is not necessarily concave, we are not guaranteed to converge to the global max. <br>\n",
        "By choosing random initial points, it allows us to reach that global minima by re-running the algorithm. <br>\n",
        "If we had chosen deterministic initial points, then we would always reach the same minima"
      ],
      "metadata": {
        "id": "pwBGBRAZ3SOS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "GtpXJgTyaufm"
      },
      "source": [
        "### Question CPLSI1.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJUUxSfPFhpv",
        "outputId": "cfb2e447-57d1-483c-972f-e8e0948febbd"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------------------+\n",
            "|userId|movieId|          p(z|u,s)|\n",
            "+------+-------+------------------+\n",
            "|     1|      1| [0.67, 0.1, 0.93]|\n",
            "|     1|      2|[0.33, 0.63, 0.67]|\n",
            "|     2|      1|[0.55, 0.12, 0.22]|\n",
            "|     2|      2|  [0.1, 0.81, 0.8]|\n",
            "+------+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "AQiwyBZVMAu-"
      },
      "outputs": [],
      "source": [
        "from pydoc import tempfilepager\n",
        "def run_plsi(observed_pairs, n_iterations, n_latent_classes, checkpoint_every=1):\n",
        "    start_init_time = time.time()\n",
        "    spark.sparkContext.setJobDescription(\"Initialization\")\n",
        "\n",
        "    temp = initialize_statistics(observed_pairs, n_latent_classes)\n",
        "    count_z_s = get_count_z_s(temp, n_latent_classes)\n",
        "    count_z = get_count_z(count_z_s, n_latent_classes)\n",
        "    p_z_knowing_u = get_p_z_knowing_u(temp, n_latent_classes)\n",
        "    llh = log_likelihood(\n",
        "        observed_pairs=observed_pairs,\n",
        "        count_z_s=count_z_s,\n",
        "        count_z=count_z,\n",
        "        p_z_knowing_u=p_z_knowing_u,\n",
        "        n_latent_classes=n_latent_classes\n",
        "    )\n",
        "    mlflow.log_metric(key=\"llh\", value=llh, step=0)\n",
        "    print(f'LLH: {llh:.10f}')\n",
        "\n",
        "    end_init_time = time.time()\n",
        "    print(f'Initialization: {end_init_time - start_init_time:.1f}s')\n",
        "\n",
        "    for i in range(n_iterations):\n",
        "        start_e_step = time.time()\n",
        "        spark.sparkContext.setJobDescription(f\"Iteration {i+1}: E-step\")\n",
        "        # E step\n",
        "        p_z_knowing_u_and_s = get_p_z_knowing_u_and_s(\n",
        "            observed_pairs=observed_pairs,\n",
        "            count_z_s=count_z_s,\n",
        "            count_z=count_z,\n",
        "            p_z_knowing_u=p_z_knowing_u,\n",
        "            n_latent_classes=n_latent_classes\n",
        "        )\n",
        "\n",
        "        end_e_step = time.time()\n",
        "        print(f'Iteration {i+1}: E-step: {end_e_step - start_e_step:.1f}s')\n",
        "\n",
        "        spark.sparkContext.setJobDescription(f\"Iteration {i+1}: M-step\")\n",
        "        # M step\n",
        "        count_z_s = get_count_z_s(p_z_knowing_u_and_s, n_latent_classes)\n",
        "        count_z = get_count_z(count_z_s, n_latent_classes)\n",
        "        # p_s_knowing_z = get_p_s_knowing_z(count_z_s, count_z, n_latent_classes)\n",
        "        p_z_knowing_u = get_p_z_knowing_u(p_z_knowing_u_and_s, n_latent_classes)\n",
        "\n",
        "        llh = log_likelihood(observed_pairs, count_z_s, count_z, p_z_knowing_u, n_latent_classes)\n",
        "        mlflow.log_metric(key=\"llh\", value=llh, step=i+1)\n",
        "\n",
        "        end_m_step = time.time()\n",
        "        print(f'Iteration {i+1}: M-step: {end_m_step - end_e_step:.1f}s')\n",
        "        print(f'LLH: {llh:.10f}')\n",
        "\n",
        "    return get_p_s_knowing_z(count_z_s, count_z, n_latent_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "er6q4Xm5Jj7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87100497-7071-42b0-e5c6-3aec5a637248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "dV0zwPSlJkqk"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpBo-j0dMGIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3f54b5-a5b3-4568-a5f0-90e0e48922fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLH: 40.7161273893\n",
            "Initialization: 9.4s\n",
            "Iteration 1: E-step: 0.3s\n",
            "Iteration 1: M-step: 35.6s\n",
            "LLH: 40.7150861633\n",
            "Iteration 2: E-step: 0.4s\n",
            "Iteration 2: M-step: 115.2s\n",
            "LLH: 40.7156397006\n",
            "Iteration 3: E-step: 0.7s\n",
            "Iteration 3: M-step: 344.1s\n",
            "LLH: 40.7163058674\n"
          ]
        }
      ],
      "source": [
        "#Very long\n",
        "n_iterations = 3\n",
        "n_latent_classes = 5\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.log_param(\"n_iterations\", n_iterations)\n",
        "    mlflow.log_param(\"n_latent_classes\", n_latent_classes)\n",
        "    run_plsi(ratings_small_df, n_iterations=n_iterations, n_latent_classes=n_latent_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK3XqiypKREd"
      },
      "source": [
        "### Question CPLSI2.1\n",
        "\n",
        "> How does the EM algorithm is supposed to scale with the number of EM steps ? Do you observe such a scaling ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER** <br>\n",
        "Each step computes 4 dataframes whose size doesn't change between iterations. <br>\n",
        "So the computational time should scale linearly with the number of steps. <br> The computation of one step should not take more time than the previous one. <br>\n",
        "Here we clearly see that each step takes more and more computational time, roughly 3 times more than the previous step"
      ],
      "metadata": {
        "id": "l7ThD_brNwoe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el3838P9aufo"
      },
      "source": [
        "### Question CPLSI2.2\n",
        "> If each step takes longer than the previous one: Try using .cache() wisely."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER** <br>\n",
        "\n",
        "We add .cache() to :\n",
        "- p_z_knowing_u_and_s\n",
        "- count_z_s\n",
        "- count_z\n",
        "- p_z_knowing_u\n",
        "<br>\n",
        "\n",
        "This way, we don't have to recompute the result of all the previous iterations to compute the values of the current iteration. <br>\n",
        "Below we defined a second version of the function :"
      ],
      "metadata": {
        "id": "4xfPSCZEQMmq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "mdRhJTWOaufo"
      },
      "outputs": [],
      "source": [
        "#same function as above, but with .cache() added to the 4 dataframes\n",
        "def run_plsi_v2(observed_pairs, n_iterations, n_latent_classes, checkpoint_every=1):\n",
        "    start_init_time = time.time()\n",
        "    spark.sparkContext.setJobDescription(\"Initialization\")\n",
        "\n",
        "    p_z_knowing_u_and_s = initialize_statistics(observed_pairs, n_latent_classes).cache()\n",
        "    count_z_s = get_count_z_s(p_z_knowing_u_and_s, n_latent_classes).cache()\n",
        "    count_z = get_count_z(count_z_s, n_latent_classes).cache()\n",
        "    p_z_knowing_u = get_p_z_knowing_u(p_z_knowing_u_and_s, n_latent_classes).cache()\n",
        "    llh = log_likelihood(\n",
        "        observed_pairs=observed_pairs,\n",
        "        count_z_s=count_z_s,\n",
        "        count_z=count_z,\n",
        "        p_z_knowing_u=p_z_knowing_u,\n",
        "        n_latent_classes=n_latent_classes\n",
        "    )\n",
        "    mlflow.log_metric(key=\"llh\", value=llh, step=0)\n",
        "    print(f'LLH: {llh:.10f}')\n",
        "\n",
        "    end_init_time = time.time()\n",
        "    print(f'Initialization: {end_init_time - start_init_time:.1f}s')\n",
        "\n",
        "    for i in range(n_iterations):\n",
        "        start_e_step = time.time()\n",
        "        spark.sparkContext.setJobDescription(f\"Iteration {i+1}: E-step\")\n",
        "        # E step\n",
        "        p_z_knowing_u_and_s = get_p_z_knowing_u_and_s(\n",
        "            observed_pairs=observed_pairs,\n",
        "            count_z_s=count_z_s,\n",
        "            count_z=count_z,\n",
        "            p_z_knowing_u=p_z_knowing_u,\n",
        "            n_latent_classes=n_latent_classes\n",
        "        ).cache()\n",
        "\n",
        "        end_e_step = time.time()\n",
        "        print(f'Iteration {i+1}: E-step: {end_e_step - start_e_step:.1f}s')\n",
        "\n",
        "        spark.sparkContext.setJobDescription(f\"Iteration {i+1}: M-step\")\n",
        "        # M step\n",
        "        count_z_s = get_count_z_s(p_z_knowing_u_and_s, n_latent_classes).cache()\n",
        "        count_z = get_count_z(count_z_s, n_latent_classes).cache()\n",
        "        p_z_knowing_u = get_p_z_knowing_u(p_z_knowing_u_and_s, n_latent_classes).cache()\n",
        "\n",
        "        llh = log_likelihood(observed_pairs, count_z_s, count_z, p_z_knowing_u, n_latent_classes)\n",
        "        mlflow.log_metric(key=\"llh\", value=llh, step=i+1)\n",
        "\n",
        "        end_m_step = time.time()\n",
        "        print(f'Iteration {i+1}: M-step: {end_m_step - end_e_step:.1f}s')\n",
        "        print(f'LLH: {llh:.10f}')\n",
        "\n",
        "    return get_p_s_knowing_z(count_z_s, count_z, n_latent_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_iterations = 6\n",
        "n_latent_classes = 5\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.log_param(\"n_iterations\", n_iterations)\n",
        "    mlflow.log_param(\"n_latent_classes\", n_latent_classes)\n",
        "    run_plsi_v2(ratings_small_df, n_iterations=n_iterations, n_latent_classes=n_latent_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwEIeSUnP-by",
        "outputId": "4cda3112-3654-4b93-cb40-b02410b77503"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLH: 40.7161341716\n",
            "Initialization: 6.1s\n",
            "Iteration 1: E-step: 0.5s\n",
            "Iteration 1: M-step: 9.0s\n",
            "LLH: 40.7161669555\n",
            "Iteration 2: E-step: 0.6s\n",
            "Iteration 2: M-step: 5.3s\n",
            "LLH: 40.7162341512\n",
            "Iteration 3: E-step: 1.1s\n",
            "Iteration 3: M-step: 12.0s\n",
            "LLH: 40.7163530331\n",
            "Iteration 4: E-step: 2.5s\n",
            "Iteration 4: M-step: 13.4s\n",
            "LLH: 40.7165633034\n",
            "Iteration 5: E-step: 6.7s\n",
            "Iteration 5: M-step: 27.3s\n",
            "LLH: 40.7169555504\n",
            "Iteration 6: E-step: 22.9s\n",
            "Iteration 6: M-step: 77.8s\n",
            "LLH: 40.7177529545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**\n",
        "\n",
        "We indeed see that the computation is much faster, but we still see that the M-step takes more and more time"
      ],
      "metadata": {
        "id": "ekuh0qJ8Rx1c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVGoNDANaufo"
      },
      "source": [
        "### Question CPLSI2.3\n",
        "\n",
        "> Try to unpersist your dataframes when they become unneeded (look at the Storage tab in the Spark UI) (Optional + 2pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**\n",
        "\n",
        "Below we add unpersist() in the for loop at the right timing. We have 2 chain computations :\n",
        "- p(z|u,s) ▶ N(z|s), N(z), p(z|u) ▶ p(z|u,s) ▶ etc ... <BR>\n",
        "So we can erase the previous iteration dataframes on the fly, example : we don't need p(z|u,s) to compute the next iteration p(z|u,s) so we unpersist() p1(z|u,s) before computing p2(z|u,s). Same idea for the other 3 dataframes\n"
      ],
      "metadata": {
        "id": "Ip5GQ1gbTG2a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "GR3u5-fIaufo"
      },
      "outputs": [],
      "source": [
        "def run_plsi_v3(observed_pairs, n_iterations, n_latent_classes, checkpoint_every=1):\n",
        "    start_init_time = time.time()\n",
        "    spark.sparkContext.setJobDescription(\"Initialization\")\n",
        "\n",
        "    p_z_knowing_u_and_s = initialize_statistics(observed_pairs, n_latent_classes).cache()\n",
        "    count_z_s = get_count_z_s(p_z_knowing_u_and_s, n_latent_classes).cache()\n",
        "    p_z_knowing_u = get_p_z_knowing_u(p_z_knowing_u_and_s, n_latent_classes).cache()\n",
        "    count_z = get_count_z(count_z_s, n_latent_classes).cache()\n",
        "    llh = log_likelihood(\n",
        "        observed_pairs=observed_pairs,\n",
        "        count_z_s=count_z_s,\n",
        "        count_z=count_z,\n",
        "        p_z_knowing_u=p_z_knowing_u,\n",
        "        n_latent_classes=n_latent_classes\n",
        "    )\n",
        "    mlflow.log_metric(key=\"llh\", value=llh, step=0)\n",
        "    print(f'LLH: {llh:.10f}')\n",
        "\n",
        "    end_init_time = time.time()\n",
        "    print(f'Initialization: {end_init_time - start_init_time:.1f}s')\n",
        "\n",
        "    for i in range(n_iterations):\n",
        "        start_e_step = time.time()\n",
        "        spark.sparkContext.setJobDescription(f\"Iteration {i+1}: E-step\")\n",
        "        # E step\n",
        "        # Unpersist the previous iteration p(z|u,s) as we don't need it anymore\n",
        "        p_z_knowing_u_and_s.unpersist()\n",
        "        # Recomputing p(z|u,s)\n",
        "        p_z_knowing_u_and_s = get_p_z_knowing_u_and_s(\n",
        "            observed_pairs=observed_pairs,\n",
        "            count_z_s=count_z_s,\n",
        "            count_z=count_z,\n",
        "            p_z_knowing_u=p_z_knowing_u,\n",
        "            n_latent_classes=n_latent_classes\n",
        "        ).cache()\n",
        "\n",
        "        end_e_step = time.time()\n",
        "        print(f'Iteration {i+1}: E-step: {end_e_step - start_e_step:.1f}s')\n",
        "\n",
        "        spark.sparkContext.setJobDescription(f\"Iteration {i+1}: M-step\")\n",
        "        # M step\n",
        "        # Unpersist the previous iteration N(z|s), N(z), p(z|u) as we don't need them anymore\n",
        "        count_z_s.unpersist()\n",
        "        count_z.unpersist()\n",
        "        p_z_knowing_u.unpersist()\n",
        "        # Recomputing N(z|s), N(z), p(z|u)\n",
        "        count_z_s = get_count_z_s(p_z_knowing_u_and_s, n_latent_classes).cache()\n",
        "        count_z = get_count_z(count_z_s, n_latent_classes).cache()\n",
        "        p_z_knowing_u = get_p_z_knowing_u(p_z_knowing_u_and_s, n_latent_classes).cache()\n",
        "\n",
        "        llh = log_likelihood(observed_pairs, count_z_s, count_z, p_z_knowing_u, n_latent_classes)\n",
        "        mlflow.log_metric(key=\"llh\", value=llh, step=i+1)\n",
        "\n",
        "        end_m_step = time.time()\n",
        "        print(f'Iteration {i+1}: M-step: {end_m_step - end_e_step:.1f}s')\n",
        "        print(f'LLH: {llh:.10f}')\n",
        "\n",
        "    # Unpersist() p(z|u) and p(z|u,s) since we don't need them anymore\n",
        "    p_z_knowing_u.unpersist()\n",
        "    p_z_knowing_u_and_s.unpersist()\n",
        "\n",
        "    p_s_knowing_z = get_p_s_knowing_z(count_z_s, count_z, n_latent_classes)\n",
        "    return p_s_knowing_z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Quite long, do not run with more than 5 iterations\n",
        "n_iterations = 5\n",
        "n_latent_classes = 5\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.log_param(\"n_iterations\", n_iterations)\n",
        "    mlflow.log_param(\"n_latent_classes\", n_latent_classes)\n",
        "    RESULT = run_plsi_v3(ratings_small_df, n_iterations=n_iterations, n_latent_classes=n_latent_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "4q-Ho9P6ZGXP",
        "outputId": "66a79162-7ea9-4b31-f4d6-fd98ecac74c4"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLH: 40.7160845607\n",
            "Initialization: 5.4s\n",
            "Iteration 1: E-step: 0.4s\n",
            "Iteration 1: M-step: 17.4s\n",
            "LLH: 40.7161462762\n",
            "Iteration 2: E-step: 0.6s\n",
            "Iteration 2: M-step: 45.2s\n",
            "LLH: 40.7161244225\n",
            "Iteration 3: E-step: 1.4s\n",
            "Iteration 3: M-step: 152.0s\n",
            "LLH: 40.7161807767\n",
            "Iteration 4: E-step: 2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-77f439a2fdfd>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_iterations\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_latent_classes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mRESULT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_plsi_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_small_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_latent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-91-08b84a22e34d>\u001b[0m in \u001b[0;36mrun_plsi_v3\u001b[0;34m(observed_pairs, n_iterations, n_latent_classes, checkpoint_every)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mp_z_knowing_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_p_z_knowing_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_z_knowing_u_and_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mllh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_z_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_z_knowing_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"llh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-6899b5180dc1>\u001b[0m in \u001b[0;36mlog_likelihood\u001b[0;34m(observed_pairs, count_z_s, count_z, p_z_knowing_u, n_latent_classes)\u001b[0m\n\u001b[1;32m     17\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log[ sum_z p(s|z) * p(z|u)]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_sum_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p(s|z) * p(z|u)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log[ sum_z p(s|z) * p(z|u)]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_likelihood'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m              \u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \"\"\"\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_rdd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjavaToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             self._lazy_rdd = RDD(\n\u001b[1;32m    216\u001b[0m                 \u001b[0mjrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTRRSDGiaufo"
      },
      "source": [
        "### Question CPLSI2.4\n",
        "\n",
        "> If after few steps (typically 5), your algorithm starts being much slower and spend more and more time scheduling jobs (look in the Spark UI), try using [.localCheckpoint()](https://spark.apache.org/docs/2.1.0/api/python/pyspark.html#pyspark.RDD.localCheckpoint). How does it differ from caching ? What are the benefits and the drawbacks ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "95-Mir1Naufp"
      },
      "outputs": [],
      "source": [
        "def run_plsi_v4(observed_pairs, n_iterations, n_latent_classes, checkpoint_every=1):\n",
        "    start_init_time = time.time()\n",
        "    spark.sparkContext.setJobDescription(\"Initialization\")\n",
        "\n",
        "    p_z_knowing_u_and_s = initialize_statistics(observed_pairs, n_latent_classes).localCheckpoint(True)\n",
        "    count_z_s = get_count_z_s(p_z_knowing_u_and_s, n_latent_classes).localCheckpoint(True)\n",
        "    count_z = get_count_z(count_z_s, n_latent_classes).localCheckpoint(True)\n",
        "    p_z_knowing_u = get_p_z_knowing_u(p_z_knowing_u_and_s, n_latent_classes).localCheckpoint(True)\n",
        "    llh = log_likelihood(\n",
        "        observed_pairs=observed_pairs,\n",
        "        count_z_s=count_z_s,\n",
        "        count_z=count_z,\n",
        "        p_z_knowing_u=p_z_knowing_u,\n",
        "        n_latent_classes=n_latent_classes\n",
        "    )\n",
        "    mlflow.log_metric(key=\"llh\", value=llh, step=0)\n",
        "    print(f'LLH: {llh:.10f}')\n",
        "\n",
        "    end_init_time = time.time()\n",
        "    print(f'Initialization: {end_init_time - start_init_time:.1f}s')\n",
        "\n",
        "    for i in range(n_iterations):\n",
        "        # E step\n",
        "        start_e_step = time.time()\n",
        "        spark.sparkContext.setJobDescription(f\"Iteration {i+1}: E-step\")\n",
        "        p_z_knowing_u_and_s = get_p_z_knowing_u_and_s(\n",
        "            observed_pairs=observed_pairs,\n",
        "            count_z_s=count_z_s,\n",
        "            count_z=count_z,\n",
        "            p_z_knowing_u=p_z_knowing_u,\n",
        "            n_latent_classes=n_latent_classes\n",
        "        ).localCheckpoint(True)\n",
        "\n",
        "        end_e_step = time.time()\n",
        "        print(f'Iteration {i+1}: E-step: {end_e_step - start_e_step:.1f}s')\n",
        "\n",
        "        # M step\n",
        "        spark.sparkContext.setJobDescription(f\"Iteration {i+1}: M-step\")\n",
        "        count_z_s = get_count_z_s(p_z_knowing_u_and_s, n_latent_classes).localCheckpoint(True)\n",
        "        count_z = get_count_z(count_z_s, n_latent_classes).localCheckpoint(True)\n",
        "        p_z_knowing_u = get_p_z_knowing_u(p_z_knowing_u_and_s, n_latent_classes).localCheckpoint(True)\n",
        "\n",
        "        llh = log_likelihood(observed_pairs, count_z_s, count_z, p_z_knowing_u, n_latent_classes)\n",
        "        mlflow.log_metric(key=\"llh\", value=llh, step=i+1)\n",
        "\n",
        "        end_m_step = time.time()\n",
        "        print(f'Iteration {i+1}: M-step: {end_m_step - end_e_step:.1f}s')\n",
        "        print(f'LLH: {llh:.10f}')\n",
        "\n",
        "    #We use collect() to actually compute the result so we can then unpersist() the 4 dataFrames\n",
        "    p_s_knowing_z = get_p_s_knowing_z(count_z_s, count_z, n_latent_classes).collect()\n",
        "    count_z_s.unpersist()\n",
        "    count_z.unpersist()\n",
        "    p_z_knowing_u.unpersist()\n",
        "    p_z_knowing_u_and_s.unpersist()\n",
        "    return p_s_knowing_z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_iterations = 10\n",
        "n_latent_classes = 5\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.log_param(\"n_iterations\", n_iterations)\n",
        "    mlflow.log_param(\"n_latent_classes\", n_latent_classes)\n",
        "    #Store the result in RESULT, otherwise it'll print the whole dataframe making us run out of memory\n",
        "    RESULT = run_plsi_v4(ratings_small_df, n_iterations=n_iterations, n_latent_classes=n_latent_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "R5fwGXD-bIv2",
        "outputId": "3c6a3177-85ea-4a90-fedf-2761cded5cee"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-14984a0cacfa>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_latent_classes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Store the result in RESULT, otherwise it'll print the whole dataframe making us run out of memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mRESULT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_plsi_v4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_small_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_latent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-93-24af5404c8ac>\u001b[0m in \u001b[0;36mrun_plsi_v4\u001b[0;34m(observed_pairs, n_iterations, n_latent_classes, checkpoint_every)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetJobDescription\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initialization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mp_z_knowing_u_and_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocalCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcount_z_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_count_z_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_z_knowing_u_and_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocalCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcount_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_count_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_z_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocalCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mlocalCheckpoint\u001b[0;34m(self, eager)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0mDataFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbigint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \"\"\"\n\u001b[0;32m-> 1064\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocalCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezgb0OT2bcPx",
        "outputId": "d000f8dd-397d-4492-da8a-d557f174b34b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "602"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**\n",
        "\n",
        "Here we see that the steps don't take more and more time thanks to .localCheckpoint(). <br>\n",
        "<br>\n",
        "\n",
        "The fundamental difference between the 2 methods is that cache() preserves the lineage and .localChecpoint() doesn't : <BR>\n",
        "\n",
        "That means if you use an 3 iterations algorithm where you compute a variable A at iteration 3 off of the variable A of the 2nd iteration who is also computed off of the A of the 1st iteration and you cache() at every iterations. A1 -> A2 -> A3 <BR> Then .cache() keeps the history of A of every iterations, so that if for some reasons we lose A1, we can still recompute A2 and A3. <br>\n",
        "\n",
        "Whereas .localCheckpoint() only keeps the A of the current iteration, it doesn't keep the lineage. <br>\n",
        "So .localCheckpoint() is preferable in an iterative algorithm like this where we don't need to keep the 4 dataframes of the previous iterations. <br>\n",
        "- Benefits of Drawbacks of .cache() : we keep the history just in case, but that takes more storage/memory space and the computation is slower\n",
        "- Benefits of Drawbacks of .localCheckpoint() : computationally faster, less storage/memory usage, but unconvenient if we need the lineage for whatever reason\n"
      ],
      "metadata": {
        "id": "R09oJ75ibd39"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbstFMhYnpSk"
      },
      "source": [
        "# Part D - Test them all (5 points)\n",
        "\n",
        "> In this section, we create training and test datasets, and test all the different prediction algorithms described above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "engmZXePsEfv"
      },
      "source": [
        "## Training and Testing datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIxB2g3QsKGC"
      },
      "source": [
        "### Question D1\n",
        "\n",
        "> Create the training dataset named *training_df*. It is made of raw ratings dataframe, where:\n",
        "> - *hash(userId) % 2 == 0*\n",
        "> - and *rating >= 3.5*\n",
        ">\n",
        "> You should rely on functions written in Part A.\n",
        ">\n",
        "> Persist it on disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "tags": [],
        "id": "-As9-gJLaufq"
      },
      "outputs": [],
      "source": [
        "training_df = remove_bad_ratings(\n",
        "    sample_users(ratings_df_parquet, ratio=0.5),\n",
        "    threshold=3.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_df.persist(StorageLevel.DISK_ONLY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2BOBJZeKmB1",
        "outputId": "e2981814-cf75-4f36-ad02-d74c790a9a7c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats(training_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSCY5WtDKjZz",
        "outputId": "d32f32ac-51d4-4719-c389-6f225f0363ff"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of distinct users : 69227\n",
            "Amount of distinct movies : 20294\n",
            "Total amount of ratings : 6089805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK43OefMszyg"
      },
      "source": [
        "### Question D2\n",
        "\n",
        "> Create a function named *create_test_df*, that creates a test dataset from a ratings dataframe ; it only retain the following records:\n",
        "> - hash(userId) % 2 == 1\n",
        "> - rating >= 3.5\n",
        ">\n",
        "> Also, the function returns a dataframe structured like this:\n",
        "> - userid : the user id\n",
        "> - movies : list[integer] (all the movies in the user timeline minus the *K* most recent ones)\n",
        "> - label : list[integer] (all the *K* most recent movies in user timeline)\n",
        ">\n",
        "> *K* is parameter whose default value is 5.\n",
        ">\n",
        "> Test the test dataset creation on a toy example.\n",
        ">\n",
        "> Create the real test dataset from the whole movieLense dataset. Name it *test_df*. Persist it on disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "tags": [],
        "id": "uwgJz469aufq"
      },
      "outputs": [],
      "source": [
        "def create_test_df(ratings_df, K=5):\n",
        "    filtered_df = ratings_df.filter((F.hash(\"userId\") % 2 == 1) & (ratings_df.rating >= 3.5))\n",
        "\n",
        "    window = Window.partitionBy(\"userId\").orderBy(F.desc(\"timestamp\"))\n",
        "    movies_with_row_number = filtered_df.withColumn(\"row_number\", F.row_number().over(window))\n",
        "    test_df = movies_with_row_number.groupBy(\"userId\").agg(\n",
        "        F.collect_list(F.when(F.col(\"row_number\") > K, F.col(\"movieId\"))).alias(\"movies\"),\n",
        "        F.collect_list(F.when(F.col(\"row_number\") <= K, F.col(\"movieId\"))).alias(\"label\")\n",
        "    ).select(\"userId\", \"movies\", \"label\")\n",
        "    return test_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_data = ratings_df_parquet.sample(fraction=1e-2)\n",
        "#2M rows"
      ],
      "metadata": {
        "id": "TrNQUMI9DKZT"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_test_df(toy_data, K=5).show(20, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD9zhLXqMnRk",
        "outputId": "3bde00cb-4ec2-4ed4-bbd2-509caf1e79eb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+----------------------+\n",
            "|userId|movies|label                 |\n",
            "+------+------+----------------------+\n",
            "|11    |[]    |[6537, 1584]          |\n",
            "|21    |[]    |[3363, 3098]          |\n",
            "|23    |[]    |[1, 2353]             |\n",
            "|24    |[]    |[5299, 5679, 104, 357]|\n",
            "|33    |[]    |[608]                 |\n",
            "|44    |[]    |[920]                 |\n",
            "|53    |[]    |[1366]                |\n",
            "|54    |[]    |[2803]                |\n",
            "|71    |[]    |[107069]              |\n",
            "|74    |[]    |[930]                 |\n",
            "|96    |[]    |[94070]               |\n",
            "|100   |[]    |[708]                 |\n",
            "|112   |[]    |[1682]                |\n",
            "|116   |[]    |[7360, 353]           |\n",
            "|121   |[]    |[61250]               |\n",
            "|124   |[]    |[194, 3882]           |\n",
            "|138   |[]    |[4992]                |\n",
            "|147   |[]    |[904]                 |\n",
            "|154   |[]    |[4226]                |\n",
            "|158   |[]    |[481, 475]            |\n",
            "+------+------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = create_test_df(ratings_df_parquet, K=5)"
      ],
      "metadata": {
        "id": "I75ynbYtMydL"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.persist(StorageLevel.DISK_ONLY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSvR_fK7NG_K",
        "outputId": "f06570a5-1ee7-4ba9-f1cf-66ebe19fc712"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[userId: int, movies: array<int>, label: array<int>]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CIzNEs5zgVW"
      },
      "source": [
        "### Question D3\n",
        "\n",
        "> Use/adapt each of the algorithms defined in previous sections (naïve, a-priori, FP-growth, PLSI) to predict the 5 next movies that will be seen by the user based on previously seen movies.\n",
        ">\n",
        "> Each algorithm can be 'trained' on *training_df* or a subset of it ; choose and justify.\n",
        ">\n",
        "> For each algorithm, make a quick qualitative analysis, to see how relevant recommended movies are. You should rely on *movies_df* for this question.\n",
        ">\n",
        "> Then, compare the algorithms with the *test_df*, with metrics like *recall* and *precision at k* (define some methods that compute recall and precision at k from test dataframe and predictions dataframe parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER**"
      ],
      "metadata": {
        "id": "eAQ9B3imKbuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_df_subset = remove_exotic_movies(\n",
        "    remove_old_movies_in_timelines(training_df, nb_max_movies=100),\n",
        "    nb_min_ratings=200,\n",
        "    drop_count=True\n",
        ")"
      ],
      "metadata": {
        "id": "oAyetNgEJXuZ"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We removed old movies in timeline because of the trending effect, we would rather recommend recent trending movies and since we only have to predict 5 movies this should be enough. <br>\n",
        "By restricting to the last rated 30 movies, we also limit the skewness effect of generating pairs (For the Naive & A priori algorithm) as :\n",
        "- 30 choose 2 = 435\n",
        "- 30 choose 3 = 4060\n",
        "<br>\n",
        "\n",
        "We also remove exotic movies (movies with less than 200 ratings) to reduce the size of the dataset"
      ],
      "metadata": {
        "id": "HxgIFCzkKplP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats(training_df_subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "cxBl1kRiKI_o",
        "outputId": "dfd745b7-4697-466c-ac69-a83f3bcddb2a"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-247-c217728461f2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-a0c2825f9ebd>\u001b[0m in \u001b[0;36mdf_stats\u001b[0;34m(rating_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdf_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mnb_distinct_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrating_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'userId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Amount of distinct users : {nb_distinct_users}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mnb_distinct_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrating_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Amount of distinct movies : {nb_distinct_movies}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \"\"\"\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_df_subset.persist(StorageLevel.DISK_ONLY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "906MIurvKZy7",
        "outputId": "cf6c3bc1-b915-445b-e5fa-0812c3b0e1cb"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[movieId: int, userId: int, rating: double, timestamp: int, most_recent: int]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NAIVE"
      ],
      "metadata": {
        "id": "u8ga0FKoIp5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(user_timeline_df, association_rules_df):\n",
        "    # Explode the movies column in the user timeline DataFrame\n",
        "    user_movies_df = user_timeline_df.withColumn(\"movieId\", explode(\"movies\"))\n",
        "\n",
        "    # Join the user movies with association rules to get recommendations\n",
        "    recommendations_df = user_movies_df.join(\n",
        "        association_rules_df,\n",
        "        (user_movies_df.movieId == association_rules_df.movieId1) |\n",
        "        (user_movies_df.movieId == association_rules_df.movieId2),\n",
        "        how=\"left\"\n",
        "    ).withColumn(\"recommandation\", F.when(F.col(\"movieId2\") == F.col(\"movieId\"), F.col(\"movieId1\")).otherwise(F.col(\"movieId2\")))\\\n",
        "    .filter(~F.array_contains(F.col(\"movies\"),F.col(\"recommandation\")))\\\n",
        "    .groupBy([\"userId\",\"recommandation\"])\\\n",
        "    .agg(F.max(\"support\").alias(\"support\"))\n",
        "\n",
        "    # Rank recommendations based on count\n",
        "    windowSpec = Window.partitionBy(\"userId\").orderBy(F.col(\"support\").desc())\n",
        "    ranked_recommendations_df = recommendations_df.withColumn(\"rank\", F.row_number().over(windowSpec))\n",
        "\n",
        "    # Filter the top 5 recommendations\n",
        "    top_recommendations_df = ranked_recommendations_df.filter(F.col(\"rank\") <= 5)\n",
        "    return top_recommendations_df.agg(F.collect_list(\"recommandation\"))\n"
      ],
      "metadata": {
        "id": "2iZMWzI6-KAV"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Naive():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, df):\n",
        "        pair_frequencies = compute_pair_frequencies(\n",
        "            compute_pairs(\n",
        "                compute_timeline(df)\n",
        "            )\n",
        "        )\n",
        "        self.pair_frequencies = pair_frequencies\n",
        "        pair_frequencies.localCheckpoint(True)\n",
        "        return pair_frequencies\n",
        "\n",
        "    def predict(self, user_timeline, nb_predictions=5):\n",
        "        # Exploded timeline looks like this :\n",
        "        # [{userId=1, movies=[1,2,3], movieId=1},\n",
        "        #  {userId=1, movies=[1,2,3], movieId=2},\n",
        "        #  {userId=1, movies=[1,2,3], movieId=3}]\n",
        "        exploded_timeline = user_timeline.withColumn('movieId', F.explode('movies'))\n",
        "\n",
        "        # Join the pair_frequences with exploded timeline to compute the recommended movies\n",
        "        # the recommended movie is the movie of the pair(movieId1, movieId2) that's not equal to movieId\n",
        "        recommendations_df = exploded_timeline.join(\n",
        "            self.pair_frequencies,\n",
        "            on=(exploded_timeline.movieId == self.pair_frequencies.movieId1) | (exploded_timeline.movieId == self.pair_frequencies.movieId2),\n",
        "            how=\"left\"\n",
        "        ).withColumn(\"recommendation\", F.when(F.col(\"movieId2\") == F.col(\"movieId\"), F.col(\"movieId1\")).otherwise(F.col(\"movieId2\")))\n",
        "        # Filter out all the recommendation movies that are already seen by the user by checking if 'movies' contains recommendations\n",
        "        recommendations_df = recommendations_df.filter(~F.array_contains(F.col(\"movies\"),F.col(\"recommendation\")))\\\n",
        "        .groupBy([\"userId\",\"recommendation\"])\\\n",
        "        .agg(F.max(\"support\").alias(\"support\")) #Explanation for this line below\n",
        "\n",
        "        # Filter the top 5 recommendations\n",
        "        windowSpec = Window.partitionBy(\"userId\").orderBy(F.col(\"support\").desc())\n",
        "        recommendations_df = recommendations_df.withColumn(\"rank\", F.row_number().over(windowSpec))\\\n",
        "                             .recommendations_df.filter(F.col(\"rank\") <= 5)\n",
        "\n",
        "        # Agregate all the recommendations into a list\n",
        "        return recommendations_df.agg(F.collect_list(\"recommendation\"))"
      ],
      "metadata": {
        "id": "FtlcZLJbpqxl"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "nAyI7OsuWMWe"
      },
      "outputs": [],
      "source": [
        "naive_model = Naive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_model.fit(training_df_subset).show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "QZaCLhCkRF6u",
        "outputId": "09d059f2-4fea-44e5-c94e-efe10110a7db"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-245-90c471110736>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnaive_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_timeline = compute_timeline(test_df.sample(0.01)).localCheckpoint()\n",
        "naive_model.predict(user_timeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUd40GZSwfZb",
        "outputId": "9261c21e-be76-494c-c87b-2d6faa3e11dd"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[movieId1: int, movieId2: int, count: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A PRIORI"
      ],
      "metadata": {
        "id": "82_kHiNsItR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Apriori = Apriori_B8(\n",
        "    training_df_subset,\n",
        "    support_threshold=150,\n",
        "    max_K=3\n",
        ")"
      ],
      "metadata": {
        "id": "6bQMzDMDgL3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Apriori.show()"
      ],
      "metadata": {
        "id": "GWkzVzhxhU0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Apriori.persist(StorageLevel.DISK_ONLY)"
      ],
      "metadata": {
        "id": "pXjSMFRdhQD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FP-GROWTH"
      ],
      "metadata": {
        "id": "Tx1fnP0iIvX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_user_timeline = compute_timeline(training_df_subset)"
      ],
      "metadata": {
        "id": "wBSpEly3nUiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpGrowth = FPGrowth(itemsCol='movies', minSupport=0.1, minConfidence=0.5)\n",
        "model = fpGrowth.fit(user_timeline)"
      ],
      "metadata": {
        "id": "K4Tyu-jFhXVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PLSI"
      ],
      "metadata": {
        "id": "jQEZCYEZIyjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BENCHMARK"
      ],
      "metadata": {
        "id": "5PZpczQcI0VI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "p5yHDm0vXkIQ"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}